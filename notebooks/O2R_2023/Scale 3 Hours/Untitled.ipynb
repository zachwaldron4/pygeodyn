{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485b74da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T22:11:48.034053Z",
     "start_time": "2024-05-28T22:11:48.014558Z"
    }
   },
   "outputs": [],
   "source": [
    "# def normalize_density_msis2(sat_data, sat_name, alt_norm):\n",
    "#     import pandas as pd\n",
    "#     import numpy as np \n",
    "#     import sys  \n",
    "#     from scipy.io import loadmat  #allows us to read in .mat files\n",
    "#     from datetime import datetime, timedelta\n",
    "#     import gc\n",
    "\n",
    "#     #### MAKE MSIS Take the 3HR Ap values\n",
    "#     from pymsis import msis\n",
    "#     SWI_option = [1.0]*25\n",
    "#     SWI_option[8] = -1.0\n",
    "    \n",
    "#     if sat_name =='GRACE-FO':\n",
    "#         rhoname  = 'dens_x'\n",
    "#         datename = 'Date'\n",
    "#     if sat_name =='ICESat-2':\n",
    "#         rhoname  = 'Rho_x'\n",
    "#         datename = 'date'\n",
    "\n",
    "        \n",
    "        \n",
    "#     from netCDF4 import Dataset\n",
    "#     import numpy as np \n",
    "#     import os\n",
    "#     import pandas as pd\n",
    "#     # import numpy  as np\n",
    "\n",
    "#     def read_nc_file( filename, variables):\n",
    "#         ''' This fu#### clear up some space        \n",
    "#     truncate_date    = np.logical_and(gpi_data['Date'].year>=2018 , gpi_data['Date'].year<=2019 )\n",
    "#     truncate_date3hr =  np.logical_and(gpi_data['Date_3hrAp'].year>=2018 , gpi_data['Date_3hrAp'].year<=2019 )\n",
    "\n",
    "#     gpi_data['Date_3hrAp'] = gpi_data['Date_3hrAp'][truncate_date3hr]\n",
    "#     gpi_data['Ap']         = np.array(gpi_data['Ap'])[truncate_date3hr]\n",
    "#     gpi_data['Date']       = gpi_data['Date'][truncate_date]\n",
    "#     gpi_data['Ap_dailyavg'] =  np.array(gpi_data['Ap_dailyavg'])[truncate_date]\n",
    "#     gpi_data['f107d_earth'] = np.array(gpi_data['f107d_earth'])[truncate_date]\n",
    "#     gpi_data['f107a_earth'] = np.array(gpi_data['f107a_earth'])[truncate_date]\n",
    "\n",
    "#     del gpi_data['DOY']\n",
    "#     del gpi_data['kp']\n",
    "#     del gpi_data['f107d']\n",
    "#     del gpi_data['f107a']\n",
    "#     del gpi_data['year_day']\n",
    "#     nction reads the TIEGCM .nc files and saves the given input variables to a dictionary.\n",
    "#             The breakloop feature is here so that if the file doesn't exist the code can still continue.  '''\n",
    "#         status = os.path.exists(filename)\n",
    "\n",
    "#         if status == True:\n",
    "#             data = {}\n",
    "#             for i, var_names in enumerate(variables):\n",
    "#                 ncid =  Dataset(filename,\"r+\", format=\"NETCDF4\")# filename must be a string\n",
    "#                 varData = ncid.variables\n",
    "#                 data[var_names] = np.array(varData[var_names])  \n",
    "#         elif status == False:\n",
    "#             print('No File Found', filename )\n",
    "#             breakloop = True\n",
    "#             data = 0\n",
    "#             return( data , breakloop)\n",
    "#         breakloop = False\n",
    "#         return(data,breakloop )\n",
    "\n",
    "\n",
    "\n",
    "#     #################################################################\n",
    "#     ##########    First fix the F10.7 values to be MgII    ##########\n",
    "#     #################################################################\n",
    "#     Kp_to_Ap = {0.    : 0  ,\n",
    "#                 0.1   : 0  ,\n",
    "#                 0.3   : 2  ,\n",
    "#                 0.7   : 3  ,\n",
    "#                  1.   : 4  ,\n",
    "#                  1.3  : 5  ,\n",
    "#                  1.7  : 6  ,\n",
    "#                  2.   : 7  ,\n",
    "#                  2.3  : 9  ,\n",
    "#                  2.7  : 12 ,\n",
    "#                  3.   : 15 ,\n",
    "#                  3.3  : 18 ,\n",
    "#                  3.7  : 22 ,\n",
    "#                  4.   : 27 ,\n",
    "#                  4.3  : 32 ,\n",
    "#                  4.7  : 39 ,\n",
    "#                  5    : 48 ,\n",
    "#                  5.3  : 56 ,\n",
    "#                  5.7  : 67 ,\n",
    "#                  6.   : 80 ,\n",
    "#                  6.3  : 94 ,\n",
    "#                  6.7  : 111,\n",
    "#                  7    : 132,\n",
    "#                  7.3  : 154,\n",
    "#                  7.7  : 179,\n",
    "#                  8.   : 207,\n",
    "#                  8.3  : 236,\n",
    "#                  8.7  : 300,\n",
    "#                  9.   : 400}\n",
    "\n",
    "#     path_to_gpi = '/data/SatDragModelValidation/data/inputs/atmos_models/geo_phys_indicies/gpi_1960001-2021243_f107aDaily.nc'\n",
    "#     variables    =  ['year_day', 'f107d', 'f107a', 'kp']\n",
    "#     gpi_data    =  read_nc_file(path_to_gpi, variables)\n",
    "#     gpi_data    =  gpi_data[0]\n",
    "#     gpi_data['Date']= pd.to_datetime( gpi_data['year_day'], format='%Y%j')\n",
    "\n",
    "#     #### Make an array of datetimes for the 3hr Kps\n",
    "#     doy=[]\n",
    "#     Date_3hrAp = []\n",
    "#     Ap = []\n",
    "#     Ap_dailyavg = []\n",
    "\n",
    "#     for i,val in enumerate(gpi_data['Date']):\n",
    "#         doy.append(str(gpi_data['year_day'][i])[-3:])\n",
    "\n",
    "#         n=0\n",
    "#         avg_ap = []\n",
    "#         for ii,kpval in enumerate(gpi_data['kp'][i]):\n",
    "#             Ap.append( Kp_to_Ap[np.around(kpval,1)])\n",
    "#             avg_ap.append( Kp_to_Ap[np.around(kpval,1)])\n",
    "\n",
    "#             if ii==0:\n",
    "#                 Date_3hrAp.append(val)\n",
    "#             else:\n",
    "#                 Date_3hrAp.append(val + pd.Timedelta(hours=3*n))\n",
    "#             n+=1\n",
    "\n",
    "#         Ap_dailyavg.append(np.mean(avg_ap))\n",
    "#     gpi_data['Date_3hrAp']=  pd.to_datetime(Date_3hrAp)\n",
    "#     gpi_data['DOY']= doy\n",
    "#     gpi_data['Ap']= Ap\n",
    "#     gpi_data['Ap_dailyavg']= Ap_dailyavg\n",
    "\n",
    "#     #### Account for the F10.7 at earth (instead of referenced at 1AU)\n",
    "#     f107d_earth = []\n",
    "#     f107a_earth = []\n",
    "#     for i,val in enumerate(gpi_data['Date']):\n",
    "#         iday = int(gpi_data['DOY'][i])\n",
    "\n",
    "#         theta0 = 2 * np.pi * (iday)/365.\n",
    "#         sfeps = 1.000110 + 0.034221*np.cos(theta0)+0.001280* np.sin(theta0) +0.000719*np.cos(2.*theta0)+0.000077*np.sin(2.*theta0)\n",
    "\n",
    "#         f107d_earth.append(sfeps * gpi_data['f107d'][i])\n",
    "#         f107a_earth.append(sfeps * gpi_data['f107a'][i])\n",
    "\n",
    "#     gpi_data['f107d_earth'] = f107d_earth\n",
    "#     gpi_data['f107a_earth'] = f107a_earth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     #### clear up some space        \n",
    "#     truncate_date    = np.logical_and(gpi_data['Date'].year>=2018 , gpi_data['Date'].year<=2019 )\n",
    "#     truncate_date3hr =  np.logical_and(gpi_data['Date_3hrAp'].year>=2018 , gpi_data['Date_3hrAp'].year<=2019 )\n",
    "\n",
    "#     gpi_data['Date_3hrAp'] = gpi_data['Date_3hrAp'][truncate_date3hr]\n",
    "#     gpi_data['Ap']         = np.array(gpi_data['Ap'])[truncate_date3hr]\n",
    "#     gpi_data['Date']       = gpi_data['Date'][truncate_date]\n",
    "#     gpi_data['Ap_dailyavg'] =  np.array(gpi_data['Ap_dailyavg'])[truncate_date]\n",
    "#     gpi_data['f107d_earth'] = np.array(gpi_data['f107d_earth'])[truncate_date]\n",
    "#     gpi_data['f107a_earth'] = np.array(gpi_data['f107a_earth'])[truncate_date]\n",
    "\n",
    "#     del gpi_data['DOY']\n",
    "#     del gpi_data['kp']\n",
    "#     del gpi_data['f107d']\n",
    "#     del gpi_data['f107a']\n",
    "#     del gpi_data['year_day']\n",
    "#     del truncate_date, truncate_date3hr\n",
    "\n",
    "#     del Ap, doy, Date_3hrAp,  Ap_dailyavg, f107d_earth, f107a_earth, i\n",
    "#     del Kp_to_Ap, avg_ap\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#     Dnorm         = np.zeros(np.size(sat_data[datename]))\n",
    "\n",
    "#     for it,time in enumerate(sat_data[datename]):\n",
    "\n",
    "#         year  = time.year\n",
    "#         day   = time.dayofyear\n",
    "#         hours = time.hour\n",
    "\n",
    "#         ####---------------------------------------------\n",
    "#         #### Gather the Necessary Flux and Ap Information\n",
    "#         index_date = np.logical_and(gpi_data['Date'].year==year , gpi_data['Date'].dayofyear==day )\n",
    "#         f107a = [float(np.squeeze(np.asarray(gpi_data['f107a_earth'])[index_date]))]\n",
    "#         f107d = [float(np.squeeze(np.asarray(gpi_data['f107d_earth'])[index_date]))]\n",
    "#         Ap_daily_avg = float(np.squeeze(np.asarray(gpi_data['Ap_dailyavg'])[index_date]))\n",
    "\n",
    "#         ### Construct the necessary 3hr Ap Array to go into MSIS\n",
    "#         index_date3hr = np.logical_and(gpi_data['Date_3hrAp'].year==year , gpi_data['Date_3hrAp'].dayofyear==day )\n",
    "#         indexvals =  [i for i, x in enumerate(index_date3hr) if x]\n",
    "#         Ap_doy_windows = gpi_data['Date_3hrAp'][indexvals]\n",
    "\n",
    "#         #### Find the Current 3hr Kp window:A\n",
    "#         Ap_windw_hrs = [i.hour for i in Ap_doy_windows]\n",
    "#         Ap_windw_hrs = np.append(np.array(Ap_windw_hrs),24)  ## add the final window edge\n",
    "#         index_current_Ap = int(np.digitize([time.hour],Ap_windw_hrs))\n",
    "#         if index_current_Ap==8:\n",
    "#             index_current_Ap += -1\n",
    "#         indexglobal_currentAp = indexvals[index_current_Ap]\n",
    "#         Ap_3HR_current        = gpi_data['Ap'][indexglobal_currentAp]\n",
    "#         Ap_3HR_prior          = gpi_data['Ap'][indexglobal_currentAp-1]\n",
    "#         Ap_6HR_prior          = gpi_data['Ap'][indexglobal_currentAp-2]\n",
    "#         Ap_9HR_prior          = gpi_data['Ap'][indexglobal_currentAp-3]\n",
    "#         Ap_12hr_33hr_priorAVG = np.mean(gpi_data['Ap'][indexglobal_currentAp-11 :indexglobal_currentAp-3 ] ) ### 33hrs to 12 hours\n",
    "#         Ap_36hr_57hr_priorAVG = np.mean(gpi_data['Ap'][indexglobal_currentAp-19 :indexglobal_currentAp-11 ])  ### 36hrs to 57 hours\n",
    "\n",
    "#         apsin = [[Ap_daily_avg,          # (1) DAILY AP\n",
    "#                   Ap_3HR_current,        # (2) 3 HR AP INDEX FOR CURRENT TIME\n",
    "#                   Ap_3HR_prior,          # (3) 3 HR AP INDEX FOR 3 HRS BEFORE CURRENT TIME\n",
    "#                   Ap_6HR_prior,          # (4) 3 HR AP INDEX FOR 6 HRS BEFORE CURRENT TIME\n",
    "#                   Ap_9HR_prior,          # (5) 3 HR AP INDEX FOR 9 HRS BEFORE CURRENT TIME\n",
    "#                   Ap_12hr_33hr_priorAVG, # (6) AVERAGE OF EIGHT 3 HR AP INDICIES FROM 12 TO 33 HRS PRIOR\n",
    "#                   Ap_36hr_57hr_priorAVG]]# (7) AVERAGE OF EIGHT 3 HR AP INDICIES FROM 36 TO 57 HRS PRIOR\n",
    "\n",
    "#         output2_sat = msis.run(time, sat_data['lon'][it], sat_data['lat'][it], sat_data['alt'][it]/1000 , f107d, f107a, apsin , version=2, options=SWI_option)\n",
    "#         output2_norm = msis.run(time, sat_data['lon'][it], sat_data['lat'][it], alt_norm                , f107d, f107a, apsin , version=2, options=SWI_option)\n",
    "\n",
    "\n",
    "#         # print(sat_data[rhoname][it])\n",
    "#         # print(output2_norm[0,0,0,0][0] / output2_sat[0,0,0,0][0])\n",
    "#         # print(sat_data[rhoname][it])\n",
    "#         ### Add the values to the growing lists\n",
    "#         Dnorm[it]   = sat_data[rhoname][it] * (output2_norm[0,0,0,0][0] / output2_sat[0,0,0,0][0])   # normalized density to norm altitude with MSIS2\n",
    "\n",
    "#     return(Dnorm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deac6a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T22:15:46.199914Z",
     "start_time": "2024-05-28T22:15:46.192491Z"
    }
   },
   "outputs": [],
   "source": [
    "#### MAKE MSIS Take the 3HR Ap values\n",
    "from pymsis import msis\n",
    "import pandas as pd\n",
    "SWI_option = [1.0]*25\n",
    "SWI_option[8] = -1.0\n",
    "\n",
    "\n",
    "\n",
    "time = pd.to_datetime('2018-10-14 00:00:00')\n",
    "lon  = 100\n",
    "lat  = 20\n",
    "alt  = 490\n",
    "f107d = 100\n",
    "f107a = 100\n",
    "apsin = [[2,          # (1) DAILY AP\n",
    "          2,        # (2) 3 HR AP INDEX FOR CURRENT TIME\n",
    "          2,          # (3) 3 HR AP INDEX FOR 3 HRS BEFORE CURRENT TIME\n",
    "          2,          # (4) 3 HR AP INDEX FOR 6 HRS BEFORE CURRENT TIME\n",
    "          2,          # (5) 3 HR AP INDEX FOR 9 HRS BEFORE CURRENT TIME\n",
    "          2, # (6) AVERAGE OF EIGHT 3 HR AP INDICIES FROM 12 TO 33 HRS PRIOR\n",
    "          2]]\n",
    "\n",
    "output2_sat = msis.run(time, lon, lat, alt , f107d, f107a, apsin , version=2, options=SWI_option)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2afd9601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T22:17:43.273657Z",
     "start_time": "2024-05-28T22:17:43.267127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6993174e-13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2_sat[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d105bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T22:17:24.372347Z",
     "start_time": "2024-05-28T22:17:24.354571Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 4 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output2_sat[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 4 were indexed"
     ]
    }
   ],
   "source": [
    "output2_sat[0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d98d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
