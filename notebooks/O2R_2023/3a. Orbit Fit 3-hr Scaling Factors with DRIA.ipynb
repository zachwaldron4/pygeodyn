{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18921a5c",
   "metadata": {},
   "source": [
    "# Determine the drag coefficient with DRIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e432fbe0",
   "metadata": {},
   "source": [
    "To construct the orbit arcs we are going to use the `arc_times.txt` file.\n",
    "- just use the orbit start and stop times\n",
    "- turn on the DRIA usage: ` 'cd_model'       : {'input': 'DRIA'},\n",
    "`\n",
    "\n",
    "### TO DO:\n",
    "- construct the 30-hour arcs using the provided data arcs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd75757",
   "metadata": {},
   "source": [
    "## Read arc_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1526e793",
   "metadata": {},
   "source": [
    "The below snippet reads arc times from the `arc_times.txt` file and uses them as the inputs for subsequent runs.\n",
    "The scaling factor cadence is based on trimming the excess ~<3 hours off the ends and having a time stamp every 3-hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a82eae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:45:37.660260Z",
     "start_time": "2024-04-23T17:45:37.656090Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_index = 12\n",
    "# test_index = 24\n",
    "scale_cadence = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd69c564",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:45:38.318826Z",
     "start_time": "2024-04-23T17:45:37.661844Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "import numpy as np\n",
    "\n",
    "arc_timesfile = '/data/SatDragModelValidation/data/inputs/sat_icesat2/arc_times.txt'\n",
    "\n",
    "\n",
    "### Make a function that finds the right range of dates in this file.\n",
    "arcs = pd.read_csv(arc_timesfile, \n",
    "            sep = ',',\n",
    "#             dtype=object,\n",
    "            names = [\n",
    "                'arc'         ,\n",
    "                'epoch_start' ,\n",
    "                'epoch_stop'  ,\n",
    "                'orbit_start' ,\n",
    "                'orbit_stop'  ,\n",
    "                    ],)\n",
    "\n",
    "\n",
    "arcs_yyyyddd = [x.strip() for x in arcs['arc'].values.tolist()]\n",
    "epochstart   = [x.strip() for x in arcs['orbit_start'].values.tolist()]\n",
    "epochstop    = [x.strip() for x in arcs['orbit_stop' ].values.tolist()]\n",
    "\n",
    "\n",
    "# month_list = ['oct', 'nov', 'dec']\n",
    "month_list = ['nov']\n",
    "for imonth, month in enumerate(month_list):\n",
    "    if month=='oct':\n",
    "        m_num = 10\n",
    "    if month=='nov':\n",
    "        m_num = 11\n",
    "    if month=='dec':\n",
    "        m_num = 12\n",
    "    \n",
    "    input_arcs       = []\n",
    "    input_epochstart = []\n",
    "    input_epochstop  = []\n",
    "    arc_length = []\n",
    "    scaleparameter_times = []\n",
    "    \n",
    "    for i,val in enumerate(arcs_yyyyddd):\n",
    "        \n",
    "        if pd.to_datetime(val[:8],format=\"%Y.%j\").month == m_num:\n",
    "            epoch_delta  =  pd.to_timedelta(pd.to_datetime(epochstop[i]) - pd.to_datetime(epochstart[i]), 'hours')\n",
    "            arc_length.append(epoch_delta.total_seconds()/3600)\n",
    "\n",
    "            if val[8:] == 'A' or val[8:] == 'B':\n",
    "#                 input_arcs.append(      arcs_yyyyddd[i])\n",
    "#                 input_epochstart.append(epochstart[i])\n",
    "#                 input_epochstop.append( epochstop[i])\n",
    "#                 scaleparameter_times.append([''])\n",
    "                pass\n",
    "            else:\n",
    "                ### use 24-hour start/stop\n",
    "                # input_arcs.append(      arcs_yyyyddd[i])\n",
    "                # input_epochstart.append(str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\")))\n",
    "                # input_epochstop.append( str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\")+ pd.to_timedelta(24,'h')))\n",
    "                \n",
    "                ### Use Arc text file times\n",
    "                input_arcs.append(      arcs_yyyyddd[i])\n",
    "                input_epochstart.append(epochstart[i])\n",
    "                input_epochstop.append( epochstop[i])\n",
    "#                 print(f\"epoch_top {epochstop[i]}\")\n",
    "                scalestart = str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\"))\n",
    "                scalestop  = str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\") + pd.to_timedelta(24,'h'))\n",
    "                scaletimes = pd.date_range(start = pd.to_datetime(scalestart),\n",
    "                                                          end   = pd.to_datetime(scalestop ),\n",
    "                                                          freq=str(scale_cadence)+\"H\")\n",
    "\n",
    "                ###append the epoch end time to the end\n",
    "                add_epochend = np.append(scaletimes.values.astype(np.int64) // 10 ** 9,\n",
    "                              pd.to_datetime(pd.Series(epochstop[i])).values.astype(np.int64) // 10 ** 9)\n",
    "\n",
    "                \n",
    "                scaleparameter_times.append([pd.to_datetime(datetime.strftime(datetime.fromtimestamp(ts), '%y%m%d%H%M%S.%f'),\n",
    "                    format ='%y%m%d%H%M%S.%f' )\n",
    "                                 for ts in add_epochend ])\n",
    "    \n",
    "# for i,val in enumerate(input_arcs):\n",
    "#     print(f\" {input_arcs[i]:10}  , {input_epochstart[i]:20},  {input_epochstop[i]:20}, {arc_length[i]}\")\n",
    "#     if val[8:] == 'A' or val[8:] == 'B':\n",
    "#         print(\"\")\n",
    "\n",
    "#     else:\n",
    "#         print(f\" {'':10}  , {scaleparameter_times[i]}\")\n",
    "#         print(\"\")    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009bdcfd",
   "metadata": {},
   "source": [
    "Select the dates within the month of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7cdf98",
   "metadata": {},
   "source": [
    "## Run geodyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9534e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:45:38.369171Z",
     "start_time": "2024-04-23T17:45:38.321102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'novmsis2': {'num': 5, 'model_path': None}, 'novjb2008': {'num': 1, 'model_path': None}, 'novdtm2020_o': {'num': 3, 'model_path': None}}\n"
     ]
    }
   ],
   "source": [
    "from pygeodyn.PYGEODYN import Pygeodyn\n",
    "import datetime\n",
    "\n",
    "\n",
    "scaling_cadence = 3\n",
    "scale_cadence = scaling_cadence\n",
    "index_buffarc_start = 0\n",
    "run_list = [\n",
    "                'msis2',\n",
    "                'jb2008',\n",
    "                'dtm2020_o',\n",
    "           ]\n",
    "\n",
    "month_list = ['nov']\n",
    "# month_list = ['oct', 'nov', 'dec', 'jan', 'feb', 'mar', 'apr']\n",
    "# month_list = ['oct','nov', 'dec']#, 'jan', 'feb', 'mar', 'apr']\n",
    "# month_list = ['jan', 'feb', 'mar', 'apr']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dir_modeldat='/data/SatDragModelValidation/data/inputs/atmos_models'\n",
    "run_dict={}\n",
    "for i in run_list:\n",
    "    for imonth,month in enumerate(month_list):\n",
    "        if i =='msis2':\n",
    "            run_dict[month+i]={}\n",
    "            run_dict[month+i]['num'] = 5\n",
    "            run_dict[month+i]['model_path'] = None\n",
    "        if i =='dtm2020_o':\n",
    "            run_dict[month+i]={}\n",
    "            run_dict[month+i]['num'] = 3\n",
    "            run_dict[month+i]['model_path'] = None\n",
    "        if i =='jb2008':\n",
    "            run_dict[month+i]={}\n",
    "            run_dict[month+i]['num'] = 1\n",
    "            run_dict[month+i]['model_path'] = None\n",
    "\n",
    "print(run_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6262f57c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.713335Z",
     "start_time": "2024-04-23T17:45:38.371216Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the ICESat-2 Class\n",
      "check sat ICESat2\n",
      "hours_between_cd_adj 3\n",
      "     drag card date  0   181101000000\n",
      "     drag card date  1   181101030000\n",
      "     drag card date  2   181101060000\n",
      "     drag card date  3   181101090000\n",
      "     drag card date  4   181101120000\n",
      "     drag card date  5   181101150000\n",
      "     drag card date  6   181101180000\n",
      "     drag card date  7   181101210000\n",
      "     drag card date  8   181102000000\n",
      "     drag card date  9   181102024200\n",
      "Run #1     Current Time =      10:45:39  GMT-7\n",
      "Run #1\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #1 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     1.0\n",
      "|    Density      msis2\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.305\n",
      "|    Arc length   29.4 hours\n",
      "|    Epoch Start  2018-10-31 21:18:00\n",
      "|    Epoch End    2018-11-02 02:42:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018305_msis2.DRIA_alpha85_scaled_\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.305\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.305.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/msis2/msis2_DRIA_nov/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #1          Running IIS\n",
      "Run #1          No errors in IIS\n",
      "Run #1 ---------End of IIS\n",
      "\n",
      "Run #1          Running IIE\n",
      "Run #1          Current Time = 10:46:21 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/msis2_DRIA_nov/icesat2_2018305_msis2.DRIA_alpha85_scaled_\n",
      "Run #1          No errors in IIE\n",
      "Run #1 ---------End of IIE\n",
      "Run #1          Time of IIE:  400.1388738155365 secs ( 6.668981230258941  mins)\n",
      "Run #1          Current Time = 17:53:01\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #1                Finished renaming files\n",
      "Run #1                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/msis2_DRIA_nov\n",
      "hours_between_cd_adj 3\n",
      "     drag card date  0   181102000000\n",
      "     drag card date  1   181102030000\n",
      "     drag card date  2   181102060000\n",
      "     drag card date  3   181102090000\n",
      "     drag card date  4   181102120000\n",
      "     drag card date  5   181102150000\n",
      "     drag card date  6   181102180000\n",
      "     drag card date  7   181102210000\n",
      "     drag card date  8   181103000000\n",
      "     drag card date  9   181103024200\n",
      "Run #2     Current Time =      10:53:04  GMT-7\n",
      "Run #2\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #2 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     1.0\n",
      "|    Density      msis2\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.306\n",
      "|    Arc length   29.4 hours\n",
      "|    Epoch Start  2018-11-01 21:18:00\n",
      "|    Epoch End    2018-11-03 02:42:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018306_msis2.DRIA_alpha85_scaled_\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.306\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.306.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/msis2/msis2_DRIA_nov/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #2          Running IIS\n",
      "Run #2          No errors in IIS\n",
      "Run #2 ---------End of IIS\n",
      "\n",
      "Run #2          Running IIE\n",
      "Run #2          Current Time = 10:53:35 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/msis2_DRIA_nov/icesat2_2018306_msis2.DRIA_alpha85_scaled_\n",
      "Run #2          No errors in IIE\n",
      "Run #2 ---------End of IIE\n",
      "Run #2          Time of IIE:  405.31725692749023 secs ( 6.755287615458171  mins)\n",
      "Run #2          Current Time = 18:00:21\n",
      "Saving fort.103 as drag_file\n",
      "Saving fort.104 as SatGeometry_file\n",
      "Run #2                Finished renaming files\n",
      "Run #2                Finished copying files to outputdir\n",
      "        Deleting tmp/:  /data/SatDragModelValidation/data/tmp/msis2_DRIA_nov\n",
      "hours_between_cd_adj 3\n",
      "     drag card date  0   181103000000\n",
      "     drag card date  1   181103030000\n",
      "     drag card date  2   181103060000\n",
      "     drag card date  3   181103090000\n",
      "     drag card date  4   181103120000\n",
      "     drag card date  5   181103150000\n",
      "     drag card date  6   181103180000\n",
      "     drag card date  7   181103210000\n",
      "     drag card date  8   181104000000\n",
      "     drag card date  9   181104024200\n",
      "Run #3     Current Time =      11:00:24  GMT-7\n",
      "Run #3\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "| Run #3 Parameters\n",
      "| —————————————————\n",
      "|  Run Specs\n",
      "|  --------- \n",
      "|    Satellite    icesat2\n",
      "|    Run Type     DataReduction_PCE\n",
      "|    CD Type      Fixed_CD\n",
      "|    CD Value     1.0\n",
      "|    Density      msis2\n",
      "|\n",
      "|  Epoch Info \n",
      "|  ---------- \n",
      "|    Arc          2018.307\n",
      "|    Arc length   29.4 hours\n",
      "|    Epoch Start  2018-11-02 21:18:00\n",
      "|    Epoch End    2018-11-04 02:42:00\n",
      "|    Step Size    10.0 seconds\n",
      "|\n",
      "|  Files Info\n",
      "|  ---------- \n",
      "|    Arc Name    icesat2_2018307_msis2.DRIA_alpha85_scaled_\n",
      "|\n",
      "|    IISSET      .../data/inputs/sat_icesat2/setups/iisset.2018.307\n",
      "|    EXAT        .../data/inputs/sat_icesat2/external_attitude/EXAT01.2018.307.gz\n",
      "|    Output Raw  .../data/outputs_raw/icesat2/msis2/msis2_DRIA_nov/\n",
      "|\n",
      "|————————————————————————————————————————————————————————————————————————————————\n",
      "\n",
      "Run #3          Running IIS\n",
      "Run #3          No errors in IIS\n",
      "Run #3 ---------End of IIS\n",
      "\n",
      "Run #3          Running IIE\n",
      "Run #3          Current Time = 11:00:51 GMT-7\n",
      " ------ Current DIR:  /data/SatDragModelValidation/data/tmp/msis2_DRIA_nov/icesat2_2018307_msis2.DRIA_alpha85_scaled_\n",
      "ERRORS FOUND IN IIE: /data/SatDragModelValidation/data/tmp/msis2_DRIA_nov/icesat2_2018307_msis2.DRIA_alpha85_scaled_/iieerr\n",
      "Run #3          Time of IIE:  1.6338245868682861 secs ( 0.027230409781138103  mins)\n",
      "At line 62 of file OBSIO.f90 (unit = 12, file = 'ftn12')\n",
      "Fortran runtime error: Unformatted file structure has been corrupted\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Ending program... Errors found in iieout file.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Ending program... Errors found in iieout file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from gc import collect as gc_collect\n",
    "import pickle \n",
    "import os\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "\n",
    "g2b_path = \"/data/SatDragModelValidation/data/inputs/sat_icesat2/g2b/\"\n",
    "dir_save    =  '/data/SatDragModelValidation/data/outputs_clean/'\\\n",
    "             + 'icesat2/O2R2023_longimeperiod/1_DRIAruns/'\n",
    "\n",
    "\n",
    "\n",
    "obj = {}\n",
    "\n",
    "for imonth,month in enumerate(month_list):\n",
    "    if month=='oct':\n",
    "        y_num = 2018\n",
    "        m_num = 10\n",
    "    if month=='nov':\n",
    "        y_num = 2018\n",
    "        m_num = 11\n",
    "    if month=='dec':\n",
    "        y_num = 2018\n",
    "        m_num = 12\n",
    "    if month=='jan':\n",
    "        y_num = 2019\n",
    "        m_num = 1\n",
    "    if month=='feb':\n",
    "        y_num = 2019\n",
    "        m_num = 2\n",
    "    if month=='mar':\n",
    "        y_num = 2019\n",
    "        m_num = 3\n",
    "    if month=='apr':\n",
    "        y_num = 2019\n",
    "        m_num = 4\n",
    "    file_raw_ICs = f\"{g2b_path}ICESat2_RawEphem_{y_num}_{m_num:02d}.txt\"\n",
    "    file_g2b     = f\"pce_icesat2_pso_{y_num}_{m_num:02d}\"\n",
    "\n",
    "    input_arcs       = []\n",
    "    input_epochstart = []\n",
    "    input_epochstop  = []\n",
    "    arc_length = []\n",
    "    scaleparameter_times = []\n",
    "    \n",
    "    for i,val in enumerate(arcs_yyyyddd):\n",
    "        if pd.to_datetime(val[:8],format=\"%Y.%j\").month == m_num:\n",
    "            epoch_delta  =  pd.to_timedelta(pd.to_datetime(epochstop[i]) - pd.to_datetime(epochstart[i]), 'hours')\n",
    "            arc_length.append(epoch_delta.total_seconds()/3600)\n",
    "\n",
    "            if val[8:] == 'A' or val[8:] == 'B':\n",
    "#                 input_arcs.append(      arcs_yyyyddd[i])\n",
    "#                 input_epochstart.append(epochstart[i])\n",
    "#                 input_epochstop.append( epochstop[i])\n",
    "#                 scaleparameter_times.append([''])\n",
    "                pass\n",
    "            else:\n",
    "                ### use 24-hour start/stop\n",
    "                # input_arcs.append(      arcs_yyyyddd[i])\n",
    "                # input_epochstart.append(str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\")))\n",
    "                # input_epochstop.append( str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\")+ pd.to_timedelta(24,'h')))\n",
    "                \n",
    "                ### Use Arc text file times\n",
    "                input_arcs.append(      arcs_yyyyddd[i])\n",
    "                input_epochstart.append(epochstart[i])\n",
    "                input_epochstop.append( epochstop[i])\n",
    "                scalestart = str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\"))\n",
    "                scalestop  = str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\") + pd.to_timedelta(24,'h'))\n",
    "                scaletimes = pd.date_range(start = pd.to_datetime(scalestart),\n",
    "                                                          end   = pd.to_datetime(scalestop ),\n",
    "                                                          freq=str(scale_cadence)+\"H\")\n",
    "\n",
    "                ###append the epoch end time to the end\n",
    "                add_epochend = np.append(scaletimes.values.astype(np.int64) // 10 ** 9,\n",
    "                              pd.to_datetime(pd.Series(epochstop[i])).values.astype(np.int64) // 10 ** 9)\n",
    "                scaleparameter_times.append([pd.to_datetime(datetime.strftime(datetime.fromtimestamp(ts), '%y%m%d%H%M%S.%f'),\n",
    "                    format ='%y%m%d%H%M%S.%f' )\n",
    "                                 for ts in add_epochend ])\n",
    "\n",
    "\n",
    "      \n",
    "    if month=='dec':\n",
    "        input_arcs       = input_arcs[:-1] \n",
    "        input_epochstart = input_epochstart[:-1] \n",
    "        input_epochstop  = input_epochstop[:-1] \n",
    "    \n",
    "#     for i,val in enumerate(input_arcs):\n",
    "#         print(f\" {input_arcs[i]:10}  , {input_epochstart[i]:20},  {input_epochstop[i]:20}, {arc_length[i]}\")\n",
    "#         if val[8:] == 'A' or val[8:] == 'B':\n",
    "#             print(\"\")\n",
    "\n",
    "#         else:\n",
    "#             print(f\" {'':10}  , {scaleparameter_times[i]}\")\n",
    "#             print(\"\")    \n",
    "    \n",
    "    for i,den in enumerate(run_list):\n",
    "        settings_icesat2= {# Basic input settings\n",
    "                     'satellite'      : {'input': 'icesat2'},\n",
    "                     'den_model'      : {'input': den},\n",
    "                     'run_type'       : {'input': 'DataReduction_PCE'},\n",
    "                     'run_specifier'  : {'input': '_'+month},\n",
    "                     'cd_model'       : {'input': 'DRIA'},\n",
    "                     'file_string'    : {'input': 'DRIA_alpha85_scaled_'},\n",
    "                     'model_data_path' : {'input': run_dict[month+den]['model_path']},\n",
    "                     # Force Model settings\n",
    "                      'cd_type'               : {'input':\"Fixed_CD\"},\n",
    "                      'cd_value'              : {'input':1.0 },\n",
    "                      'scaling_factor'        : {'input':True},\n",
    "                      'hours_between_cd_adj'  : {'input':scaling_cadence},\n",
    "                      #### Comment for unadjusted run:\n",
    "                      'cd_adjustment_boolean' : {'input':True },\n",
    "                    #### DRIA CD Model Parameters\n",
    "                    'cd_model_params' : {'input':{ \n",
    "                            'MS'     : '26.980D0'   ,  #!  molar mass for each panel (g/mol)\n",
    "                            'TW'     : '300.0D0'    ,  #!  temperature of panels  (K)\n",
    "                               ###  Alpha is b/w 0 and 1\n",
    "                            'ALPHA'  : '0.850D0'    ,  #!  accomodation coefficient\n",
    "                            'KL'     : '0.0D0'    ,    #!  langmuir parameter\n",
    "                            'FRACOX' : '1.0D0'   ,     #!  fraction of surface covered by atomic oxygen\n",
    "                       }},\n",
    "                      #### ---------------------------------------\n",
    "                     # Run\n",
    "                      'arc_type'       : {'input':'Nominal30hr_and_AB'},      \n",
    "                      'step'           : {'input': 10.},\n",
    "                      'orbfil_step'    : {'input': 120.},\n",
    "                      'which_ICfile'   : {'input':file_raw_ICs},\n",
    "                      'which_g2bfile'  : {'input':file_g2b},\n",
    "                        #\n",
    "                      'arc'            : {'input': input_arcs},\n",
    "                      'epoch_start'    : {'input': input_epochstart},\n",
    "                      'epoch_stop'     : {'input': input_epochstop},  \n",
    "                'scaleparameter_times' : {'input': scaleparameter_times},  \n",
    "                       #                                \n",
    "                      'global_options' : {'input':'pso_2018'},\n",
    "                     # Request read on raw outputs\n",
    "                      'request_data'   : {'input': ['Trajectory_orbfil', \n",
    "                                                   'Density', \n",
    "                                                   'Residuals_summary',\n",
    "                                                   'DragFile',\n",
    "                                                   'AdjustedParams'\n",
    "                                                   ]},\n",
    "                  #end dict\n",
    "                  }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        sat = Pygeodyn(settings_icesat2, use_file=False)\n",
    "        sat.run_arcs()\n",
    "#         obj[month+den] =  sat.getData_BigData_lowmemory(orbit_propagation=False)\n",
    "#         obj[month+den] = vars(obj[month+den])\n",
    "        gc_collect()\n",
    "\n",
    "\n",
    "        pickleName = f'_{month}_DRIA_alpha85_scale{scale_cadence}.pkl'\n",
    "\n",
    "        pickle_file = dir_save+den+pickleName\n",
    "        if not os.path.exists(pickle_file):\n",
    "            print('Must create pickle file...')\n",
    "            print('   ',  pickle_file)\n",
    "            print('   ', 'Reading Geodyn Data')\n",
    "\n",
    "            ### Load the data into an object\n",
    "            sat = Pygeodyn(settings_icesat2, use_file=False)\n",
    "            obj = sat.getData_BigData_lowmemory(orbit_propagation=False)\n",
    "            gc_collect()\n",
    "\n",
    "            #### Pickle the object to save it\n",
    "            print('   ', 'Saving pickle')\n",
    "            filehandler = open(pickle_file, 'wb') \n",
    "            pickle.dump(vars(obj), filehandler)\n",
    "            filehandler.close()\n",
    "            obj = 0\n",
    "            print('   ', 'Saved pickle')\n",
    "\n",
    "obj = {}\n",
    "for i,model in enumerate(run_list):\n",
    "    for imonth,month in enumerate(month_list):\n",
    "        pickleName = f'_{month}_DRIA_alpha85_scale{scale_cadence}.pkl'\n",
    "\n",
    "        ### Load the data if the pickles exist\n",
    "        print()\n",
    "        print()\n",
    "        gc_collect()\n",
    "\n",
    "        pickle_file = dir_save+model+pickleName\n",
    "\n",
    "        filehandler = open(pickle_file, 'rb') \n",
    "        obj[month+model] = pickle.load(filehandler)\n",
    "        filehandler.close()\n",
    "        print('Loaded data from pickle... ',  model)\n",
    "    \n",
    "    \n",
    "### Save space if doing density retrieval\n",
    "for model in run_dict.keys():\n",
    "    del obj[model]['OrbitResids']\n",
    "    del obj[model]['Trajectory_orbfil']\n",
    "    \n",
    "gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb35c09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T17:41:19.974589Z",
     "start_time": "2024-01-23T17:41:19.959912Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32ab2ec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T16:29:28.674412Z",
     "start_time": "2023-10-27T16:29:28.533557Z"
    }
   },
   "source": [
    "### geodyn output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6e024",
   "metadata": {},
   "source": [
    "## Plot Settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00410a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.719127Z",
     "start_time": "2024-04-23T17:45:37.992Z"
    }
   },
   "outputs": [],
   "source": [
    "from pygeodyn.pygeodyn_plot_scalingfactors import *\n",
    "\n",
    "coldict = {}\n",
    "coldict['msis2']     = \"#2ca02c\"  # 'tab:green'\n",
    "coldict['dtm2020_o'] = \"#d62728\"  # 'tab:red'\n",
    "coldict['jb2008']    = \"orange\"   \n",
    "coldict['hasdm_oc']  = \"#1f77b4\"     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92187f04",
   "metadata": {},
   "source": [
    "## Plot densities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31c84a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T17:42:06.020388Z",
     "start_time": "2024-01-23T17:42:04.754Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58cde652",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T17:42:06.021132Z",
     "start_time": "2024-01-23T17:42:04.757Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "### Plot Kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f14fb17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.720152Z",
     "start_time": "2024-04-23T17:45:37.996Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# from pygeodyn.pygeodyn_plot_scalingfactors import *\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from netCDF4 import Dataset\n",
    "# def read_nc_file( filename, variables):\n",
    "#     ''' This function reads the TIEGCM .nc files and saves the given input variables to a dictionary.\n",
    "#         The breakloop feature is here so that if the file doesn't exist the code can still continue.  '''\n",
    "#     status = os.path.exists(filename)\n",
    "    \n",
    "#     if status == True:\n",
    "#         data = {}\n",
    "#         for i, var_names in enumerate(variables):\n",
    "#             ncid =  Dataset(filename,\"r+\", format=\"NETCDF4\")# filename must be a string\n",
    "#             varData = ncid.variables\n",
    "#             data[var_names] = np.array(varData[var_names])  \n",
    "#     elif status == False:\n",
    "#         print('No File Found', filename )\n",
    "#         breakloop = True\n",
    "#         data = 0\n",
    "#         return( data , breakloop)\n",
    "#     breakloop = False\n",
    "#     return(data,breakloop )\n",
    "\n",
    "\n",
    "# arc_list = []\n",
    "\n",
    "# arc_list_18 = np.arange(280,366)\n",
    "# for i in arc_list_18:\n",
    "#     val = '2018'+str(i)\n",
    "#     arc_list.append(int(val))\n",
    "    \n",
    "#     #     print(val)\n",
    "    \n",
    "# arc_list_19 = np.arange(1,112)\n",
    "# for i in arc_list_19:\n",
    "#     val = f\"2019{i:03d}\"\n",
    "#     arc_list.append(int(val))\n",
    "\n",
    "\n",
    "# path_to_f107 = '/data/SatDragModelValidation/data/inputs/atmos_models/geo_phys_indicies/gpi_1960001-2021243_f107aDaily.nc'\n",
    "\n",
    "# f107_data = read_nc_file(path_to_f107, ['year_day', 'f107d', 'f107a', 'kp'])\n",
    "\n",
    "# date = []\n",
    "# kp_list = []\n",
    "# f107d_list = []\n",
    "# f107a_list  = []\n",
    "# date_3hr = []\n",
    "# doy_list    = []\n",
    "\n",
    "\n",
    "\n",
    "# for i,val in enumerate(arc_list):\n",
    "    \n",
    "#     index = f107_data[0]['year_day']==val\n",
    "#     kp_list.append(f107_data[0]['kp'][index][0])\n",
    "#     f107d_list.append(f107_data[0]['f107d'][index][0])\n",
    "#     f107a_list.append(f107_data[0]['f107a'][index][0])\n",
    "#     doy_list.append(str(f107_data[0]['year_day'][index][0])[-3:])\n",
    "\n",
    "#     date.append(pd.to_datetime( str(val), format='%Y%j'))\n",
    "\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=0))\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=3))\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=6))\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=9))\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=12))\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=15))\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=18))\n",
    "#     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=21))\n",
    "# #     date_3hr.append(pd.to_datetime( str(val), format='%Y%j') +pd.Timedelta(hours=24))\n",
    "    \n",
    "# kp_expand = []\n",
    "# for i in kp_list:\n",
    "#     for ii in i:\n",
    "#         kp_expand.append(ii)\n",
    "        \n",
    "        \n",
    "        \n",
    "# solar_fluxes = {}\n",
    "# solar_fluxes['f107d_list'] = f107d_list\n",
    "# solar_fluxes['f107a_list'] = f107a_list\n",
    "# solar_fluxes['date']       = date\n",
    "# solar_fluxes['date_3hr']   = date_3hr\n",
    "# solar_fluxes['kp_expand']  = kp_expand\n",
    "\n",
    "# f107d_earth = []\n",
    "# f107a_earth = []\n",
    "# ######################################################################### \n",
    "# ##### Account for the F10.7 at earth (instead of referenced at 1AU) #####\n",
    "# ######################################################################### \n",
    "\n",
    "# for i_doy,val_doy in enumerate(doy_list):\n",
    "#     iday = int(val_doy)\n",
    "#     theta0 = 2 * np.pi * (iday)/365.\n",
    "#     sfeps = 1.000110 + 0.034221*np.cos(theta0)+0.001280* np.sin(theta0) +0.000719*np.cos(2.*theta0)+0.000077*np.sin(2.*theta0)\n",
    "\n",
    "#     f107d_earth.append(sfeps * solar_fluxes['f107d_list'][i_doy])\n",
    "#     f107a_earth.append(sfeps * solar_fluxes['f107a_list'][i_doy])\n",
    "\n",
    "# solar_fluxes['f107d_earth'] = f107d_earth\n",
    "# solar_fluxes['f107a_earth'] = f107a_earth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig = make_subplots(rows=2, cols=1,\n",
    "#                     vertical_spacing = 0.05,\n",
    "#                     shared_xaxes=True)\n",
    "\n",
    "\n",
    "# index1 = 21\n",
    "# index2 = 37\n",
    "# index3h_1 = 168\n",
    "# index3h_2 = 289\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=solar_fluxes['date'],\n",
    "#                            y=solar_fluxes['f107d_earth'],\n",
    "#                            name= 'F107d_1AU',\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "# #                                marker=dict(color='cornflowerblue', size=2 ),\n",
    "#                            line = dict(shape = 'hvh',dash='dash', color = 'black', width=2),\n",
    "#                            showlegend=False),\n",
    "#                            secondary_y=False,row=1, col=1)\n",
    "# fig.add_trace(go.Scatter(x=solar_fluxes['date'],\n",
    "#                            y=solar_fluxes['f107a_earth'],\n",
    "#                            name= 'F107a_1AU',\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "# #                                marker=dict(color='cornflowerblue', size=2 ),\n",
    "#                            line = dict(shape = 'hvh', color = 'black', width=2),\n",
    "#                            showlegend=False),\n",
    "#                            secondary_y=False,row=1, col=1)\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=solar_fluxes['date_3hr'],\n",
    "#                            y=solar_fluxes['kp_expand'],\n",
    "#                            name= 'Kp',\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "# #                                marker=dict(color='black',size=2),\n",
    "#                            line = dict(shape = 'hvh', color = 'black', width=2),\n",
    "#                            showlegend=False),\n",
    "#                            secondary_y=False,row=2, col=1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# #######################################################\n",
    "# font_dict=dict(family='Arial',size=16,color='black')\n",
    "# #######################################################\n",
    "\n",
    "# fig.update_yaxes(title_text=r\"$\\text{F}_{\\text{10.7}}\\text{ Solar Flux (sfu)}$\", \n",
    "# #                  color='black',\n",
    "# #                  range=[64.5, 86],\n",
    "#                   row=1, col=1,)\n",
    "\n",
    "# fig.update_yaxes(title_text=r\"$\\text{K}_\\text{p}\\text{ Index}$\",\n",
    "# #                   range=[-0.3, 8],\n",
    "#                  row=2, col=1,)\n",
    "\n",
    "   \n",
    "# font_dict=dict(family='Arial',size=11,color='black')\n",
    "# ## automate the specification of the axes for subplots\n",
    "# rownum, colnum = fig._get_subplot_rows_columns()\n",
    "# for i in rownum:\n",
    "#     if len(rownum)==1:\n",
    "#         L_ticklabel = True\n",
    "#     else:\n",
    "#         if i < len(rownum):\n",
    "#             L_ticklabel = True\n",
    "#         else:\n",
    "#             L_ticklabel = True\n",
    "#     fig.update_xaxes(### LINE at axis border\n",
    "#                       showline=True,\n",
    "#                       showticklabels=L_ticklabel,\n",
    "# #                       tickformat= '%m/%d',\n",
    "#                       linecolor='black',\n",
    "#                       linewidth=1,\n",
    "#                      ### Major ticks\n",
    "#                       ticks='inside',\n",
    "#                       tickfont=font_dict,\n",
    "#                       mirror=True,\n",
    "# #                       tickwidth=2,\n",
    "# #                       ticklen=9,\n",
    "#                       tickcolor='grey',\n",
    "# #                       tick0=\"2018-11-9\" ,\n",
    "# #                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "#                       #### Minor Ticks\n",
    "#                        minor=dict(\n",
    "#                          dtick=86400000.0, # milliseconds in a day\n",
    "#                          tickwidth=1,\n",
    "#                          ticklen=4,\n",
    "#                          tickcolor='grey',\n",
    "#                          ticks='inside'),\n",
    "#                       ### GRID\n",
    "#                        gridcolor='gainsboro',\n",
    "#                        gridwidth=1,\n",
    "#                        layer='above traces',\n",
    "#                        tickangle=0,\n",
    "#                        row=i, col=1)\n",
    "#     fig.update_yaxes(showline=True,      # add line at x=0\n",
    "#                          showticklabels=True,\n",
    "#                          linecolor='black',  # line color\n",
    "#                          linewidth=1,        # line size\n",
    "#                      ticks='inside',     # ticks outside axis\n",
    "#                      tickfont=font_dict, # tick label font\n",
    "#                      mirror='allticks',  # add ticks to top/right axes\n",
    "#                      tickwidth=1,      # tick width\n",
    "#                      tickcolor='black',  # tick color\n",
    "#                      gridcolor='gainsboro',\n",
    "#                      gridwidth=1,\n",
    "#                      layer='above traces',\n",
    "#                      row=i, col=1)\n",
    "\n",
    "\n",
    "# fig.update_layout(autosize=False,    width=1000,    height=500,\n",
    "#                   legend= {'itemsizing': 'trace'},\n",
    "#                   font=font_dict, plot_bgcolor='white', \n",
    "#                  )\n",
    "# fig.update_annotations(font_size=14)  # Increase size of subplot title\n",
    "# fig.show(#renderer=\"jpg\",\n",
    "#          config=config)\n",
    "\n",
    "# ### pio.write_image(fig, plots_dir+'twoweek_fullresult.pdf')\n",
    "# # pio.write_image(fig, plots_dir+'f107_kp_twoweek.jpg', scale=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b705aa85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T17:30:35.237040Z",
     "start_time": "2024-01-18T17:30:35.028228Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0853c097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.721990Z",
     "start_time": "2024-04-23T17:45:38.000Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# obj[model]['Statistics']#['T_RMS'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9107d58e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eb2347",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d74d2959",
   "metadata": {},
   "source": [
    "### original scaling (no ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ec9be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.724009Z",
     "start_time": "2024-04-23T17:45:38.004Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "# satid = 1807001\n",
    "# for plot_num, model in enumerate(run_list):\n",
    "#     for imonth,month in enumerate(month_list):\n",
    "#         print(model,month)\n",
    "\n",
    "    \n",
    "#         ScalingFactors      = []\n",
    "#         ScalingFactor_times = []\n",
    "#         PercChange          = []\n",
    "\n",
    "#         for ii,arc in enumerate(obj[month+model]['global_params']['arc_input']):\n",
    "# #             print()\n",
    "#             epochstart = obj[month+model]['global_params']['prms']['epoch_start'][ii]\n",
    "#             hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "#             frachours =(hrs/24)\n",
    "#             #\n",
    "#             if len(arc) == 9:\n",
    "#                 maneuv_indicator = arc[8]\n",
    "#             else:\n",
    "#                 maneuv_indicator = ''\n",
    "#             arc_type = obj[month+model]['global_params']['prms']['arc_type']\n",
    "#             if arc_type == \"Nominal30hr_and_AB\":\n",
    "#                 arc_name =arc[:8]+ maneuv_indicator\n",
    "#             else:\n",
    "#                 arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "\n",
    "\n",
    "#             iters = int(obj[month+model]['run_parameters'+arc_name]['total_iterations'])\n",
    "#             for iit, itime in enumerate(obj[month+model]['AdjustedParams'][arc_name][iters][satid]['0CD'].keys()):\n",
    "#                 if iit == 0 or iit==9:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     CURRENT_VALUE = obj[month+model]['AdjustedParams'][arc_name][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "#                     APRIORI_VALUE = obj[month+model]['AdjustedParams'][arc_name][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "#                     ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "#                     ScalingFactor_times.append(itime) \n",
    "#                     PercChange.append(calc_percent_change(APRIORI_VALUE, CURRENT_VALUE))\n",
    "#     #                 print(itime,CURRENT_VALUE )\n",
    "\n",
    "#         run_dict[month+model]['ScalingFactor_times'] = ScalingFactor_times\n",
    "#         run_dict[month+model]['ScalingFactors']      = ScalingFactors\n",
    "#         run_dict[month+model]['percent_change']      = PercChange\n",
    "\n",
    "    \n",
    "    \n",
    "# #### SCALE THE DENSITIES:\n",
    "\n",
    "# models_dens = {}\n",
    "# for monthmodel in run_dict.keys():\n",
    "#     print(model)\n",
    "#     models_dens[monthmodel] = get_continuous_scaled_densities(obj, run_dict, monthmodel, scale_cadence)\n",
    "\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f7c83",
   "metadata": {},
   "source": [
    "# fixing scaling with ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5d41f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T21:51:26.018091Z",
     "start_time": "2024-01-22T21:51:26.000088Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402d2b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.724873Z",
     "start_time": "2024-04-23T17:45:38.009Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# def calc_rho_ScaledEnsembleWgtAvg(OBJECT, model_dict, model_fill, scale_cadence):\n",
    "    \n",
    "#     \"\"\"REDO THIS USING THE SCALED DENSITY DICT FROM THE ABOVE\"\"\"\n",
    "\n",
    "\n",
    "#     dates   = []\n",
    "#     rho_scaledEnsembleAvg = []\n",
    "#     std_scaledEnsembleAvg = []\n",
    "#     list_lat = []\n",
    "\n",
    "#     # i_countfactor = 0\n",
    "\n",
    "#     # for ii,arc in enumerate(OBJECT[model_fill]['global_params']['arc_input']):\n",
    "\n",
    "#     #     epochstart = OBJECT[model_fill]['global_params']['prms']['epoch_start'][ii]\n",
    "#     #     epochstop  = OBJECT[model_fill]['global_params']['prms']['epoch_stop'][ii]\n",
    "#     #     hrs        = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "#     #     frachours  =(hrs/24)\n",
    "#     #     #\n",
    "#     #     arc_name =arc+('%.3f'%frachours).lstrip('0')\n",
    "\n",
    "#     for ii,arc in enumerate(OBJECT[model_fill]['global_params']['arc_input']):\n",
    "#         epochstart = OBJECT[model_fill]['global_params']['prms']['epoch_start'][ii]\n",
    "#         hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "#         frachours =(hrs/24)\n",
    "#         #\n",
    "#         if len(arc) == 9:\n",
    "#             maneuv_indicator = arc[8]\n",
    "#         else:\n",
    "#             maneuv_indicator = ''\n",
    "#         arc_type = OBJECT[model_fill]['global_params']['prms']['arc_type']\n",
    "#         if arc_type == \"Nominal30hr_and_AB\":\n",
    "#             arc_name =arc[:8]+ maneuv_indicator\n",
    "#         else:\n",
    "#             arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "\n",
    "#         start_arc = OBJECT[model_fill]['run_parameters'+arc_name]['prms_arc']['scaleparameter_times'][0]\n",
    "#         end_arc   = OBJECT[model_fill]['run_parameters'+arc_name]['prms_arc']['scaleparameter_times'][-1]\n",
    "\n",
    "#         #\n",
    "#         # start_arc  = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S') + pd.to_timedelta(scale_cadence,'h')\n",
    "#         # end_arc   = pd.to_datetime(epochstop, format='%Y-%m-%d %H:%M:%S') - pd.to_timedelta(scale_cadence,'h')\n",
    "\n",
    "        \n",
    "# #         epochstart = OBJECT[model_fill]['global_params']['prms']['epoch_start'][ii]\n",
    "# #         hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "# #         frachours =(hrs/24)\n",
    "        \n",
    "# #         arc_name =arc+('%.3f'%frachours).lstrip('0')\n",
    "# #         start_arc = pd.to_datetime(arc, format='%Y.%j')\n",
    "# #         end_arc = pd.to_datetime(arc, format='%Y.%j')+ pd.to_timedelta(24,'h')\n",
    "# #         print('arc',arc)\n",
    "# #         print('start_arc', start_arc)\n",
    "# #         print('end_arc', end_arc)\n",
    "# #         print()\n",
    "#         ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "#         A = OBJECT[model_fill]['Density'][arc_name].query( \\\n",
    "#                 f\"{start_arc.year}\"         \\\n",
    "#                +f\"{start_arc.month:02d}\"    \\\n",
    "#                +f\"{start_arc.day:02d}\"      \\\n",
    "#                +f\"{start_arc.hour:02d}\"     \\\n",
    "#                +f\"{start_arc.minute:02d}\"   \\\n",
    "#                +f\"{start_arc.second:02d}\"   \\\n",
    "#                +f\" <= Date < \"                     \\\n",
    "#                +f\"{end_arc.year}\"       \\\n",
    "#                +f\"{end_arc.month:02d}\"  \\\n",
    "#                +f\"{end_arc.day:02d}\"    \\\n",
    "#                +f\"{end_arc.hour:02d}\"   \\\n",
    "#                +f\"{end_arc.minute:02d}\" \\\n",
    "#                +f\"{end_arc.second:02d}\" \\\n",
    "#             )\n",
    "#         len_dates = np.shape(A['rho (kg/m**3)'])[0]\n",
    "\n",
    "#         ### Loop thru all dates of interest in this arc\n",
    "#         ###   for each date we will make a list of rho, lats, wgts for each model\n",
    "#         for it in np.arange(0,len_dates):\n",
    "#             list_it_models = []\n",
    "#             list_it_lat    = []\n",
    "#             wgts           = []\n",
    "\n",
    "\n",
    "#             for model in model_dict.keys():\n",
    "#                 # print(A)\n",
    "#                 A = OBJECT[model]['Density'][arc_name].query( \\\n",
    "#                     f\"{start_arc.year}\"         \\\n",
    "#                    +f\"{start_arc.month:02d}\"    \\\n",
    "#                    +f\"{start_arc.day:02d}\"      \\\n",
    "#                    +f\"{start_arc.hour:02d}\"     \\\n",
    "#                    +f\"{start_arc.minute:02d}\"   \\\n",
    "#                    +f\"{start_arc.second:02d}\"   \\\n",
    "#                    +f\" <= Date < \"                     \\\n",
    "#                    +f\"{end_arc.year}\"       \\\n",
    "#                    +f\"{end_arc.month:02d}\"  \\\n",
    "#                    +f\"{end_arc.day:02d}\"    \\\n",
    "#                    +f\"{end_arc.hour:02d}\"   \\\n",
    "#                    +f\"{end_arc.minute:02d}\" \\\n",
    "#                    +f\"{end_arc.second:02d}\" \\\n",
    "#                 )\n",
    "\n",
    "                \n",
    "#                 if scale_cadence==24:\n",
    "#                     ## the 24-hour scaling uses the arc index to index the scaling factor since they have the same cadence\n",
    "#                     try:\n",
    "#                         list_it_models.append(A['rho (kg/m**3)'].iloc[it] \\\n",
    "#                                             *model_dict[model]['ScalingFactors'][ii])\n",
    "#                         list_it_lat.append(A['Lat'].iloc[it])\n",
    "#                         wgts.append(model_dict[model]['Weight'][arc_name])\n",
    "#                     except:\n",
    "#                         continue\n",
    "#             if scale_cadence ==24: \n",
    "#                 dates.append(A['Date'].iloc[it])\n",
    "#                 list_lat.append(np.average(list_it_lat))\n",
    "#             else:\n",
    "                \n",
    "#             # i_countfactor  = i_countfactor + 1\n",
    "\n",
    "#             # print(f\"  {arc} \")\n",
    "\n",
    "#             # print(\"list_it_models\",list_it_models)\n",
    "#             # print(\"wgts\",wgts)\n",
    "\n",
    "#             # weights are done on an arc-basis and do not depend on Scale Cadence\n",
    "#             x_bar_wgt  = np.average(list_it_models, weights=wgts)\n",
    "#             M = np.count_nonzero(wgts)\n",
    "#             rho_scaledEnsembleAvg.append(  x_bar_wgt   )    \n",
    "# #             std_scaledEnsembleAvg.append(  np.std(list_it_models)       )\n",
    "#             std_numerator  = sum([ wgts[i]*((list_it_models[i] - x_bar_wgt)**2) \\\n",
    "#                                                  for i in range(len(wgts)) ])\n",
    "#             std_denominator= ((M-1)/M)*sum(wgts)\n",
    "#             std_scaledEnsembleAvg.append(  np.sqrt( std_numerator/std_denominator) )\n",
    "\n",
    "#     return(dates, list_lat, rho_scaledEnsembleAvg, std_scaledEnsembleAvg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3a4ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.725657Z",
     "start_time": "2024-04-23T17:45:38.011Z"
    }
   },
   "outputs": [],
   "source": [
    "  \n",
    "satid = 1807001\n",
    "wgts = {}\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    wgts[model] = {}\n",
    "    ScalingFactors  = []\n",
    "    ScalingFactor_times = []\n",
    "\n",
    "    for ii,arc in enumerate(obj[model]['global_params']['arc_input']):\n",
    "        epochstart = obj[model]['global_params']['prms']['epoch_start'][ii]\n",
    "        hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "        frachours =(hrs/24)\n",
    "        #\n",
    "        if len(arc) == 9:\n",
    "            maneuv_indicator = arc[8]\n",
    "        else:\n",
    "            maneuv_indicator = ''\n",
    "        arc_type = obj[model]['global_params']['prms']['arc_type']\n",
    "        if arc_type == \"Nominal30hr_and_AB\":\n",
    "            arc_name =arc[:8]+ maneuv_indicator\n",
    "        else:\n",
    "            arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "        ### Collect the weights for the ensemble average\n",
    "        inv_rms          = 1/obj[model]['Statistics'][arc_name]['T_RMS'].values[0]\n",
    "        wgts[model][arc_name] = inv_rms#/sum_wgts\n",
    "\n",
    "        iters = int(obj[model]['run_parameters'+arc_name]['total_iterations']) \n",
    "        for iit, itime in enumerate(obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'].keys()):\n",
    "            if iit == 0 or iit==9:\n",
    "                pass\n",
    "            else:\n",
    "                CURRENT_VALUE = obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "                APRIORI_VALUE = obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "                ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "                ScalingFactor_times.append(itime)\n",
    "    run_dict[model]['ScalingFactor_times'] = ScalingFactor_times\n",
    "    run_dict[model]['ScalingFactors']      = ScalingFactors\n",
    "    run_dict[model]['Weight'] = wgts[model]\n",
    "    \n",
    "\n",
    "    \n",
    "###### SCALE THE DENSITIES:\n",
    "models_dens = {}\n",
    "for monthmodel in run_dict.keys():\n",
    "    print(f\"---Making continuous scaled rho for {monthmodel}\")\n",
    "    models_dens[monthmodel] = get_continuous_scaled_densities(obj, run_dict, monthmodel, scale_cadence)\n",
    "\n",
    "\n",
    "## Retrieve scaled ensemble weighted average\n",
    "##     'Rho_x' denotes the ensemble weighted avg\n",
    "\n",
    "models_dens =  calc_rho_ScaledEnsembleWgtAvg(models_dens,run_dict, scale_cadence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc967a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.726494Z",
     "start_time": "2024-04-23T17:45:38.014Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def PLOT_retrievedRHO(fig, obj_m1, den_dict, model_dict):\n",
    "        \n",
    "    model_m1 = obj_m1['global_params']['prms']['den_model']\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=pd.to_datetime(model_dict['ScalingFactor_times'])-pd.to_timedelta(scale_cadence/2, 'h'),\n",
    "                               y=model_dict['ScalingFactors'],\n",
    "                               name= model,\n",
    "                               mode='markers',\n",
    "                               opacity=1,\n",
    "#                                    marker=dict(color=coldict[model_m1], \n",
    "#                                                size=5,\n",
    "#                                                symbol='line-ew',\n",
    "#                                                line = dict(color = coldict[model_m1], width=3)), #symbol='diamond-wide'),\n",
    "                                   marker=dict(color=coldict[model_m1], size=5),\n",
    "                               line = dict(shape = 'hvh',dash ='dot', color = coldict[model_m1], width=1),\n",
    "                               showlegend=False),\n",
    "                               secondary_y=False,row=1, col=1)\n",
    "\n",
    "    \n",
    "    time_avg,dscale_avg = orbit_avg_generic(den_dict['dates'], den_dict['denscaled'], den_dict['lat'])\n",
    "    ## -----------------------------------------------------------------------------------------------------\n",
    "    ##     Orbit Averaged Density\n",
    "    fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                               y=dscale_avg,\n",
    "                               ### name= model_m1,\n",
    "                               mode='markers+lines',\n",
    "                               opacity=1,\n",
    "                                   marker=dict(color=coldict[model_m1],size=2),\n",
    "                                   line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "                               showlegend=False), row=2, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "             \n",
    "    return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig  = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    vertical_spacing = 0.05,\n",
    "    shared_xaxes=True)\n",
    "\n",
    "\n",
    "\n",
    "# run_dict = { }\n",
    "# rms_total_return = {}\n",
    "\n",
    "for model in run_dict.keys():\n",
    "#     for imonth,month in enumerate(month_list):\n",
    "\n",
    "    fig = PLOT_retrievedRHO(fig, obj[model],   models_dens[model], run_dict[model])\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "time_avg,Rho_x = orbit_avg_generic(models_dens['novRho_x']['dates'],\n",
    "                                        models_dens['novRho_x']['Rho_x'],\n",
    "                                        models_dens['novRho_x']['lat'])\n",
    "\n",
    "time_avg,Rho_std = orbit_avg_generic(models_dens['novRho_x']['dates'],\n",
    "                                        models_dens['novRho_x']['Rho_std'],\n",
    "                                        models_dens['novRho_x']['lat'])\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                           y=Rho_x,\n",
    "                           ### name= model_m1,\n",
    "                           mode='markers+lines',\n",
    "                           opacity=1,\n",
    "                           marker=dict(color='black',size=5),\n",
    "                               line = dict( dash ='solid', color = 'black', width=4),\n",
    "                           showlegend=False), row=2, col=1)\n",
    "### ERRROR BARS\n",
    "fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                           y=np.array(Rho_x)\\\n",
    "                               +np.array(Rho_std),\n",
    "                           ### name= model_m1,\n",
    "                           mode='lines',\n",
    "                           opacity=.8,\n",
    "                               line = dict( dash ='dash', color = 'grey', width=3),\n",
    "                           showlegend=False), row=2, col=1)\n",
    "fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                           y=np.array(Rho_x)\\\n",
    "                              -np.array(Rho_std),\n",
    "                           ### name= model_m1,\n",
    "                           mode='lines',\n",
    "                           opacity=.8,\n",
    "                               line = dict( dash ='dash', color = 'grey', width=3),\n",
    "                           showlegend=False), row=2, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=11,color='black')\n",
    "## automate the specification of the axes for subplots\n",
    "rownum, colnum = fig._get_subplot_rows_columns()\n",
    "for i in rownum:\n",
    "    if len(rownum)==1:\n",
    "        L_ticklabel = True\n",
    "    else:\n",
    "        if i < len(rownum):\n",
    "            L_ticklabel = True\n",
    "        else:\n",
    "            L_ticklabel = True\n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,\n",
    "                      showticklabels=L_ticklabel,\n",
    "#                       tickformat= '%m/%d',\n",
    "                      linecolor='black',\n",
    "                      linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',\n",
    "                      tickfont=font_dict,\n",
    "                      mirror=True,\n",
    "#                       tickwidth=2,\n",
    "#                       ticklen=9,\n",
    "                      tickcolor='grey',\n",
    "#                       tick0=\"2018-11-9\" ,\n",
    "#                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(\n",
    "                         dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,\n",
    "                         ticklen=4,\n",
    "                         tickcolor='grey',\n",
    "                         ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',\n",
    "                       gridwidth=1,\n",
    "                       layer='above traces',\n",
    "                       tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                         showticklabels=True,\n",
    "                         linecolor='black',  # line color\n",
    "                         linewidth=1,        # line size\n",
    "                     ticks='inside',     # ticks outside axis\n",
    "                     tickfont=font_dict, # tick label font\n",
    "                     mirror='allticks',  # add ticks to top/right axes\n",
    "                     tickwidth=1,      # tick width\n",
    "                     tickcolor='black',  # tick color\n",
    "                     gridcolor='gainsboro',\n",
    "                     gridwidth=1,\n",
    "                     layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Scaling Factor\", \n",
    "                     exponentformat= 'power',row=1, col=1)\n",
    "\n",
    "#     yaxis_range = [-13.7 -.55 ,  -12.6+.25]# ] #full_fig.layout.yaxis2.range\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Scaled Density\", \n",
    "                     type=\"log\", \n",
    "#                       range=yaxis_range,\n",
    "                     exponentformat= 'power',row=2, col=1)\n",
    "#     fig.update_yaxes(title_text=\"CD*A\", \n",
    "# #                       type=\"log\", \n",
    "# #                       range=yaxis_range,\n",
    "#                      exponentformat= 'power',row=3, col=1)\n",
    "    \n",
    "a='input'\n",
    "s=settings_icesat2\n",
    "\n",
    "fig.update_layout(title=f\"{s['cd_model'][a]}, {s['hours_between_cd_adj'][a]}-hr Scale from CD={s['cd_value'][a]}\",\n",
    "#                     title=f\"BWDRAG, 3-hr Scale from CD=2.5 \",\n",
    "                  autosize=False,    width=900,    height=700,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "fig.update_annotations(font_size=16)  # Increase size of subplot title\n",
    "fig.show(config=config)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b739b4",
   "metadata": {},
   "source": [
    "#### VIEW PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d554c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.727217Z",
     "start_time": "2024-04-23T17:45:38.017Z"
    }
   },
   "outputs": [],
   "source": [
    "from sys import exit as sysexit\n",
    "sysexit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373f9e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.728129Z",
     "start_time": "2024-04-23T17:45:38.021Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def PLOT_resids(fig, obj_m1, den_dict, model_dict):\n",
    "    \n",
    "    SHOW_alldata = False\n",
    "    \n",
    "    model_m1 = obj_m1['global_params']['prms']['den_model']\n",
    "    if model!='hasdm_oc':\n",
    "        opac_val = 1\n",
    "    else:\n",
    "        opac_val = 1\n",
    "\n",
    "    for ii,arc in enumerate(obj_m1['global_params']['arc_input']):\n",
    "        epochstart = obj_m1['global_params']['prms']['epoch_start'][ii]\n",
    "        hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "        frachours =(hrs/24)\n",
    "        #\n",
    "        if len(arc) == 9:\n",
    "            maneuv_indicator = arc[8]\n",
    "        else:\n",
    "            maneuv_indicator = ''\n",
    "        arc_type = obj_m1['global_params']['prms']['arc_type']\n",
    "        if arc_type == \"Nominal30hr_and_AB\":\n",
    "            arc_name =arc[:8]+ maneuv_indicator\n",
    "        else:\n",
    "            arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "        \n",
    "\n",
    "#         data_res = obj_m1['OrbitResids'][arc_name]['resids']\n",
    "\n",
    "        drag_data        = obj_m1['DragFile'][arc_name]\n",
    "        drag_data[\"Lat\"] = obj_m1['Density' ][arc_name]['Lat']\n",
    "#         den_df           = obj_m1['Density' ][arc_name]\n",
    "        \n",
    "#         print(arc[:8])\n",
    "        ### Cut off the extra time for the regular days\n",
    "        start_arc = pd.to_datetime(arc[:8], format='%Y.%j')\n",
    "        end_arc   = pd.to_datetime(arc[:8], format = '%Y.%j')+pd.to_timedelta(24, 'h')-pd.to_timedelta(1, 'm')\n",
    "\n",
    "#         print(f\" {arc_name:10}|   , {start_arc},  {end_arc}\")\n",
    "        \n",
    "        ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "        drag_data = drag_data.query( \\\n",
    "                f\"{start_arc.year}\"         \\\n",
    "               +f\"{start_arc.month:02d}\"    \\\n",
    "               +f\"{start_arc.day:02d}\"      \\\n",
    "               +f\"{start_arc.hour:02d}\"     \\\n",
    "               +f\"{start_arc.minute:02d}\"   \\\n",
    "               +f\"{start_arc.second:02d}\"   \\\n",
    "               +f\" <= Date < \"                     \\\n",
    "               +f\"{end_arc.year}\"       \\\n",
    "               +f\"{end_arc.month:02d}\"  \\\n",
    "               +f\"{end_arc.day:02d}\"    \\\n",
    "               +f\"{end_arc.hour:02d}\"   \\\n",
    "               +f\"{end_arc.minute:02d}\" \\\n",
    "               +f\"{end_arc.second:02d}\" \\\n",
    "            )\n",
    "        ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "#         den_df = den_df.query( \\\n",
    "#                 f\"{start_arc.year}\"         \\\n",
    "#                +f\"{start_arc.month:02d}\"    \\\n",
    "#                +f\"{start_arc.day:02d}\"      \\\n",
    "#                +f\"{start_arc.hour:02d}\"     \\\n",
    "#                +f\"{start_arc.minute:02d}\"   \\\n",
    "#                +f\"{start_arc.second:02d}\"   \\\n",
    "#                +f\" <= Date < \"                     \\\n",
    "#                +f\"{end_arc.year}\"       \\\n",
    "#                +f\"{end_arc.month:02d}\"  \\\n",
    "#                +f\"{end_arc.day:02d}\"    \\\n",
    "#                +f\"{end_arc.hour:02d}\"   \\\n",
    "#                +f\"{end_arc.minute:02d}\" \\\n",
    "#                +f\"{end_arc.second:02d}\" \\\n",
    "#             )\n",
    "\n",
    "\n",
    "        indplot=3\n",
    "\n",
    "#         date_rms.append(pd.to_datetime(datetime.datetime(int(arc.split('.')[0]), 1, 1) + datetime.timedelta(int(arc.split('.')[1]))- datetime.timedelta(hours=12) ))\n",
    "#         rms_totals.append(obj_m1['Statistics'][arc]['T_RMS'].values[0])\n",
    "\n",
    "#         iters = obj_m1['run_parameters'+arc_name]['total_iterations']\n",
    "#         for itime in obj_m1['AdjustedParams'][arc_string][iters][satid]['0CD']:\n",
    "#             date_scalefactor.append(itime)\n",
    "#             ScalingFactor.append(obj_m1['AdjustedParams'][arc_string][iters][satid]['0CD'][itime]['CURRENT_VALUE'])\n",
    "\n",
    "\n",
    "#         if SHOW_alldata:\n",
    "#         fig.add_trace(go.Scattergl(x=drag_data['Date'][::5],\n",
    "#                                    y=drag_data['CD']*drag_data['TOTAREA'][::5],\n",
    "#                                  mode='markers',\n",
    "#                                  opacity=1,\n",
    "#                                  marker=dict(color= coldict[model_m1],size=3,),\n",
    "#                                  showlegend=False,),\n",
    "#                                  secondary_y=False,\n",
    "#                                  row=3, col=1)\n",
    "        (time_avg, avg_cd ) = orbit_avg_generic(drag_data['Date'],drag_data['CD']*drag_data['TOTAREA'],drag_data['Lat'])    \n",
    "        fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                                 y=avg_cd,\n",
    "                           mode='lines',\n",
    "                           opacity=1,\n",
    "                               line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "                           showlegend=False), row=3, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    fig.add_trace(go.Scattergl(x=pd.to_datetime(model_dict['ScalingFactor_times'])-pd.to_timedelta(scale_cadence/2, 'h'),\n",
    "                               y=model_dict['ScalingFactors'],\n",
    "                               name= model,\n",
    "                               mode='markers',\n",
    "                               opacity=1,\n",
    "#                                    marker=dict(color=coldict[model_m1], \n",
    "#                                                size=5,\n",
    "#                                                symbol='line-ew',\n",
    "#                                                line = dict(color = coldict[model_m1], width=3)), #symbol='diamond-wide'),\n",
    "                                   marker=dict(color=coldict[model_m1], size=5),\n",
    "                               line = dict(shape = 'hvh',dash ='dot', color = coldict[model_m1], width=1),\n",
    "                               showlegend=False),\n",
    "                               secondary_y=False,row=1, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    time_avg,dscale_avg = orbit_avg_generic(den_dict['dates'], den_dict['denscaled'], den_dict['lat'])\n",
    "    ## -----------------------------------------------------------------------------------------------------\n",
    "    ##     Orbit Averaged Density\n",
    "    fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                               y=dscale_avg,\n",
    "                               ### name= model_m1,\n",
    "                               mode='markers+lines',\n",
    "                               opacity=1,\n",
    "                                   marker=dict(color=coldict[model_m1],size=2),\n",
    "                                   line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "                               showlegend=False), row=2, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     time_avg,d_avg = orbit_avg_generic(den_dict['dates'], den_dict['dens'], den_dict['lat'])\n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    ###     Orbit Averaged Density\n",
    "#     fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                y=d_avg,\n",
    "#                                ### name= model_m1,\n",
    "#                                mode='markers',\n",
    "#                                opacity=0.3,\n",
    "#                                    marker=dict(color= coldict[model_m1],size=2),\n",
    "#                                    line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                                showlegend=False), row=2, col=1)\n",
    "         \n",
    "    return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig  = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "#     subplot_titles=(['Density (kg/m^3)'   , \n",
    "# #                      'CD*A'               ,\n",
    "#                      'CD'                 ,   \n",
    "#                      'Relative Velocity'  , \n",
    "#                      'Speed Ratio',\n",
    "#                     ]),\n",
    "    vertical_spacing = 0.05,\n",
    "#     horizontal_spacing = 0.05,\n",
    "    shared_xaxes=True)\n",
    "\n",
    "\n",
    "\n",
    "# run_dict = { }\n",
    "# rms_total_return = {}\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    for imonth,month in enumerate(month_list):\n",
    "\n",
    "        fig = PLOT_resids(fig, obj[model],   models_dens[model], run_dict[model])\n",
    "\n",
    "    \n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=11,color='black')\n",
    "## automate the specification of the axes for subplots\n",
    "rownum, colnum = fig._get_subplot_rows_columns()\n",
    "for i in rownum:\n",
    "    if len(rownum)==1:\n",
    "        L_ticklabel = True\n",
    "    else:\n",
    "        if i < len(rownum):\n",
    "            L_ticklabel = True\n",
    "        else:\n",
    "            L_ticklabel = True\n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,\n",
    "                      showticklabels=L_ticklabel,\n",
    "#                       tickformat= '%m/%d',\n",
    "                      linecolor='black',\n",
    "                      linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',\n",
    "                      tickfont=font_dict,\n",
    "                      mirror=True,\n",
    "#                       tickwidth=2,\n",
    "#                       ticklen=9,\n",
    "                      tickcolor='grey',\n",
    "#                       tick0=\"2018-11-9\" ,\n",
    "#                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(\n",
    "                         dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,\n",
    "                         ticklen=4,\n",
    "                         tickcolor='grey',\n",
    "                         ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',\n",
    "                       gridwidth=1,\n",
    "                       layer='above traces',\n",
    "                       tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                         showticklabels=True,\n",
    "                         linecolor='black',  # line color\n",
    "                         linewidth=1,        # line size\n",
    "                     ticks='inside',     # ticks outside axis\n",
    "                     tickfont=font_dict, # tick label font\n",
    "                     mirror='allticks',  # add ticks to top/right axes\n",
    "                     tickwidth=1,      # tick width\n",
    "                     tickcolor='black',  # tick color\n",
    "                     gridcolor='gainsboro',\n",
    "                     gridwidth=1,\n",
    "                     layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Scaling Factor\", \n",
    "                     exponentformat= 'power',row=1, col=1)\n",
    "\n",
    "    yaxis_range = [-13.7 -.55 ,  -12.6+.25]# ] #full_fig.layout.yaxis2.range\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Scaled Density\", \n",
    "                     type=\"log\", \n",
    "                      range=yaxis_range,\n",
    "                     exponentformat= 'power',row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"CD*A\", \n",
    "#                       type=\"log\", \n",
    "#                       range=yaxis_range,\n",
    "                     exponentformat= 'power',row=3, col=1)\n",
    "    \n",
    "a='input'\n",
    "s=settings_icesat2\n",
    "\n",
    "fig.update_layout(title=f\"{s['cd_model'][a]}, {s['hours_between_cd_adj'][a]}-hr Scale from CD={s['cd_value'][a]}\",\n",
    "#                     title=f\"BWDRAG, 3-hr Scale from CD=2.5 \",\n",
    "                  autosize=False,    width=1000,    height=1000,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "fig.update_annotations(font_size=16)  # Increase size of subplot title\n",
    "fig.show(config=config)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb5436",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.729030Z",
     "start_time": "2024-04-23T17:45:38.024Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "# def PLOT_resids(fig, obj_m1, den_dict, model_dict):\n",
    "    \n",
    "#     SHOW_alldata = True\n",
    "    \n",
    "#     model_m1 = obj_m1['global_params']['prms']['den_model']\n",
    "#     if model!='hasdm_oc':\n",
    "#         opac_val = 1\n",
    "#     else:\n",
    "#         opac_val = 1\n",
    "\n",
    "#     for ii,arc in enumerate(obj_m1['global_params']['arc_input']):\n",
    "#         epochstart = obj_m1['global_params']['prms']['epoch_start'][ii]\n",
    "#         hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "#         frachours =(hrs/24)\n",
    "#         #\n",
    "#         if len(arc) == 9:\n",
    "#             maneuv_indicator = arc[8]\n",
    "#         else:\n",
    "#             maneuv_indicator = ''\n",
    "#         arc_type = obj_m1['global_params']['prms']['arc_type']\n",
    "#         if arc_type == \"Nominal30hr_and_AB\":\n",
    "#             arc_name =arc[:8]+ maneuv_indicator\n",
    "#         else:\n",
    "#             arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "        \n",
    "\n",
    "#         data_res = obj_m1['OrbitResids'][arc_name]['resids']\n",
    "\n",
    "#         drag_data        = obj_m1['DragFile'][arc_name]\n",
    "#         drag_data[\"Lat\"] = obj_m1['Density' ][arc_name]['Lat']\n",
    "#         den_df           = obj_m1['Density' ][arc_name]\n",
    "        \n",
    "# #         print(arc[:8])\n",
    "#         ### Cut off the extra time for the regular days\n",
    "#         start_arc = pd.to_datetime(arc[:8], format='%Y.%j')\n",
    "#         end_arc   = pd.to_datetime(arc[:8], format = '%Y.%j')+pd.to_timedelta(24, 'h')-pd.to_timedelta(1, 'm')\n",
    "\n",
    "# #         print(f\" {arc_name:10}|   , {start_arc},  {end_arc}\")\n",
    "        \n",
    "#         ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "#         drag_data = drag_data.query( \\\n",
    "#                 f\"{start_arc.year}\"         \\\n",
    "#                +f\"{start_arc.month:02d}\"    \\\n",
    "#                +f\"{start_arc.day:02d}\"      \\\n",
    "#                +f\"{start_arc.hour:02d}\"     \\\n",
    "#                +f\"{start_arc.minute:02d}\"   \\\n",
    "#                +f\"{start_arc.second:02d}\"   \\\n",
    "#                +f\" <= Date < \"                     \\\n",
    "#                +f\"{end_arc.year}\"       \\\n",
    "#                +f\"{end_arc.month:02d}\"  \\\n",
    "#                +f\"{end_arc.day:02d}\"    \\\n",
    "#                +f\"{end_arc.hour:02d}\"   \\\n",
    "#                +f\"{end_arc.minute:02d}\" \\\n",
    "#                +f\"{end_arc.second:02d}\" \\\n",
    "#             )\n",
    "#         ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "#         den_df = den_df.query( \\\n",
    "#                 f\"{start_arc.year}\"         \\\n",
    "#                +f\"{start_arc.month:02d}\"    \\\n",
    "#                +f\"{start_arc.day:02d}\"      \\\n",
    "#                +f\"{start_arc.hour:02d}\"     \\\n",
    "#                +f\"{start_arc.minute:02d}\"   \\\n",
    "#                +f\"{start_arc.second:02d}\"   \\\n",
    "#                +f\" <= Date < \"                     \\\n",
    "#                +f\"{end_arc.year}\"       \\\n",
    "#                +f\"{end_arc.month:02d}\"  \\\n",
    "#                +f\"{end_arc.day:02d}\"    \\\n",
    "#                +f\"{end_arc.hour:02d}\"   \\\n",
    "#                +f\"{end_arc.minute:02d}\" \\\n",
    "#                +f\"{end_arc.second:02d}\" \\\n",
    "#             )\n",
    "\n",
    "\n",
    "#         indplot=3\n",
    "\n",
    "# #         date_rms.append(pd.to_datetime(datetime.datetime(int(arc.split('.')[0]), 1, 1) + datetime.timedelta(int(arc.split('.')[1]))- datetime.timedelta(hours=12) ))\n",
    "# #         rms_totals.append(obj_m1['Statistics'][arc]['T_RMS'].values[0])\n",
    "\n",
    "# #         iters = obj_m1['run_parameters'+arc_name]['total_iterations']\n",
    "# #         for itime in obj_m1['AdjustedParams'][arc_string][iters][satid]['0CD']:\n",
    "# #             date_scalefactor.append(itime)\n",
    "# #             ScalingFactor.append(obj_m1['AdjustedParams'][arc_string][iters][satid]['0CD'][itime]['CURRENT_VALUE'])\n",
    "\n",
    "\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'],\n",
    "#                                        y=drag_data['CD']*drag_data['TOTAREA'],\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=1,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=3,),\n",
    "#                                      showlegend=False,),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=4, col=1,\n",
    "#                                  )\n",
    "# #         (time_avg, avg_cd ) = orbit_avg_generic(drag_data['Date'],drag_data['CD'],drag_data['Lat'])    \n",
    "# #         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "# #                                  y=avg_cd,\n",
    "# #                            mode='lines',\n",
    "# #                            opacity=1,\n",
    "# #                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "# #                            showlegend=False), row=3, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "#     fig.add_trace(go.Scattergl(x=pd.to_datetime(model_dict['ScalingFactor_times'])-pd.to_timedelta(scale_cadence/2, 'h'),\n",
    "#                            y=model_dict['ScalingFactors'],\n",
    "#                            name= model,\n",
    "#                            mode='markers+lines',\n",
    "#                            opacity=1,\n",
    "#                                marker=dict(color=coldict[model_m1], \n",
    "#                                            size=15,\n",
    "#                                            symbol='line-ew',\n",
    "#                                            line = dict(color = coldict[model_m1], width=3)), #symbol='diamond-wide'),\n",
    "#                            line = dict(shape = 'hvh',dash ='dash', color = coldict[model_m1], width=1),\n",
    "#                            showlegend=False),\n",
    "#                            secondary_y=False,row=1, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "#     time_avg,dscale_avg = orbit_avg_generic(den_dict['dates'], den_dict['denscaled'], den_dict['lat'])\n",
    "#     ## -----------------------------------------------------------------------------------------------------\n",
    "#     ##     Orbit Averaged Density\n",
    "#     fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                y=dscale_avg,\n",
    "#                                ### name= model_m1,\n",
    "#                                mode='markers+lines',\n",
    "#                                opacity=1,\n",
    "#                                    marker=dict(color=coldict[model_m1],size=2),\n",
    "#                                    line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                                showlegend=False), row=3, col=1)\n",
    "# #     fig.add_trace(go.Scattergl(x=den_dict['dates'],\n",
    "# #                                y=den_dict['denscaled'],\n",
    "# #                                ### name= model_m1,\n",
    "# #                                mode='markers+lines',\n",
    "# #                                opacity=1,\n",
    "# #                                    marker=dict(color=coldict[model_m1],size=2),\n",
    "# #                                    line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "# #                                showlegend=False), row=3, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     time_avg,d_avg = orbit_avg_generic(den_dict['dates'], den_dict['dens'], den_dict['lat'])\n",
    "#     ### -----------------------------------------------------------------------------------------------------\n",
    "#     ###     Orbit Averaged Density\n",
    "# #     fig.add_trace(go.Scattergl(x=den_dict['dates'], #time_avg,\n",
    "# #                                y=den_dict['dens'], #d_avg,\n",
    "# #                                ### name= model_m1,\n",
    "# #                                mode='markers+lines',\n",
    "# #                                opacity=1,\n",
    "# #                                    marker=dict(color=coldict[model_m1],size=1),\n",
    "# #                                    line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "# #                                showlegend=False), row=2, col=1)\n",
    "\n",
    "#     ###     Orbit Averaged Density\n",
    "#     fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                y=d_avg,\n",
    "#                                ### name= model_m1,\n",
    "#                                mode='markers+lines',\n",
    "#                                opacity=1,\n",
    "#                                    marker=dict(color= coldict[model_m1],size=2),\n",
    "#                                    line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                                showlegend=False), row=2, col=1)\n",
    "    \n",
    "    \n",
    "# #                 time_avg,CD_avg, area_avg_rolling, CD_std = orb_avg_param(obj_m1.__dict__['DragFile'], arc_string, 'TOTAREA')\n",
    "# #                 fig.add_trace(go.Scattergl(x=time_avg,\n",
    "# #                                            y=area_avg_rolling,\n",
    "# #     #                                          name= plot_name+arc,\n",
    "# #                                              mode='markers+lines',\n",
    "# #                                              opacity=1,\n",
    "# #                                              marker=dict(color=col,size=2,),\n",
    "# #                                              line = dict(shape='hvh', dash ='solid', color = col, width=3),\n",
    "# #                                              showlegend=False, ),\n",
    "# #                                              secondary_y=False,\n",
    "# #                                              row=3, col=1,\n",
    "# #                                          )\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "#     return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig  = make_subplots(\n",
    "#     rows=4, cols=1,\n",
    "# #     subplot_titles=(['Density (kg/m^3)'   , \n",
    "# # #                      'CD*A'               ,\n",
    "# #                      'CD'                 ,   \n",
    "# #                      'Relative Velocity'  , \n",
    "# #                      'Speed Ratio',\n",
    "# #                     ]),\n",
    "#     vertical_spacing = 0.05,\n",
    "# #     horizontal_spacing = 0.05,\n",
    "#     shared_xaxes=True)\n",
    "\n",
    "\n",
    "\n",
    "# # run_dict = { }\n",
    "# # rms_total_return = {}\n",
    "\n",
    "# for model in run_dict.keys():\n",
    "#     for imonth,month in enumerate(month_list):\n",
    "\n",
    "# #     for ialph,alpha in enumerate(alphas):   \n",
    "#          # fig,rms_total_return = PLOT__intrack_residuals_w_rms_w_cd(fig, Obj_Geodyn['msis2'] , 0,  arc_listlist)\n",
    "# #         run_dict[val+\"alpha_\"+alpha] = ialph\n",
    "\n",
    "#         fig = PLOT_resids(fig, obj[model],   models_dens[model], run_dict[monthmodel])\n",
    "\n",
    "    \n",
    "# #######################################################\n",
    "# font_dict=dict(family='Arial',size=11,color='black')\n",
    "# ## automate the specification of the axes for subplots\n",
    "# rownum, colnum = fig._get_subplot_rows_columns()\n",
    "# for i in rownum:\n",
    "#     if len(rownum)==1:\n",
    "#         L_ticklabel = True\n",
    "#     else:\n",
    "#         if i < len(rownum):\n",
    "#             L_ticklabel = True\n",
    "#         else:\n",
    "#             L_ticklabel = True\n",
    "#     fig.update_xaxes(### LINE at axis border\n",
    "#                       showline=True,\n",
    "#                       showticklabels=L_ticklabel,\n",
    "# #                       tickformat= '%m/%d',\n",
    "#                       linecolor='black',\n",
    "#                       linewidth=1,\n",
    "#                      ### Major ticks\n",
    "#                       ticks='inside',\n",
    "#                       tickfont=font_dict,\n",
    "#                       mirror=True,\n",
    "# #                       tickwidth=2,\n",
    "# #                       ticklen=9,\n",
    "#                       tickcolor='grey',\n",
    "# #                       tick0=\"2018-11-9\" ,\n",
    "# #                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "#                       #### Minor Ticks\n",
    "#                        minor=dict(\n",
    "#                          dtick=86400000.0, # milliseconds in a day\n",
    "#                          tickwidth=1,\n",
    "#                          ticklen=4,\n",
    "#                          tickcolor='grey',\n",
    "#                          ticks='inside'),\n",
    "#                       ### GRID\n",
    "#                        gridcolor='gainsboro',\n",
    "#                        gridwidth=1,\n",
    "#                        layer='above traces',\n",
    "#                        tickangle=0,\n",
    "#                        row=i, col=1)\n",
    "#     fig.update_yaxes(showline=True,      # add line at x=0\n",
    "#                          showticklabels=True,\n",
    "#                          linecolor='black',  # line color\n",
    "#                          linewidth=1,        # line size\n",
    "#                      ticks='inside',     # ticks outside axis\n",
    "#                      tickfont=font_dict, # tick label font\n",
    "#                      mirror='allticks',  # add ticks to top/right axes\n",
    "#                      tickwidth=1,      # tick width\n",
    "#                      tickcolor='black',  # tick color\n",
    "#                      gridcolor='gainsboro',\n",
    "#                      gridwidth=1,\n",
    "#                      layer='above traces',\n",
    "#                      row=i, col=1)\n",
    "\n",
    "#     fig.update_yaxes(title_text=\"Scaling Factor\", \n",
    "#                      exponentformat= 'power',row=1, col=1)\n",
    "\n",
    "#     fig.update_yaxes(title_text=\"Density\", \n",
    "#                      type=\"log\", \n",
    "#                      exponentformat= 'power',row=2, col=1)\n",
    "#     fig.update_yaxes(title_text=\"Scaled Density\", \n",
    "#                       type=\"log\", \n",
    "#                      exponentformat= 'power',row=3, col=1)\n",
    "# #     D\n",
    "# a='input'\n",
    "# s=settings_icesat2\n",
    "# fig.update_layout(title=f\"{s['cd_model'][a]}, {s['hours_between_cd_adj'][a]}-hr Scale from CD={s['cd_value'][a]}\", \n",
    "#                   autosize=False,    width=1000,    height=1100,\n",
    "#                   legend= {'itemsizing': 'trace'},\n",
    "#                   font=font_dict,\n",
    "#                   plot_bgcolor='white', \n",
    "#                  )\n",
    "# fig.update_annotations(font_size=16)  # Increase size of subplot title\n",
    "# fig.show(config=config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc5118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe88847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.729772Z",
     "start_time": "2024-04-23T17:45:38.028Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a8865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96c2ee4f",
   "metadata": {},
   "source": [
    "## Plot Drag State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbb8a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T17:41:22.044098Z",
     "start_time": "2023-12-14T17:41:21.803208Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286486a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.730512Z",
     "start_time": "2024-04-23T17:45:38.033Z"
    }
   },
   "outputs": [],
   "source": [
    "# obj['jb2008']['DragFile']['2018.303']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657efac5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.731225Z",
     "start_time": "2024-04-23T17:45:38.036Z"
    }
   },
   "outputs": [],
   "source": [
    "# arc = obj['jb2008']['global_params']['arc_input'][0]\n",
    "\n",
    "# print(pd.to_datetime(arc, format = '%Y.%j'))\n",
    "# print(pd.to_datetime(arc, format = '%Y.%j')+pd.to_timedelta(24, 'h')-pd.to_timedelta(1, 'm'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adcbb47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T18:00:52.732185Z",
     "start_time": "2024-04-23T17:45:38.039Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "# def PLOT__SATDRAG_STATE(fig, obj_m1, den_dict):\n",
    "    \n",
    "#     SHOW_alldata = False\n",
    "    \n",
    "#     model_m1 = obj_m1['global_params']['prms']['den_model']\n",
    "#     if model!='hasdm_oc':\n",
    "#         opac_val = 1\n",
    "#     else:\n",
    "#         opac_val = 1\n",
    "\n",
    "#     for ii,arc in enumerate(obj_m1['global_params']['arc_input']):\n",
    "#         epochstart = obj_m1['global_params']['prms']['epoch_start'][ii]\n",
    "#         hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "#         frachours =(hrs/24)\n",
    "#         #\n",
    "#         if len(arc) == 9:\n",
    "#             maneuv_indicator = arc[8]\n",
    "#         else:\n",
    "#             maneuv_indicator = ''\n",
    "#         arc_type = obj_m1['global_params']['prms']['arc_type']\n",
    "#         if arc_type == \"Nominal30hr_and_AB\":\n",
    "#             arc_name =arc[:8]+ maneuv_indicator\n",
    "#         else:\n",
    "#             arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#         drag_data        = obj_m1['DragFile'][arc_name]\n",
    "#         drag_data[\"Lat\"] = obj_m1['Density' ][arc_name]['Lat']\n",
    "#         den_df           = obj_m1['Density' ][arc_name]\n",
    "        \n",
    "# #         print(arc[:8])\n",
    "#         ### Cut off the extra time for the regular days\n",
    "#         start_arc = pd.to_datetime(arc[:8], format='%Y.%j')\n",
    "#         end_arc   = pd.to_datetime(arc[:8], format = '%Y.%j')+pd.to_timedelta(24, 'h')-pd.to_timedelta(1, 'm')\n",
    "\n",
    "# #         print(f\" {arc_name:10}|   , {start_arc},  {end_arc}\")\n",
    "        \n",
    "#         ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "#         drag_data = drag_data.query( \\\n",
    "#                 f\"{start_arc.year}\"         \\\n",
    "#                +f\"{start_arc.month:02d}\"    \\\n",
    "#                +f\"{start_arc.day:02d}\"      \\\n",
    "#                +f\"{start_arc.hour:02d}\"     \\\n",
    "#                +f\"{start_arc.minute:02d}\"   \\\n",
    "#                +f\"{start_arc.second:02d}\"   \\\n",
    "#                +f\" <= Date < \"                     \\\n",
    "#                +f\"{end_arc.year}\"       \\\n",
    "#                +f\"{end_arc.month:02d}\"  \\\n",
    "#                +f\"{end_arc.day:02d}\"    \\\n",
    "#                +f\"{end_arc.hour:02d}\"   \\\n",
    "#                +f\"{end_arc.minute:02d}\" \\\n",
    "#                +f\"{end_arc.second:02d}\" \\\n",
    "#             )\n",
    "#         ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "#         den_df = den_df.query( \\\n",
    "#                 f\"{start_arc.year}\"         \\\n",
    "#                +f\"{start_arc.month:02d}\"    \\\n",
    "#                +f\"{start_arc.day:02d}\"      \\\n",
    "#                +f\"{start_arc.hour:02d}\"     \\\n",
    "#                +f\"{start_arc.minute:02d}\"   \\\n",
    "#                +f\"{start_arc.second:02d}\"   \\\n",
    "#                +f\" <= Date < \"                     \\\n",
    "#                +f\"{end_arc.year}\"       \\\n",
    "#                +f\"{end_arc.month:02d}\"  \\\n",
    "#                +f\"{end_arc.day:02d}\"    \\\n",
    "#                +f\"{end_arc.hour:02d}\"   \\\n",
    "#                +f\"{end_arc.minute:02d}\" \\\n",
    "#                +f\"{end_arc.second:02d}\" \\\n",
    "#             )\n",
    "\n",
    "\n",
    "#         indplot=3\n",
    "\n",
    "# #         date_rms.append(pd.to_datetime(datetime.datetime(int(arc.split('.')[0]), 1, 1) + datetime.timedelta(int(arc.split('.')[1]))- datetime.timedelta(hours=12) ))\n",
    "# #         rms_totals.append(obj_m1['Statistics'][arc]['T_RMS'].values[0])\n",
    "\n",
    "# #         iters = obj_m1['run_parameters'+arc_name]['total_iterations']\n",
    "# #         for itime in obj_m1['AdjustedParams'][arc_string][iters][satid]['0CD']:\n",
    "# #             date_scalefactor.append(itime)\n",
    "# #             ScalingFactor.append(obj_m1['AdjustedParams'][arc_string][iters][satid]['0CD'][itime]['CURRENT_VALUE'])\n",
    "\n",
    "\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                        y=drag_data['CD'][::indplot],\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=0.5,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                                      showlegend=False,),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=2, col=1,\n",
    "#                                  )\n",
    "#         (time_avg, avg_cd ) = orbit_avg_generic(drag_data['Date'],drag_data['CD'],drag_data['Lat'])    \n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg_cd,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=2, col=1)\n",
    "\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                        y=drag_data['TOTAREA'][::indplot],\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=0.5,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                                      showlegend=False,),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=3, col=1,\n",
    "#                                  )\n",
    "#         (time_avg, avg_area) = orbit_avg_generic(drag_data['Date'],drag_data['TOTAREA'],drag_data['Lat'])    \n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg_area,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=3, col=1)\n",
    "\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                        y=drag_data['CD'][::indplot]*drag_data['TOTAREA'][::indplot],\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=0.5,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                                      showlegend=False,),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=4, col=1,\n",
    "#                                  )\n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg_cd*avg_area,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=4, col=1)\n",
    "\n",
    "        \n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                        y=drag_data['VELREL'][::indplot],\n",
    "# #                                          name= plot_name+arc,\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=0.5,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                                      line = dict(shape='hvh', dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                                      showlegend=False, ),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=5, col=1,\n",
    "#                                  )\n",
    "#         (time_avg, avg ) = orbit_avg_generic(drag_data['Date'],drag_data['VELREL'],drag_data['Lat'])    \n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=5, col=1)\n",
    "\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                    y=drag_data['SpeedRatio'][::indplot],\n",
    "# #                                          name= plot_name+arc,\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=0.5,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                                      line = dict(shape='hvh', dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                                      showlegend=False, ),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=6, col=1,\n",
    "#                                  )\n",
    "#         (time_avg, avg ) = orbit_avg_generic(drag_data['Date'],drag_data['SpeedRatio'],drag_data['Lat'])    \n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=6, col=1)\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=den_df['Date'][::indplot],\n",
    "#                                  y=den_df['rho (kg/m**3)'][::indplot],\n",
    "#                        ### name= model_m1,\n",
    "#                        mode='markers',\n",
    "#                        opacity=0.5,\n",
    "#                            marker=dict(color=coldict[model_m1],size=2),\n",
    "#                            line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                        showlegend=False), row=1, col=1)\n",
    "        \n",
    "#         (time_avg, d_avg ) = orbit_avg_generic(den_df['Date'],den_df['rho (kg/m**3)'],\n",
    "#                                                den_df['Lat'])    \n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=d_avg,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                marker=dict(color=coldict[model_m1],size=1),\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=1, col=1)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# #     (time_avg, d_avg ) = orbit_avg_generic(den_dict['dates'],\n",
    "# #                                    den_dict['den'],\n",
    "# #                                    den_dict['lat'])\n",
    "# #     ### -----------------------------------------------------------------------------------------------------\n",
    "# #     ###     Orbit Averaged Density\n",
    "# #     fig.add_trace(go.Scattergl(x=time_avg,\n",
    "# #                                y=d_avg,\n",
    "# #                                ### name= model_m1,\n",
    "# #                                mode='markers',\n",
    "# #                                opacity=opac_val,\n",
    "# #                                    marker=dict(color= coldict[model_m1],size=2),\n",
    "# #                                    line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "# #                                showlegend=False), row=1, col=1)\n",
    "    \n",
    "    \n",
    "# #                 time_avg,CD_avg, area_avg_rolling, CD_std = orb_avg_param(obj_m1.__dict__['DragFile'], arc_string, 'TOTAREA')\n",
    "# #                 fig.add_trace(go.Scattergl(x=time_avg,\n",
    "# #                                            y=area_avg_rolling,\n",
    "# #     #                                          name= plot_name+arc,\n",
    "# #                                              mode='markers+lines',\n",
    "# #                                              opacity=1,\n",
    "# #                                              marker=dict(color=col,size=2,),\n",
    "# #                                              line = dict(shape='hvh', dash ='solid', color = col, width=3),\n",
    "# #                                              showlegend=False, ),\n",
    "# #                                              secondary_y=False,\n",
    "# #                                              row=3, col=1,\n",
    "# #                                          )\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "#     return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig  = make_subplots(\n",
    "#     rows=6, cols=1,\n",
    "# #     subplot_titles=(['Density (kg/m^3)'   , \n",
    "# # #                      'CD*A'               ,\n",
    "# #                      'CD'                 ,   \n",
    "# #                      'Relative Velocity'  , \n",
    "# #                      'Speed Ratio',\n",
    "# #                     ]),\n",
    "#     vertical_spacing = 0.05,\n",
    "# #     horizontal_spacing = 0.05,\n",
    "#     shared_xaxes=True)\n",
    "\n",
    "\n",
    "\n",
    "# # run_dict = { }\n",
    "# # rms_total_return = {}\n",
    "\n",
    "# for model in run_dict.keys():\n",
    "#     for imonth,month in enumerate(month_list):\n",
    "\n",
    "# #     for ialph,alpha in enumerate(alphas):   \n",
    "#          # fig,rms_total_return = PLOT__intrack_residuals_w_rms_w_cd(fig, Obj_Geodyn['msis2'] , 0,  arc_listlist)\n",
    "# #         run_dict[val+\"alpha_\"+alpha] = ialph\n",
    "\n",
    "#         fig = PLOT__SATDRAG_STATE(fig, obj[month+model],   models_dens[month+model])\n",
    "\n",
    "    \n",
    "# #######################################################\n",
    "# font_dict=dict(family='Arial',size=11,color='black')\n",
    "# ## automate the specification of the axes for subplots\n",
    "# rownum, colnum = fig._get_subplot_rows_columns()\n",
    "# for i in rownum:\n",
    "#     if len(rownum)==1:\n",
    "#         L_ticklabel = True\n",
    "#     else:\n",
    "#         if i < len(rownum):\n",
    "#             L_ticklabel = True\n",
    "#         else:\n",
    "#             L_ticklabel = True\n",
    "#     fig.update_xaxes(### LINE at axis border\n",
    "#                       showline=True,\n",
    "#                       showticklabels=L_ticklabel,\n",
    "# #                       tickformat= '%m/%d',\n",
    "#                       linecolor='black',\n",
    "#                       linewidth=1,\n",
    "#                      ### Major ticks\n",
    "#                       ticks='inside',\n",
    "#                       tickfont=font_dict,\n",
    "#                       mirror=True,\n",
    "# #                       tickwidth=2,\n",
    "# #                       ticklen=9,\n",
    "#                       tickcolor='grey',\n",
    "# #                       tick0=\"2018-11-9\" ,\n",
    "# #                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "#                       #### Minor Ticks\n",
    "#                        minor=dict(\n",
    "#                          dtick=86400000.0, # milliseconds in a day\n",
    "#                          tickwidth=1,\n",
    "#                          ticklen=4,\n",
    "#                          tickcolor='grey',\n",
    "#                          ticks='inside'),\n",
    "#                       ### GRID\n",
    "#                        gridcolor='gainsboro',\n",
    "#                        gridwidth=1,\n",
    "#                        layer='above traces',\n",
    "#                        tickangle=0,\n",
    "#                        row=i, col=1)\n",
    "#     fig.update_yaxes(showline=True,      # add line at x=0\n",
    "#                          showticklabels=True,\n",
    "#                          linecolor='black',  # line color\n",
    "#                          linewidth=1,        # line size\n",
    "#                      ticks='inside',     # ticks outside axis\n",
    "#                      tickfont=font_dict, # tick label font\n",
    "#                      mirror='allticks',  # add ticks to top/right axes\n",
    "#                      tickwidth=1,      # tick width\n",
    "#                      tickcolor='black',  # tick color\n",
    "#                      gridcolor='gainsboro',\n",
    "#                      gridwidth=1,\n",
    "#                      layer='above traces',\n",
    "#                      row=i, col=1)\n",
    "\n",
    "    \n",
    "#     fig.update_yaxes(title_text=\"Density\", \n",
    "#                      type=\"log\", \n",
    "#                      exponentformat= 'power',row=1, col=1)\n",
    "#     fig.update_yaxes(title_text=\"CD\", \n",
    "#                      exponentformat= 'power',row=2, col=1)\n",
    "#     fig.update_yaxes(title_text=\"Total Area\", \n",
    "#                      exponentformat= 'power',row=3, col=1)\n",
    "#     fig.update_yaxes(title_text=\"CD*Area\", \n",
    "#                      exponentformat= 'power',row=4, col=1)\n",
    "\n",
    "#     fig.update_yaxes(title_text=\"Rel. Velocity [m/s] \", \n",
    "#                      exponentformat= 'power',row=5, col=1)\n",
    "#     fig.update_yaxes(title_text=\"Speed Ratio\", \n",
    "#                      exponentformat= 'power',row=6, col=1)\n",
    "\n",
    "#     ###\n",
    "#     ###  DATE on Final x-Axis only\n",
    "# #     fig.update_xaxes(title=\"Date\",\n",
    "# #                      row=4, col=1)\n",
    "# #     fig.update_xaxes(title=\"Date\",\n",
    "# #                      row=5, col=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig.update_layout(\n",
    "# #                   title = '',\n",
    "#                   autosize=False,    width=1000,    height=1100,\n",
    "#                   legend= {'itemsizing': 'trace'},\n",
    "#                   font=font_dict,\n",
    "#                   plot_bgcolor='white', \n",
    "#                  )\n",
    "# fig.update_annotations(font_size=16)  # Increase size of subplot title\n",
    "\n",
    "\n",
    "\n",
    "# # fig.add_vrect(x0=\"2018-10-16 23:00:00\" ,\n",
    "# #               x1=\"2018-10-17 00:24:00\" ,\n",
    "# #                 fillcolor=\"red\",\n",
    "# #                 opacity=0.25,\n",
    "# #                 line_width=0)\n",
    "# # fig.add_vrect(x0=\"2018-10-28 16:00:00\" ,\n",
    "# #               x1=\"2018-10-28 17:36:00\" ,\n",
    "# #                 fillcolor=\"red\",\n",
    "# #                 opacity=0.25,\n",
    "# #                 line_width=0)\n",
    "# # fig.add_vrect(x0=\"2018-10-29 10:18:00\" ,\n",
    "# #               x1=\"2018-10-29 11:42:00\" ,\n",
    "# #                 fillcolor=\"red\",\n",
    "# #                 opacity=0.25,\n",
    "# #                 line_width=0)\n",
    "# # fig.add_vrect(x0=\"\" ,\n",
    "# #               x1=\"\" ,\n",
    "# #                 fillcolor=\"red\",\n",
    "# #                 opacity=0.25,\n",
    "# #                 line_width=0)\n",
    "# # fig.add_vrect(x0=\"\" ,\n",
    "# #               x1=\"\" ,\n",
    "# #                 fillcolor=\"red\",\n",
    "# #                 opacity=0.25,\n",
    "# #                 line_width=0)\n",
    "\n",
    "# fig.show(config=config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6e808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T19:39:20.898384Z",
     "start_time": "2023-11-07T19:39:20.181625Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95759863",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T19:39:20.925052Z",
     "start_time": "2023-11-07T19:39:20.900050Z"
    }
   },
   "source": [
    "# What is the average CD for each time period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326addc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1019px",
    "left": "24px",
    "top": "111.12px",
    "width": "174px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
