{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc435212",
   "metadata": {},
   "source": [
    "## Run GEODYN for MSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f5eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a93b3c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:58:00.815929Z",
     "start_time": "2022-06-24T18:58:00.811703Z"
    }
   },
   "outputs": [],
   "source": [
    "run_list = [  'msis2'  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65cfa4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:58:00.821161Z",
     "start_time": "2022-06-24T18:58:00.817943Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# import sys  \n",
    "# import pickle \n",
    "# import gc\n",
    "\n",
    "# sys.path.insert(0, '/data/geodyn_proj/pygeodyn/pygeodyn_develop/')\n",
    "# from PYGEODYN import Pygeodyn\n",
    "\n",
    "# for i,val in enumerate(run_list):   \n",
    "#     for ii in [ '_p1', '_p2' ]:   \n",
    "\n",
    "#         run_settings = '/data/zach_work/ML_project_support/runsettings_3month_'+ val +ii+'.yaml'\n",
    "#         ### Load the data into an object\n",
    "#         RunObject = Pygeodyn(run_settings)\n",
    "#         RunObject.RUN_GEODYN()\n",
    "#         RunObject = 0\n",
    "#         gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68d3b3",
   "metadata": {},
   "source": [
    "## Read GEODYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea4a036",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:58:01.337331Z",
     "start_time": "2022-06-24T18:58:00.823021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msis2_p1  Pickle created -- will load in next step\n",
      "msis2_p2  Pickle created -- will load in next step\n",
      "\n",
      "\n",
      "Loaded data... 3month_icesat2orbits_msis2_p1.pkl\n",
      "Loaded data... 3month_icesat2orbits_msis2_p2.pkl\n"
     ]
    }
   ],
   "source": [
    "# for i,val in enumerate(run_list): \n",
    "#     for ii in ['']:\n",
    "# EDIT_OBJECT_DATES = 0\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import sys  \n",
    "import pickle \n",
    "import gc\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '/data/geodyn_proj/pygeodyn/pygeodyn_develop/')\n",
    "from PYGEODYN import Pygeodyn\n",
    " \n",
    "dir_save = '/data/zach_work/output_from_runs/ML_project_support/'\n",
    "\n",
    "\n",
    "for i,val in enumerate(run_list): \n",
    "    for ii in ['_p1', '_p2']:        \n",
    "        pickle_file = dir_save+'3month_icesat2orbits_'+val+ii+'.pkl'\n",
    "        if not os.path.exists(pickle_file):\n",
    "            print('Must create pickle file...')\n",
    "            print('   ',  pickle_file)\n",
    "            print('   ', 'Reading Geodyn Data')\n",
    "\n",
    "            run_settings = '/data/zach_work/ML_project_support/runsettings_3month_'+ val +ii+'.yaml'\n",
    "            ### Load the data into an object\n",
    "            Obj_Geodyn = Pygeodyn(run_settings)\n",
    "            Obj_Geodyn.getData_BigData_lowmemory()\n",
    "            gc.collect()\n",
    "            #### Pickle the object to save it\n",
    "            print('   ', 'Saving pickle')\n",
    "            filehandler = open(pickle_file, 'wb') \n",
    "            pickle.dump(Obj_Geodyn, filehandler)\n",
    "            filehandler.close()\n",
    "            Obj_Geodyn = 0\n",
    "            print('   ', 'Saved pickle')\n",
    "        else:\n",
    "            print(val,ii,'  Pickle created -- will load in next step', sep='')\n",
    "            \n",
    "\n",
    "### Load the data if the pickles exist\n",
    "print()\n",
    "print()\n",
    "gc.collect()\n",
    "\n",
    "Obj_Geodyn = {}\n",
    "for i,val in enumerate(run_list):\n",
    "    for ii in ['_p1', '_p2']:\n",
    "        pickle_file = dir_save+'3month_icesat2orbits_'+val+ii+'.pkl'\n",
    "        filehandler = open(pickle_file, 'rb') \n",
    "        Obj_Geodyn[val+ii] = pickle.load(filehandler)\n",
    "        filehandler.close()\n",
    "        print('Loaded data... ', '3month_icesat2orbits_',val,ii,'.pkl',sep='')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6a7fa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:58:01.359757Z",
     "start_time": "2022-06-24T18:58:01.339370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Trajectory_orbfil', 'Density', 'Residuals_summary', 'Statistics', 'OrbitResids', 'run_parameters2018.292.01', 'global_params', 'run_parameters2018.293.01', 'run_parameters2018.294.01', 'run_parameters2018.295.01', 'run_parameters2018.296.01', 'run_parameters2018.297.01', 'run_parameters2018.298.01', 'run_parameters2018.299.01', 'run_parameters2018.304.01', 'run_parameters2018.305.01', 'run_parameters2018.306.01', 'run_parameters2018.307.01', 'run_parameters2018.308.01', 'run_parameters2018.313.01', 'run_parameters2018.314.01', 'run_parameters2018.315.01', 'run_parameters2018.316.01', 'run_parameters2018.317.01', 'run_parameters2018.318.01', 'run_parameters2018.319.01', 'run_parameters2018.320.01', 'run_parameters2018.321.01', 'run_parameters2018.322.01', 'run_parameters2018.323.01', 'run_parameters2018.324.01', 'run_parameters2018.325.01', 'run_parameters2018.326.01', 'run_parameters2018.327.01', 'arcdate_v2'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Obj_Geodyn['msis2_p1'].__dict__.keys()\n",
    "\n",
    "# 'Trajectory_orbfil', 'Density', 'Residuals_summary', 'Statistics', 'OrbitResids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e78e83ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:58:01.376810Z",
     "start_time": "2022-06-24T18:58:01.361434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_orbfil', 'data_PCE', 'resids'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Obj_Geodyn['msis2_p1'].__dict__['OrbitResids']['2018.292.01'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065dd6fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:25:03.940059Z",
     "start_time": "2022-06-24T18:25:03.925749Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baaea396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:58:01.395635Z",
     "start_time": "2022-06-24T18:58:01.378596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018.292.01\n",
      "2018.293.01\n",
      "2018.294.01\n",
      "2018.295.01\n",
      "2018.296.01\n",
      "2018.297.01\n",
      "2018.298.01\n",
      "2018.299.01\n",
      "2018.304.01\n",
      "2018.305.01\n",
      "2018.306.01\n",
      "2018.307.01\n",
      "2018.308.01\n",
      "2018.313.01\n",
      "2018.314.01\n",
      "2018.315.01\n",
      "2018.316.01\n",
      "2018.317.01\n",
      "2018.318.01\n",
      "2018.319.01\n",
      "2018.320.01\n",
      "2018.321.01\n",
      "2018.322.01\n",
      "2018.323.01\n",
      "2018.324.01\n",
      "2018.325.01\n",
      "2018.326.01\n",
      "2018.327.01\n"
     ]
    }
   ],
   "source": [
    "for ii,key2 in enumerate(Obj_Geodyn['msis2_p1'].__dict__['Density']):\n",
    "    print(key2)\n",
    "    \n",
    "    \n",
    "#     print(Obj_Geodyn['msis2_p1'].__dict__['Density'][key2])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ed354",
   "metadata": {},
   "source": [
    "# Save data to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9491e2ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:58:05.398663Z",
     "start_time": "2022-06-24T18:58:01.399771Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "files_list = [dir_save+'Density_msis2_allarcs.csv',\n",
    "              dir_save+'Statistics_msis2_allarcs.csv',\n",
    "              dir_save+'DataOrbfil_msis2_allarcs.csv',\n",
    "              dir_save+'DataPCE_msis2_allarcs.csv',\n",
    "              dir_save+'DataResids_msis2_allarcs.csv']\n",
    "### Delete the existing files so they append cleanly\n",
    "for file in files_list:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "\n",
    "        \n",
    "append_headers = True      \n",
    "\n",
    "\n",
    "### prepare the split datasets to be combined\n",
    "Objs_list = [ Obj_Geodyn['msis2_p1'] , Obj_Geodyn['msis2_p2'] ]\n",
    "\n",
    "for obj_m1 in Objs_list:\n",
    "\n",
    "    ### Loop through the arcs and append the datasets for each arc into CSV files\n",
    "    for ii,arc in enumerate(obj_m1.__dict__['global_params']['arc_input'][:]):\n",
    "        \n",
    "\n",
    "        arc =arc+'.01'\n",
    "\n",
    "        ### ----------------------------------------------------------------------------------\n",
    "        ### SAVE DENSITY\n",
    "        ##\n",
    "        obj_m1.__dict__['Density'][arc].to_csv(path_or_buf = files_list[0],\n",
    "                                                         sep=',',\n",
    "                                                         mode='a',\n",
    "                                                         #\n",
    "                                                         index_label='Index',\n",
    "                                                         header=append_headers,\n",
    "                                                         index=True,\n",
    "                                                         )\n",
    "        ### ----------------------------------------------------------------------------------\n",
    "        ### SAVE STATISTICS\n",
    "        ### ---------------\n",
    "        obj_m1.__dict__['Statistics'][arc].to_csv(path_or_buf = files_list[1],\n",
    "                                                         sep=',',\n",
    "                                                         mode='a',\n",
    "                                                         #\n",
    "                                                         index_label='Index',\n",
    "                                                         header=append_headers,\n",
    "                                                         index=True,\n",
    "                                                         )\n",
    "        ### ----------------------------------------------------------------------------------\n",
    "        ### SAVE ORBIT DATASETS \n",
    "        ### -------------------   \n",
    "        ##\n",
    "        ### Convert the dictionaries to dataframes\n",
    "        data_orbfil_df = pd.DataFrame.from_dict(obj_m1.__dict__['OrbitResids'][arc]['data_orbfil'], orient='columns')\n",
    "        data_PCE_df    = pd.DataFrame.from_dict(obj_m1.__dict__['OrbitResids'][arc]['data_PCE'],    orient='columns')\n",
    "        resids_df      = pd.DataFrame.from_dict(obj_m1.__dict__['OrbitResids'][arc]['resids'],      orient='columns')\n",
    "\n",
    "\n",
    "\n",
    "        data_orbfil_df.to_csv(path_or_buf = files_list[2],\n",
    "                                                         sep=',',\n",
    "                                                         mode='a',\n",
    "                                                         #\n",
    "                                                         index_label='Index',\n",
    "                                                         header=append_headers,\n",
    "                                                         index=True,\n",
    "                                                                  )\n",
    "        data_PCE_df.to_csv(path_or_buf = files_list[3],\n",
    "                                                         sep=',',\n",
    "                                                         mode='a',\n",
    "                                                         #\n",
    "                                                         index_label='Index',\n",
    "                                                         header=append_headers,\n",
    "                                                         index=True,\n",
    "                                                                  )\n",
    "        resids_df.to_csv(path_or_buf = files_list[4],\n",
    "                                                         sep=',',\n",
    "                                                         mode='a',\n",
    "                                                         #\n",
    "                                                         index_label='Index',\n",
    "                                                         header=append_headers,\n",
    "                                                         index=True,\n",
    "                                                                  )\n",
    "        if ii==0 and append_headers==True:\n",
    "            append_headers=False\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4727fa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:32:59.669536Z",
     "start_time": "2022-06-24T18:32:59.636069Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Read data back in from CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae7f370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:58:06.027947Z",
     "start_time": "2022-06-24T18:58:05.400469Z"
    }
   },
   "outputs": [],
   "source": [
    "files_list = [dir_save+'Density_msis2_allarcs.csv',\n",
    "              dir_save+'Statistics_msis2_allarcs.csv',\n",
    "              dir_save+'DataOrbfil_msis2_allarcs.csv',\n",
    "              dir_save+'DataPCE_msis2_allarcs.csv',\n",
    "              dir_save+'DataResids_msis2_allarcs.csv']\n",
    "\n",
    "\n",
    "test_A = pd.read_csv(files_list[3], \n",
    "                     sep=',',\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "Density_msis2_df = pd.read_csv(files_list[0], \n",
    "                     sep=',',\n",
    "                    )\n",
    "Statistics_msis2_df = pd.read_csv(files_list[1], \n",
    "                     sep=',',\n",
    "                    )\n",
    "DataOrbfil_msis2_df = pd.read_csv(files_list[2], \n",
    "                     sep=',',\n",
    "                    )\n",
    "DataPCE_msis2_df = pd.read_csv(files_list[3], \n",
    "                     sep=',',\n",
    "                    )\n",
    "DataResids_msis2_df = pd.read_csv(files_list[4], \n",
    "                     sep=',',\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec3ba509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T18:58:06.056908Z",
     "start_time": "2022-06-24T18:58:06.030384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Date</th>\n",
       "      <th>N</th>\n",
       "      <th>T</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-19 00:03:00</td>\n",
       "      <td>-0.713981</td>\n",
       "      <td>-11.197472</td>\n",
       "      <td>-0.087724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-19 00:05:00</td>\n",
       "      <td>-0.717382</td>\n",
       "      <td>-11.036047</td>\n",
       "      <td>-0.088147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-19 00:07:00</td>\n",
       "      <td>-0.715938</td>\n",
       "      <td>-10.874191</td>\n",
       "      <td>-0.086992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-10-19 00:09:00</td>\n",
       "      <td>-0.709690</td>\n",
       "      <td>-10.713108</td>\n",
       "      <td>-0.084288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-10-19 00:11:00</td>\n",
       "      <td>-0.698757</td>\n",
       "      <td>-10.554032</td>\n",
       "      <td>-0.080091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33741</th>\n",
       "      <td>713</td>\n",
       "      <td>2019-01-08 23:49:00</td>\n",
       "      <td>1.559614</td>\n",
       "      <td>-36.156976</td>\n",
       "      <td>-0.013955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33742</th>\n",
       "      <td>714</td>\n",
       "      <td>2019-01-08 23:51:00</td>\n",
       "      <td>1.548662</td>\n",
       "      <td>-36.469961</td>\n",
       "      <td>-0.021459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33743</th>\n",
       "      <td>715</td>\n",
       "      <td>2019-01-08 23:53:00</td>\n",
       "      <td>1.535229</td>\n",
       "      <td>-36.778322</td>\n",
       "      <td>-0.028695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33744</th>\n",
       "      <td>716</td>\n",
       "      <td>2019-01-08 23:55:00</td>\n",
       "      <td>1.519619</td>\n",
       "      <td>-37.081719</td>\n",
       "      <td>-0.035536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33745</th>\n",
       "      <td>717</td>\n",
       "      <td>2019-01-08 23:57:00</td>\n",
       "      <td>1.502163</td>\n",
       "      <td>-37.379987</td>\n",
       "      <td>-0.041858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33746 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index                 Date         N          T         W\n",
       "0          0  2018-10-19 00:03:00 -0.713981 -11.197472 -0.087724\n",
       "1          1  2018-10-19 00:05:00 -0.717382 -11.036047 -0.088147\n",
       "2          2  2018-10-19 00:07:00 -0.715938 -10.874191 -0.086992\n",
       "3          3  2018-10-19 00:09:00 -0.709690 -10.713108 -0.084288\n",
       "4          4  2018-10-19 00:11:00 -0.698757 -10.554032 -0.080091\n",
       "...      ...                  ...       ...        ...       ...\n",
       "33741    713  2019-01-08 23:49:00  1.559614 -36.156976 -0.013955\n",
       "33742    714  2019-01-08 23:51:00  1.548662 -36.469961 -0.021459\n",
       "33743    715  2019-01-08 23:53:00  1.535229 -36.778322 -0.028695\n",
       "33744    716  2019-01-08 23:55:00  1.519619 -37.081719 -0.035536\n",
       "33745    717  2019-01-08 23:57:00  1.502163 -37.379987 -0.041858\n",
       "\n",
       "[33746 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataResids_msis2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40837f18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
