{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb780d78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:13.254481Z",
     "start_time": "2025-01-28T19:11:12.706634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2018decdtm2020_o': {'num': 3, 'model_path': None}, '2019decdtm2020_o': {'num': 3, 'model_path': None}}\n"
     ]
    }
   ],
   "source": [
    "scale_cadence = 3\n",
    "\n",
    "from pygeodyn.PYGEODYN import Pygeodyn\n",
    "import datetime\n",
    "\n",
    "\n",
    "scaling_cadence = 3\n",
    "scale_cadence = scaling_cadence\n",
    "index_buffarc_start = 0\n",
    "run_list = [\n",
    "#                 'msis2',\n",
    "#                 'jb2008',\n",
    "                'dtm2020_o',\n",
    "#                 'hasdm_oc'\n",
    "           ]\n",
    "\n",
    "# month_list = ['jan', 'feb', 'mar', 'apr','may', 'jun','jul','aug','sep', 'oct', 'nov','dec' ]\n",
    "month_list = ['jan']\n",
    "\n",
    "year_list = [2019]\n",
    "\n",
    "\n",
    "dir_modeldat='/data/SatDragModelValidation/data/inputs/atmos_models'\n",
    "run_dict={}\n",
    "for i in run_list:\n",
    "    for y_num in year_list: #, \n",
    "        for imonth,month in enumerate(month_list):\n",
    "            if y_num==2018 and month not in ['oct', 'nov', 'dec']:\n",
    "                print(f'Skipping {y_num}.{month}')\n",
    "                continue\n",
    "#             if y_num==2019 and month in ['jan', 'feb', 'mar', 'apr']:\n",
    "#                 print(f'Skipping {y_num}.{month}')\n",
    "#                 continue\n",
    "\n",
    "            if i =='msis2':\n",
    "                run_dict[str(y_num)+month+i]={}\n",
    "                run_dict[str(y_num)+month+i]['num'] = 5\n",
    "                run_dict[str(y_num)+month+i]['model_path'] = None\n",
    "            if i =='dtm2020_o':\n",
    "                run_dict[str(y_num)+month+i]={}\n",
    "                run_dict[str(y_num)+month+i]['num'] = 3\n",
    "                run_dict[str(y_num)+month+i]['model_path'] = None\n",
    "            if i =='jb2008':\n",
    "                run_dict[str(y_num)+month+i]={}\n",
    "                run_dict[str(y_num)+month+i]['num'] = 1\n",
    "                run_dict[str(y_num)+month+i]['model_path'] = None\n",
    "            if i =='hasdm_oc':\n",
    "                run_dict[str(y_num)+month+i]={}\n",
    "                run_dict[str(y_num)+month+i]['num'] = 2 \n",
    "                run_dict[str(y_num)+month+i]['model_path'] = dir_modeldat+'/hasdm/sethasdm_orbitclouds' #HASDM_OrbitCloud_2018313.01.csv\n",
    "\n",
    "\n",
    "print(run_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5686bd73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:13.263173Z",
     "start_time": "2025-01-28T19:11:13.257097Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35180af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:13.274393Z",
     "start_time": "2025-01-28T19:11:13.265668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dec']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b05ec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:16.665652Z",
     "start_time": "2025-01-28T19:11:13.277257Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2018.335    , 2018-11-30 21:18:00 ,  2018-12-02 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-01 00:00:00'), Timestamp('2018-12-01 03:00:00'), Timestamp('2018-12-01 06:00:00'), Timestamp('2018-12-01 09:00:00'), Timestamp('2018-12-01 12:00:00'), Timestamp('2018-12-01 15:00:00'), Timestamp('2018-12-01 18:00:00'), Timestamp('2018-12-01 21:00:00'), Timestamp('2018-12-02 00:00:00'), Timestamp('2018-12-02 02:42:00')]\n",
      "\n",
      " 2018.336    , 2018-12-01 21:18:00 ,  2018-12-03 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-02 00:00:00'), Timestamp('2018-12-02 03:00:00'), Timestamp('2018-12-02 06:00:00'), Timestamp('2018-12-02 09:00:00'), Timestamp('2018-12-02 12:00:00'), Timestamp('2018-12-02 15:00:00'), Timestamp('2018-12-02 18:00:00'), Timestamp('2018-12-02 21:00:00'), Timestamp('2018-12-03 00:00:00'), Timestamp('2018-12-03 02:42:00')]\n",
      "\n",
      " 2018.337    , 2018-12-02 21:18:00 ,  2018-12-04 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-03 00:00:00'), Timestamp('2018-12-03 03:00:00'), Timestamp('2018-12-03 06:00:00'), Timestamp('2018-12-03 09:00:00'), Timestamp('2018-12-03 12:00:00'), Timestamp('2018-12-03 15:00:00'), Timestamp('2018-12-03 18:00:00'), Timestamp('2018-12-03 21:00:00'), Timestamp('2018-12-04 00:00:00'), Timestamp('2018-12-04 02:42:00')]\n",
      "\n",
      " 2018.338    , 2018-12-03 21:18:00 ,  2018-12-05 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-04 00:00:00'), Timestamp('2018-12-04 03:00:00'), Timestamp('2018-12-04 06:00:00'), Timestamp('2018-12-04 09:00:00'), Timestamp('2018-12-04 12:00:00'), Timestamp('2018-12-04 15:00:00'), Timestamp('2018-12-04 18:00:00'), Timestamp('2018-12-04 21:00:00'), Timestamp('2018-12-05 00:00:00'), Timestamp('2018-12-05 02:42:00')]\n",
      "\n",
      " 2018.339A   , 2018-12-04 21:18:00 ,  2018-12-05 13:58:00 , 16.666666666666668\n",
      "             , [Timestamp('2018-12-05 00:00:00'), Timestamp('2018-12-05 03:00:00'), Timestamp('2018-12-05 06:00:00'), Timestamp('2018-12-05 09:00:00'), Timestamp('2018-12-05 12:00:00'), Timestamp('2018-12-05 13:58:00')]\n",
      "\n",
      " 2018.340A   , 2018-12-05 22:22:00 ,  2018-12-06 14:30:00 , 16.133333333333333\n",
      "             , [Timestamp('2018-12-06 00:00:00'), Timestamp('2018-12-06 03:00:00'), Timestamp('2018-12-06 06:00:00'), Timestamp('2018-12-06 09:00:00'), Timestamp('2018-12-06 12:00:00'), Timestamp('2018-12-06 14:30:00')]\n",
      "\n",
      " 2018.340B   , 2018-12-06 16:54:00 ,  2018-12-07 02:42:00 , 9.8\n",
      "             , [Timestamp('2018-12-06 00:00:00'), Timestamp('2018-12-06 03:00:00'), Timestamp('2018-12-06 06:00:00'), Timestamp('2018-12-06 09:00:00'), Timestamp('2018-12-06 12:00:00'), Timestamp('2018-12-06 15:00:00'), Timestamp('2018-12-06 18:00:00'), Timestamp('2018-12-06 21:00:00'), Timestamp('2018-12-07 00:00:00'), Timestamp('2018-12-07 02:42:00')]\n",
      "\n",
      " 2018.341    , 2018-12-06 21:18:00 ,  2018-12-08 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-07 00:00:00'), Timestamp('2018-12-07 03:00:00'), Timestamp('2018-12-07 06:00:00'), Timestamp('2018-12-07 09:00:00'), Timestamp('2018-12-07 12:00:00'), Timestamp('2018-12-07 15:00:00'), Timestamp('2018-12-07 18:00:00'), Timestamp('2018-12-07 21:00:00'), Timestamp('2018-12-08 00:00:00'), Timestamp('2018-12-08 02:42:00')]\n",
      "\n",
      " 2018.342A   , 2018-12-07 21:18:00 ,  2018-12-08 21:42:00 , 24.4\n",
      "             , [Timestamp('2018-12-08 00:00:00'), Timestamp('2018-12-08 03:00:00'), Timestamp('2018-12-08 06:00:00'), Timestamp('2018-12-08 09:00:00'), Timestamp('2018-12-08 12:00:00'), Timestamp('2018-12-08 15:00:00'), Timestamp('2018-12-08 18:00:00'), Timestamp('2018-12-08 21:00:00'), Timestamp('2018-12-08 21:42:00')]\n",
      "\n",
      " 2018.343A   , 2018-12-09 10:13:00 ,  2018-12-09 23:38:00 , 13.416666666666666\n",
      "             , [Timestamp('2018-12-09 00:00:00'), Timestamp('2018-12-09 03:00:00'), Timestamp('2018-12-09 06:00:00'), Timestamp('2018-12-09 09:00:00'), Timestamp('2018-12-09 12:00:00'), Timestamp('2018-12-09 15:00:00'), Timestamp('2018-12-09 18:00:00'), Timestamp('2018-12-09 21:00:00'), Timestamp('2018-12-09 23:38:00')]\n",
      "\n",
      " 2018.344A   , 2018-12-10 08:13:00 ,  2018-12-11 02:42:00 , 18.483333333333334\n",
      "             , [Timestamp('2018-12-10 00:00:00'), Timestamp('2018-12-10 03:00:00'), Timestamp('2018-12-10 06:00:00'), Timestamp('2018-12-10 09:00:00'), Timestamp('2018-12-10 12:00:00'), Timestamp('2018-12-10 15:00:00'), Timestamp('2018-12-10 18:00:00'), Timestamp('2018-12-10 21:00:00'), Timestamp('2018-12-11 00:00:00'), Timestamp('2018-12-11 02:42:00')]\n",
      "\n",
      " 2018.345    , 2018-12-10 21:18:00 ,  2018-12-12 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-11 00:00:00'), Timestamp('2018-12-11 03:00:00'), Timestamp('2018-12-11 06:00:00'), Timestamp('2018-12-11 09:00:00'), Timestamp('2018-12-11 12:00:00'), Timestamp('2018-12-11 15:00:00'), Timestamp('2018-12-11 18:00:00'), Timestamp('2018-12-11 21:00:00'), Timestamp('2018-12-12 00:00:00'), Timestamp('2018-12-12 02:42:00')]\n",
      "\n",
      " 2018.346A   , 2018-12-11 21:18:00 ,  2018-12-13 00:30:00 , 27.2\n",
      "             , [Timestamp('2018-12-12 00:00:00'), Timestamp('2018-12-12 03:00:00'), Timestamp('2018-12-12 06:00:00'), Timestamp('2018-12-12 09:00:00'), Timestamp('2018-12-12 12:00:00'), Timestamp('2018-12-12 15:00:00'), Timestamp('2018-12-12 18:00:00'), Timestamp('2018-12-12 21:00:00'), Timestamp('2018-12-13 00:00:00'), Timestamp('2018-12-13 00:30:00')]\n",
      "\n",
      " 2018.347A   , 2018-12-13 01:54:00 ,  2018-12-14 02:42:00 , 24.8\n",
      "             , [Timestamp('2018-12-13 00:00:00'), Timestamp('2018-12-13 03:00:00'), Timestamp('2018-12-13 06:00:00'), Timestamp('2018-12-13 09:00:00'), Timestamp('2018-12-13 12:00:00'), Timestamp('2018-12-13 15:00:00'), Timestamp('2018-12-13 18:00:00'), Timestamp('2018-12-13 21:00:00'), Timestamp('2018-12-14 00:00:00'), Timestamp('2018-12-14 02:42:00')]\n",
      "\n",
      " 2018.348    , 2018-12-13 21:18:00 ,  2018-12-15 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-14 00:00:00'), Timestamp('2018-12-14 03:00:00'), Timestamp('2018-12-14 06:00:00'), Timestamp('2018-12-14 09:00:00'), Timestamp('2018-12-14 12:00:00'), Timestamp('2018-12-14 15:00:00'), Timestamp('2018-12-14 18:00:00'), Timestamp('2018-12-14 21:00:00'), Timestamp('2018-12-15 00:00:00'), Timestamp('2018-12-15 02:42:00')]\n",
      "\n",
      " 2018.349    , 2018-12-14 21:18:00 ,  2018-12-16 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-15 00:00:00'), Timestamp('2018-12-15 03:00:00'), Timestamp('2018-12-15 06:00:00'), Timestamp('2018-12-15 09:00:00'), Timestamp('2018-12-15 12:00:00'), Timestamp('2018-12-15 15:00:00'), Timestamp('2018-12-15 18:00:00'), Timestamp('2018-12-15 21:00:00'), Timestamp('2018-12-16 00:00:00'), Timestamp('2018-12-16 02:42:00')]\n",
      "\n",
      " 2018.350    , 2018-12-15 21:18:00 ,  2018-12-17 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-16 00:00:00'), Timestamp('2018-12-16 03:00:00'), Timestamp('2018-12-16 06:00:00'), Timestamp('2018-12-16 09:00:00'), Timestamp('2018-12-16 12:00:00'), Timestamp('2018-12-16 15:00:00'), Timestamp('2018-12-16 18:00:00'), Timestamp('2018-12-16 21:00:00'), Timestamp('2018-12-17 00:00:00'), Timestamp('2018-12-17 02:42:00')]\n",
      "\n",
      " 2018.351    , 2018-12-16 21:18:00 ,  2018-12-18 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-17 00:00:00'), Timestamp('2018-12-17 03:00:00'), Timestamp('2018-12-17 06:00:00'), Timestamp('2018-12-17 09:00:00'), Timestamp('2018-12-17 12:00:00'), Timestamp('2018-12-17 15:00:00'), Timestamp('2018-12-17 18:00:00'), Timestamp('2018-12-17 21:00:00'), Timestamp('2018-12-18 00:00:00'), Timestamp('2018-12-18 02:42:00')]\n",
      "\n",
      " 2018.352    , 2018-12-17 21:18:00 ,  2018-12-19 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-18 00:00:00'), Timestamp('2018-12-18 03:00:00'), Timestamp('2018-12-18 06:00:00'), Timestamp('2018-12-18 09:00:00'), Timestamp('2018-12-18 12:00:00'), Timestamp('2018-12-18 15:00:00'), Timestamp('2018-12-18 18:00:00'), Timestamp('2018-12-18 21:00:00'), Timestamp('2018-12-19 00:00:00'), Timestamp('2018-12-19 02:42:00')]\n",
      "\n",
      " 2018.353    , 2018-12-18 21:18:00 ,  2018-12-20 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-19 00:00:00'), Timestamp('2018-12-19 03:00:00'), Timestamp('2018-12-19 06:00:00'), Timestamp('2018-12-19 09:00:00'), Timestamp('2018-12-19 12:00:00'), Timestamp('2018-12-19 15:00:00'), Timestamp('2018-12-19 18:00:00'), Timestamp('2018-12-19 21:00:00'), Timestamp('2018-12-20 00:00:00'), Timestamp('2018-12-20 02:42:00')]\n",
      "\n",
      " 2018.354A   , 2018-12-19 21:18:00 ,  2018-12-20 13:18:00 , 16.0\n",
      "             , [Timestamp('2018-12-20 00:00:00'), Timestamp('2018-12-20 03:00:00'), Timestamp('2018-12-20 06:00:00'), Timestamp('2018-12-20 09:00:00'), Timestamp('2018-12-20 12:00:00'), Timestamp('2018-12-20 13:18:00')]\n",
      "\n",
      " 2018.354B   , 2018-12-20 14:36:00 ,  2018-12-21 02:42:00 , 12.1\n",
      "             , [Timestamp('2018-12-20 00:00:00'), Timestamp('2018-12-20 03:00:00'), Timestamp('2018-12-20 06:00:00'), Timestamp('2018-12-20 09:00:00'), Timestamp('2018-12-20 12:00:00'), Timestamp('2018-12-20 15:00:00'), Timestamp('2018-12-20 18:00:00'), Timestamp('2018-12-20 21:00:00'), Timestamp('2018-12-21 00:00:00'), Timestamp('2018-12-21 02:42:00')]\n",
      "\n",
      " 2018.355    , 2018-12-20 21:18:00 ,  2018-12-22 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-21 00:00:00'), Timestamp('2018-12-21 03:00:00'), Timestamp('2018-12-21 06:00:00'), Timestamp('2018-12-21 09:00:00'), Timestamp('2018-12-21 12:00:00'), Timestamp('2018-12-21 15:00:00'), Timestamp('2018-12-21 18:00:00'), Timestamp('2018-12-21 21:00:00'), Timestamp('2018-12-22 00:00:00'), Timestamp('2018-12-22 02:42:00')]\n",
      "\n",
      " 2018.356    , 2018-12-21 21:18:00 ,  2018-12-23 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-22 00:00:00'), Timestamp('2018-12-22 03:00:00'), Timestamp('2018-12-22 06:00:00'), Timestamp('2018-12-22 09:00:00'), Timestamp('2018-12-22 12:00:00'), Timestamp('2018-12-22 15:00:00'), Timestamp('2018-12-22 18:00:00'), Timestamp('2018-12-22 21:00:00'), Timestamp('2018-12-23 00:00:00'), Timestamp('2018-12-23 02:42:00')]\n",
      "\n",
      " 2018.357    , 2018-12-22 21:18:00 ,  2018-12-24 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-23 00:00:00'), Timestamp('2018-12-23 03:00:00'), Timestamp('2018-12-23 06:00:00'), Timestamp('2018-12-23 09:00:00'), Timestamp('2018-12-23 12:00:00'), Timestamp('2018-12-23 15:00:00'), Timestamp('2018-12-23 18:00:00'), Timestamp('2018-12-23 21:00:00'), Timestamp('2018-12-24 00:00:00'), Timestamp('2018-12-24 02:42:00')]\n",
      "\n",
      " 2018.358    , 2018-12-23 21:18:00 ,  2018-12-25 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-24 00:00:00'), Timestamp('2018-12-24 03:00:00'), Timestamp('2018-12-24 06:00:00'), Timestamp('2018-12-24 09:00:00'), Timestamp('2018-12-24 12:00:00'), Timestamp('2018-12-24 15:00:00'), Timestamp('2018-12-24 18:00:00'), Timestamp('2018-12-24 21:00:00'), Timestamp('2018-12-25 00:00:00'), Timestamp('2018-12-25 02:42:00')]\n",
      "\n",
      " 2018.359    , 2018-12-24 21:18:00 ,  2018-12-26 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-25 00:00:00'), Timestamp('2018-12-25 03:00:00'), Timestamp('2018-12-25 06:00:00'), Timestamp('2018-12-25 09:00:00'), Timestamp('2018-12-25 12:00:00'), Timestamp('2018-12-25 15:00:00'), Timestamp('2018-12-25 18:00:00'), Timestamp('2018-12-25 21:00:00'), Timestamp('2018-12-26 00:00:00'), Timestamp('2018-12-26 02:42:00')]\n",
      "\n",
      " 2018.360A   , 2018-12-25 21:18:00 ,  2018-12-27 00:48:00 , 27.5\n",
      "             , [Timestamp('2018-12-26 00:00:00'), Timestamp('2018-12-26 03:00:00'), Timestamp('2018-12-26 06:00:00'), Timestamp('2018-12-26 09:00:00'), Timestamp('2018-12-26 12:00:00'), Timestamp('2018-12-26 15:00:00'), Timestamp('2018-12-26 18:00:00'), Timestamp('2018-12-26 21:00:00'), Timestamp('2018-12-27 00:00:00'), Timestamp('2018-12-27 00:48:00')]\n",
      "\n",
      " 2018.361A   , 2018-12-27 02:18:00 ,  2018-12-28 02:42:00 , 24.4\n",
      "             , [Timestamp('2018-12-27 00:00:00'), Timestamp('2018-12-27 03:00:00'), Timestamp('2018-12-27 06:00:00'), Timestamp('2018-12-27 09:00:00'), Timestamp('2018-12-27 12:00:00'), Timestamp('2018-12-27 15:00:00'), Timestamp('2018-12-27 18:00:00'), Timestamp('2018-12-27 21:00:00'), Timestamp('2018-12-28 00:00:00'), Timestamp('2018-12-28 02:42:00')]\n",
      "\n",
      " 2018.362A   , 2018-12-27 21:18:00 ,  2018-12-28 18:34:00 , 21.266666666666666\n",
      "             , [Timestamp('2018-12-28 00:00:00'), Timestamp('2018-12-28 03:00:00'), Timestamp('2018-12-28 06:00:00'), Timestamp('2018-12-28 09:00:00'), Timestamp('2018-12-28 12:00:00'), Timestamp('2018-12-28 15:00:00'), Timestamp('2018-12-28 18:00:00'), Timestamp('2018-12-28 18:34:00')]\n",
      "\n",
      " 2018.363A   , 2018-12-28 19:22:00 ,  2018-12-30 02:42:00 , 31.333333333333332\n",
      "             , [Timestamp('2018-12-29 00:00:00'), Timestamp('2018-12-29 03:00:00'), Timestamp('2018-12-29 06:00:00'), Timestamp('2018-12-29 09:00:00'), Timestamp('2018-12-29 12:00:00'), Timestamp('2018-12-29 15:00:00'), Timestamp('2018-12-29 18:00:00'), Timestamp('2018-12-29 21:00:00'), Timestamp('2018-12-30 00:00:00'), Timestamp('2018-12-30 02:42:00')]\n",
      "\n",
      " 2018.364    , 2018-12-29 21:18:00 ,  2018-12-31 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-30 00:00:00'), Timestamp('2018-12-30 03:00:00'), Timestamp('2018-12-30 06:00:00'), Timestamp('2018-12-30 09:00:00'), Timestamp('2018-12-30 12:00:00'), Timestamp('2018-12-30 15:00:00'), Timestamp('2018-12-30 18:00:00'), Timestamp('2018-12-30 21:00:00'), Timestamp('2018-12-31 00:00:00'), Timestamp('2018-12-31 02:42:00')]\n",
      "\n",
      " 2018.365    , 2018-12-30 21:18:00 ,  2019-01-01 02:42:00 , 29.4\n",
      "             , [Timestamp('2018-12-31 00:00:00'), Timestamp('2018-12-31 03:00:00'), Timestamp('2018-12-31 06:00:00'), Timestamp('2018-12-31 09:00:00'), Timestamp('2018-12-31 12:00:00'), Timestamp('2018-12-31 15:00:00'), Timestamp('2018-12-31 18:00:00'), Timestamp('2018-12-31 21:00:00'), Timestamp('2019-01-01 00:00:00'), Timestamp('2019-01-01 02:42:00')]\n",
      "\n",
      " 2019.335    , 2019-11-30 21:18:00 ,  2019-12-02 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-01 00:00:00'), Timestamp('2019-12-01 03:00:00'), Timestamp('2019-12-01 06:00:00'), Timestamp('2019-12-01 09:00:00'), Timestamp('2019-12-01 12:00:00'), Timestamp('2019-12-01 15:00:00'), Timestamp('2019-12-01 18:00:00'), Timestamp('2019-12-01 21:00:00'), Timestamp('2019-12-02 00:00:00'), Timestamp('2019-12-02 02:42:00')]\n",
      "\n",
      " 2019.336A   , 2019-12-01 21:18:00 ,  2019-12-02 15:00:00 , 17.7\n",
      "             , [Timestamp('2019-12-02 00:00:00'), Timestamp('2019-12-02 03:00:00'), Timestamp('2019-12-02 06:00:00'), Timestamp('2019-12-02 09:00:00'), Timestamp('2019-12-02 12:00:00'), Timestamp('2019-12-02 15:00:00')]\n",
      "\n",
      " 2019.336B   , 2019-12-02 16:18:00 ,  2019-12-03 02:42:00 , 10.4\n",
      "             , [Timestamp('2019-12-02 00:00:00'), Timestamp('2019-12-02 03:00:00'), Timestamp('2019-12-02 06:00:00'), Timestamp('2019-12-02 09:00:00'), Timestamp('2019-12-02 12:00:00'), Timestamp('2019-12-02 15:00:00'), Timestamp('2019-12-02 18:00:00'), Timestamp('2019-12-02 21:00:00'), Timestamp('2019-12-03 00:00:00'), Timestamp('2019-12-03 02:42:00')]\n",
      "\n",
      " 2019.337    , 2019-12-02 21:18:00 ,  2019-12-04 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-03 00:00:00'), Timestamp('2019-12-03 03:00:00'), Timestamp('2019-12-03 06:00:00'), Timestamp('2019-12-03 09:00:00'), Timestamp('2019-12-03 12:00:00'), Timestamp('2019-12-03 15:00:00'), Timestamp('2019-12-03 18:00:00'), Timestamp('2019-12-03 21:00:00'), Timestamp('2019-12-04 00:00:00'), Timestamp('2019-12-04 02:42:00')]\n",
      "\n",
      " 2019.338    , 2019-12-03 21:18:00 ,  2019-12-05 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-04 00:00:00'), Timestamp('2019-12-04 03:00:00'), Timestamp('2019-12-04 06:00:00'), Timestamp('2019-12-04 09:00:00'), Timestamp('2019-12-04 12:00:00'), Timestamp('2019-12-04 15:00:00'), Timestamp('2019-12-04 18:00:00'), Timestamp('2019-12-04 21:00:00'), Timestamp('2019-12-05 00:00:00'), Timestamp('2019-12-05 02:42:00')]\n",
      "\n",
      " 2019.339    , 2019-12-04 21:18:00 ,  2019-12-06 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-05 00:00:00'), Timestamp('2019-12-05 03:00:00'), Timestamp('2019-12-05 06:00:00'), Timestamp('2019-12-05 09:00:00'), Timestamp('2019-12-05 12:00:00'), Timestamp('2019-12-05 15:00:00'), Timestamp('2019-12-05 18:00:00'), Timestamp('2019-12-05 21:00:00'), Timestamp('2019-12-06 00:00:00'), Timestamp('2019-12-06 02:42:00')]\n",
      "\n",
      " 2019.340    , 2019-12-05 21:18:00 ,  2019-12-07 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-06 00:00:00'), Timestamp('2019-12-06 03:00:00'), Timestamp('2019-12-06 06:00:00'), Timestamp('2019-12-06 09:00:00'), Timestamp('2019-12-06 12:00:00'), Timestamp('2019-12-06 15:00:00'), Timestamp('2019-12-06 18:00:00'), Timestamp('2019-12-06 21:00:00'), Timestamp('2019-12-07 00:00:00'), Timestamp('2019-12-07 02:42:00')]\n",
      "\n",
      " 2019.341    , 2019-12-06 21:18:00 ,  2019-12-08 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-07 00:00:00'), Timestamp('2019-12-07 03:00:00'), Timestamp('2019-12-07 06:00:00'), Timestamp('2019-12-07 09:00:00'), Timestamp('2019-12-07 12:00:00'), Timestamp('2019-12-07 15:00:00'), Timestamp('2019-12-07 18:00:00'), Timestamp('2019-12-07 21:00:00'), Timestamp('2019-12-08 00:00:00'), Timestamp('2019-12-08 02:42:00')]\n",
      "\n",
      " 2019.342    , 2019-12-07 21:18:00 ,  2019-12-09 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-08 00:00:00'), Timestamp('2019-12-08 03:00:00'), Timestamp('2019-12-08 06:00:00'), Timestamp('2019-12-08 09:00:00'), Timestamp('2019-12-08 12:00:00'), Timestamp('2019-12-08 15:00:00'), Timestamp('2019-12-08 18:00:00'), Timestamp('2019-12-08 21:00:00'), Timestamp('2019-12-09 00:00:00'), Timestamp('2019-12-09 02:42:00')]\n",
      "\n",
      " 2019.343    , 2019-12-08 21:18:00 ,  2019-12-10 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-09 00:00:00'), Timestamp('2019-12-09 03:00:00'), Timestamp('2019-12-09 06:00:00'), Timestamp('2019-12-09 09:00:00'), Timestamp('2019-12-09 12:00:00'), Timestamp('2019-12-09 15:00:00'), Timestamp('2019-12-09 18:00:00'), Timestamp('2019-12-09 21:00:00'), Timestamp('2019-12-10 00:00:00'), Timestamp('2019-12-10 02:42:00')]\n",
      "\n",
      " 2019.344    , 2019-12-09 21:18:00 ,  2019-12-11 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-10 00:00:00'), Timestamp('2019-12-10 03:00:00'), Timestamp('2019-12-10 06:00:00'), Timestamp('2019-12-10 09:00:00'), Timestamp('2019-12-10 12:00:00'), Timestamp('2019-12-10 15:00:00'), Timestamp('2019-12-10 18:00:00'), Timestamp('2019-12-10 21:00:00'), Timestamp('2019-12-11 00:00:00'), Timestamp('2019-12-11 02:42:00')]\n",
      "\n",
      " 2019.345    , 2019-12-10 21:18:00 ,  2019-12-12 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-11 00:00:00'), Timestamp('2019-12-11 03:00:00'), Timestamp('2019-12-11 06:00:00'), Timestamp('2019-12-11 09:00:00'), Timestamp('2019-12-11 12:00:00'), Timestamp('2019-12-11 15:00:00'), Timestamp('2019-12-11 18:00:00'), Timestamp('2019-12-11 21:00:00'), Timestamp('2019-12-12 00:00:00'), Timestamp('2019-12-12 02:42:00')]\n",
      "\n",
      " 2019.346    , 2019-12-11 21:18:00 ,  2019-12-13 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-12 00:00:00'), Timestamp('2019-12-12 03:00:00'), Timestamp('2019-12-12 06:00:00'), Timestamp('2019-12-12 09:00:00'), Timestamp('2019-12-12 12:00:00'), Timestamp('2019-12-12 15:00:00'), Timestamp('2019-12-12 18:00:00'), Timestamp('2019-12-12 21:00:00'), Timestamp('2019-12-13 00:00:00'), Timestamp('2019-12-13 02:42:00')]\n",
      "\n",
      " 2019.347A   , 2019-12-12 21:18:00 ,  2019-12-13 14:12:00 , 16.9\n",
      "             , [Timestamp('2019-12-13 00:00:00'), Timestamp('2019-12-13 03:00:00'), Timestamp('2019-12-13 06:00:00'), Timestamp('2019-12-13 09:00:00'), Timestamp('2019-12-13 12:00:00'), Timestamp('2019-12-13 14:12:00')]\n",
      "\n",
      " 2019.347B   , 2019-12-13 15:36:00 ,  2019-12-14 02:42:00 , 11.1\n",
      "             , [Timestamp('2019-12-13 00:00:00'), Timestamp('2019-12-13 03:00:00'), Timestamp('2019-12-13 06:00:00'), Timestamp('2019-12-13 09:00:00'), Timestamp('2019-12-13 12:00:00'), Timestamp('2019-12-13 15:00:00'), Timestamp('2019-12-13 18:00:00'), Timestamp('2019-12-13 21:00:00'), Timestamp('2019-12-14 00:00:00'), Timestamp('2019-12-14 02:42:00')]\n",
      "\n",
      " 2019.348    , 2019-12-13 21:18:00 ,  2019-12-15 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-14 00:00:00'), Timestamp('2019-12-14 03:00:00'), Timestamp('2019-12-14 06:00:00'), Timestamp('2019-12-14 09:00:00'), Timestamp('2019-12-14 12:00:00'), Timestamp('2019-12-14 15:00:00'), Timestamp('2019-12-14 18:00:00'), Timestamp('2019-12-14 21:00:00'), Timestamp('2019-12-15 00:00:00'), Timestamp('2019-12-15 02:42:00')]\n",
      "\n",
      " 2019.349    , 2019-12-14 21:18:00 ,  2019-12-16 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-15 00:00:00'), Timestamp('2019-12-15 03:00:00'), Timestamp('2019-12-15 06:00:00'), Timestamp('2019-12-15 09:00:00'), Timestamp('2019-12-15 12:00:00'), Timestamp('2019-12-15 15:00:00'), Timestamp('2019-12-15 18:00:00'), Timestamp('2019-12-15 21:00:00'), Timestamp('2019-12-16 00:00:00'), Timestamp('2019-12-16 02:42:00')]\n",
      "\n",
      " 2019.350    , 2019-12-15 21:18:00 ,  2019-12-17 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-16 00:00:00'), Timestamp('2019-12-16 03:00:00'), Timestamp('2019-12-16 06:00:00'), Timestamp('2019-12-16 09:00:00'), Timestamp('2019-12-16 12:00:00'), Timestamp('2019-12-16 15:00:00'), Timestamp('2019-12-16 18:00:00'), Timestamp('2019-12-16 21:00:00'), Timestamp('2019-12-17 00:00:00'), Timestamp('2019-12-17 02:42:00')]\n",
      "\n",
      " 2019.351    , 2019-12-16 21:18:00 ,  2019-12-18 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-17 00:00:00'), Timestamp('2019-12-17 03:00:00'), Timestamp('2019-12-17 06:00:00'), Timestamp('2019-12-17 09:00:00'), Timestamp('2019-12-17 12:00:00'), Timestamp('2019-12-17 15:00:00'), Timestamp('2019-12-17 18:00:00'), Timestamp('2019-12-17 21:00:00'), Timestamp('2019-12-18 00:00:00'), Timestamp('2019-12-18 02:42:00')]\n",
      "\n",
      " 2019.352    , 2019-12-17 21:18:00 ,  2019-12-19 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-18 00:00:00'), Timestamp('2019-12-18 03:00:00'), Timestamp('2019-12-18 06:00:00'), Timestamp('2019-12-18 09:00:00'), Timestamp('2019-12-18 12:00:00'), Timestamp('2019-12-18 15:00:00'), Timestamp('2019-12-18 18:00:00'), Timestamp('2019-12-18 21:00:00'), Timestamp('2019-12-19 00:00:00'), Timestamp('2019-12-19 02:42:00')]\n",
      "\n",
      " 2019.353A   , 2019-12-18 21:18:00 ,  2019-12-19 12:12:00 , 14.9\n",
      "             , [Timestamp('2019-12-19 00:00:00'), Timestamp('2019-12-19 03:00:00'), Timestamp('2019-12-19 06:00:00'), Timestamp('2019-12-19 09:00:00'), Timestamp('2019-12-19 12:00:00'), Timestamp('2019-12-19 12:12:00')]\n",
      "\n",
      " 2019.353B   , 2019-12-19 13:54:00 ,  2019-12-20 02:42:00 , 12.8\n",
      "             , [Timestamp('2019-12-19 00:00:00'), Timestamp('2019-12-19 03:00:00'), Timestamp('2019-12-19 06:00:00'), Timestamp('2019-12-19 09:00:00'), Timestamp('2019-12-19 12:00:00'), Timestamp('2019-12-19 15:00:00'), Timestamp('2019-12-19 18:00:00'), Timestamp('2019-12-19 21:00:00'), Timestamp('2019-12-20 00:00:00'), Timestamp('2019-12-20 02:42:00')]\n",
      "\n",
      " 2019.354    , 2019-12-19 21:18:00 ,  2019-12-21 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-20 00:00:00'), Timestamp('2019-12-20 03:00:00'), Timestamp('2019-12-20 06:00:00'), Timestamp('2019-12-20 09:00:00'), Timestamp('2019-12-20 12:00:00'), Timestamp('2019-12-20 15:00:00'), Timestamp('2019-12-20 18:00:00'), Timestamp('2019-12-20 21:00:00'), Timestamp('2019-12-21 00:00:00'), Timestamp('2019-12-21 02:42:00')]\n",
      "\n",
      " 2019.355    , 2019-12-20 21:18:00 ,  2019-12-22 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-21 00:00:00'), Timestamp('2019-12-21 03:00:00'), Timestamp('2019-12-21 06:00:00'), Timestamp('2019-12-21 09:00:00'), Timestamp('2019-12-21 12:00:00'), Timestamp('2019-12-21 15:00:00'), Timestamp('2019-12-21 18:00:00'), Timestamp('2019-12-21 21:00:00'), Timestamp('2019-12-22 00:00:00'), Timestamp('2019-12-22 02:42:00')]\n",
      "\n",
      " 2019.356    , 2019-12-21 21:18:00 ,  2019-12-23 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-22 00:00:00'), Timestamp('2019-12-22 03:00:00'), Timestamp('2019-12-22 06:00:00'), Timestamp('2019-12-22 09:00:00'), Timestamp('2019-12-22 12:00:00'), Timestamp('2019-12-22 15:00:00'), Timestamp('2019-12-22 18:00:00'), Timestamp('2019-12-22 21:00:00'), Timestamp('2019-12-23 00:00:00'), Timestamp('2019-12-23 02:42:00')]\n",
      "\n",
      " 2019.357    , 2019-12-22 21:18:00 ,  2019-12-24 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-23 00:00:00'), Timestamp('2019-12-23 03:00:00'), Timestamp('2019-12-23 06:00:00'), Timestamp('2019-12-23 09:00:00'), Timestamp('2019-12-23 12:00:00'), Timestamp('2019-12-23 15:00:00'), Timestamp('2019-12-23 18:00:00'), Timestamp('2019-12-23 21:00:00'), Timestamp('2019-12-24 00:00:00'), Timestamp('2019-12-24 02:42:00')]\n",
      "\n",
      " 2019.358    , 2019-12-23 21:18:00 ,  2019-12-25 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-24 00:00:00'), Timestamp('2019-12-24 03:00:00'), Timestamp('2019-12-24 06:00:00'), Timestamp('2019-12-24 09:00:00'), Timestamp('2019-12-24 12:00:00'), Timestamp('2019-12-24 15:00:00'), Timestamp('2019-12-24 18:00:00'), Timestamp('2019-12-24 21:00:00'), Timestamp('2019-12-25 00:00:00'), Timestamp('2019-12-25 02:42:00')]\n",
      "\n",
      " 2019.359    , 2019-12-24 21:18:00 ,  2019-12-26 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-25 00:00:00'), Timestamp('2019-12-25 03:00:00'), Timestamp('2019-12-25 06:00:00'), Timestamp('2019-12-25 09:00:00'), Timestamp('2019-12-25 12:00:00'), Timestamp('2019-12-25 15:00:00'), Timestamp('2019-12-25 18:00:00'), Timestamp('2019-12-25 21:00:00'), Timestamp('2019-12-26 00:00:00'), Timestamp('2019-12-26 02:42:00')]\n",
      "\n",
      " 2019.360    , 2019-12-25 21:18:00 ,  2019-12-27 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-26 00:00:00'), Timestamp('2019-12-26 03:00:00'), Timestamp('2019-12-26 06:00:00'), Timestamp('2019-12-26 09:00:00'), Timestamp('2019-12-26 12:00:00'), Timestamp('2019-12-26 15:00:00'), Timestamp('2019-12-26 18:00:00'), Timestamp('2019-12-26 21:00:00'), Timestamp('2019-12-27 00:00:00'), Timestamp('2019-12-27 02:42:00')]\n",
      "\n",
      " 2019.361    , 2019-12-26 21:18:00 ,  2019-12-28 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-27 00:00:00'), Timestamp('2019-12-27 03:00:00'), Timestamp('2019-12-27 06:00:00'), Timestamp('2019-12-27 09:00:00'), Timestamp('2019-12-27 12:00:00'), Timestamp('2019-12-27 15:00:00'), Timestamp('2019-12-27 18:00:00'), Timestamp('2019-12-27 21:00:00'), Timestamp('2019-12-28 00:00:00'), Timestamp('2019-12-28 02:42:00')]\n",
      "\n",
      " 2019.362    , 2019-12-27 21:18:00 ,  2019-12-29 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-28 00:00:00'), Timestamp('2019-12-28 03:00:00'), Timestamp('2019-12-28 06:00:00'), Timestamp('2019-12-28 09:00:00'), Timestamp('2019-12-28 12:00:00'), Timestamp('2019-12-28 15:00:00'), Timestamp('2019-12-28 18:00:00'), Timestamp('2019-12-28 21:00:00'), Timestamp('2019-12-29 00:00:00'), Timestamp('2019-12-29 02:42:00')]\n",
      "\n",
      " 2019.363    , 2019-12-28 21:18:00 ,  2019-12-30 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-29 00:00:00'), Timestamp('2019-12-29 03:00:00'), Timestamp('2019-12-29 06:00:00'), Timestamp('2019-12-29 09:00:00'), Timestamp('2019-12-29 12:00:00'), Timestamp('2019-12-29 15:00:00'), Timestamp('2019-12-29 18:00:00'), Timestamp('2019-12-29 21:00:00'), Timestamp('2019-12-30 00:00:00'), Timestamp('2019-12-30 02:42:00')]\n",
      "\n",
      " 2019.364    , 2019-12-29 21:18:00 ,  2019-12-31 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-30 00:00:00'), Timestamp('2019-12-30 03:00:00'), Timestamp('2019-12-30 06:00:00'), Timestamp('2019-12-30 09:00:00'), Timestamp('2019-12-30 12:00:00'), Timestamp('2019-12-30 15:00:00'), Timestamp('2019-12-30 18:00:00'), Timestamp('2019-12-30 21:00:00'), Timestamp('2019-12-31 00:00:00'), Timestamp('2019-12-31 02:42:00')]\n",
      "\n",
      " 2019.365    , 2019-12-30 21:18:00 ,  2020-01-01 02:42:00 , 29.4\n",
      "             , [Timestamp('2019-12-31 00:00:00'), Timestamp('2019-12-31 03:00:00'), Timestamp('2019-12-31 06:00:00'), Timestamp('2019-12-31 09:00:00'), Timestamp('2019-12-31 12:00:00'), Timestamp('2019-12-31 15:00:00'), Timestamp('2019-12-31 18:00:00'), Timestamp('2019-12-31 21:00:00'), Timestamp('2020-01-01 00:00:00'), Timestamp('2020-01-01 02:42:00')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "arc_timesfile = '/data/SatDragModelValidation/data/inputs/raw_inputdata/data_ICESat2/arc_times.txt'\n",
    "\n",
    "### Make a function that finds the right range of dates in this file.\n",
    "arcs = pd.read_csv(arc_timesfile, \n",
    "            sep = ',',\n",
    "#             dtype=object,\n",
    "            names = [\n",
    "                'arc'         ,\n",
    "                'epoch_start' ,\n",
    "                'epoch_stop'  ,\n",
    "                'orbit_start' ,\n",
    "                'orbit_stop'  ,\n",
    "                    ],)\n",
    "\n",
    "\n",
    "arcs_yyyyddd = [x.strip() for x in arcs['arc'].values.tolist()]\n",
    "epochstart   = [x.strip() for x in arcs['orbit_start'].values.tolist()]\n",
    "epochstop    = [x.strip() for x in arcs['orbit_stop' ].values.tolist()]\n",
    "\n",
    "\n",
    "input_arcs       = []\n",
    "input_epochstart = []\n",
    "input_epochstop  = []\n",
    "arc_length = []\n",
    "scaleparameter_times = []\n",
    "\n",
    "for y_num in year_list:\n",
    "\n",
    "    for imonth,month in enumerate(month_list):\n",
    "        if month=='jan':  m_num = 1\n",
    "        if month=='feb':  m_num = 2\n",
    "        if month=='mar':  m_num = 3\n",
    "        if month=='apr':  m_num = 4\n",
    "        if month=='may':  m_num = 5\n",
    "        if month=='jun':  m_num = 6\n",
    "        if month=='jul':  m_num = 7\n",
    "        if month=='aug':  m_num = 8\n",
    "        if month=='sep':  m_num = 9\n",
    "        if month=='oct':  m_num = 10\n",
    "        if month=='nov':  m_num = 11\n",
    "        if month=='dec':  m_num = 12\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i,val in enumerate(arcs_yyyyddd):\n",
    "\n",
    "            if pd.to_datetime(val[:8],format=\"%Y.%j\").month == m_num and pd.to_datetime(val[:8],format=\"%Y.%j\").year == y_num:\n",
    "                epoch_delta  =  pd.to_timedelta(pd.to_datetime(epochstop[i]) - pd.to_datetime(epochstart[i]), 'hours')\n",
    "                arc_length.append(epoch_delta.total_seconds()/3600)\n",
    "\n",
    "                if val[8:] == 'A' or val[8:] == 'B':\n",
    "                    input_arcs.append(      arcs_yyyyddd[i])\n",
    "                    input_epochstart.append(epochstart[i])\n",
    "                    input_epochstop.append( epochstop[i])\n",
    "    #                 scaleparameter_times.append(dict_sftime[arcs_yyyyddd[i]])\n",
    "                    scalestart = str(pd.to_datetime(arcs_yyyyddd[i][:-1],format=\"%Y.%j\"))\n",
    "                    scalestop  = str(pd.to_datetime(arcs_yyyyddd[i][:-1],format=\"%Y.%j\") + pd.to_timedelta(24,'h'))\n",
    "                    scaletimes = pd.date_range(start = pd.to_datetime(scalestart),\n",
    "                                                              end   = pd.to_datetime( epochstop[i] ),\n",
    "                                                              freq=str(scale_cadence)+\"h\")\n",
    "                    \n",
    "                    if epochstop[i] in scaletimes:  ## dont add repeats to the final epoch time\n",
    "                        ### Append the epoch end time to the end\n",
    "                        add_epochend = scaletimes.values.astype(np.int64) // 10 ** 9\n",
    "                                        #np.append(scaletimes.values.astype(np.int64) // 10 ** 9,\n",
    "                                      #pd.to_datetime(pd.Series(epochstop[i])).values.astype(np.int64) // 10 ** 9)\n",
    "\n",
    "                        scaleparameter_times.append([pd.to_datetime(datetime.strftime(datetime.fromtimestamp(ts), '%y%m%d%H%M%S.%f'),\n",
    "                            format ='%y%m%d%H%M%S.%f' )\n",
    "                                         for ts in add_epochend  ])\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        ### Append the epoch end time to the end\n",
    "                        add_epochend = np.append(scaletimes.values.astype(np.int64) // 10 ** 9,\n",
    "                                      pd.to_datetime(pd.Series(epochstop[i])).values.astype(np.int64) // 10 ** 9)\n",
    "\n",
    "\n",
    "                        scaleparameter_times.append([pd.to_datetime(datetime.strftime(datetime.fromtimestamp(ts), '%y%m%d%H%M%S.%f'),\n",
    "                            format ='%y%m%d%H%M%S.%f' )\n",
    "                                         for ts in add_epochend  ])\n",
    "\n",
    "                    pass\n",
    "                else:\n",
    "\n",
    "                    ### Use Arc text file times\n",
    "                    input_arcs.append(      arcs_yyyyddd[i])\n",
    "                    input_epochstart.append(epochstart[i])\n",
    "                    input_epochstop.append( epochstop[i])\n",
    "    #                 print(f\"epoch_top {epochstop[i]}\")\n",
    "                    scalestart = str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\"))\n",
    "                    scalestop  = str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\") + pd.to_timedelta(24,'h'))\n",
    "                    scaletimes = pd.date_range(start = pd.to_datetime(scalestart),\n",
    "                                                              end   = pd.to_datetime(scalestop ),\n",
    "                                                              freq=str(scale_cadence)+\"h\")\n",
    "\n",
    "                    ### Append the epoch end time to the end\n",
    "                    add_epochend = np.append(scaletimes.values.astype(np.int64) // 10 ** 9,\n",
    "                                  pd.to_datetime(pd.Series(epochstop[i])).values.astype(np.int64) // 10 ** 9)\n",
    "\n",
    "\n",
    "                    scaleparameter_times.append([pd.to_datetime(datetime.strftime(datetime.fromtimestamp(ts), '%y%m%d%H%M%S.%f'),\n",
    "                        format ='%y%m%d%H%M%S.%f' )\n",
    "                                     for ts in add_epochend ])\n",
    "for i,val in enumerate(input_arcs):\n",
    "    print(f\" {input_arcs[i]:10}  , {input_epochstart[i]:20},  {input_epochstop[i]:20}, {arc_length[i]}\")\n",
    "#     if val[8:] == 'A' or val[8:] == 'B':\n",
    "    print(f\" {'':10}  , {scaleparameter_times[i]}\")\n",
    "    print(\"\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9533b9af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:16.676061Z",
     "start_time": "2025-01-28T19:11:16.669914Z"
    }
   },
   "outputs": [],
   "source": [
    "def setsettings(den, y_num, month, run_dict, scaling_cadence, file_raw_ICs, file_g2b, input_arcs, input_epochstart, input_epochstop, scaleparameter_times):\n",
    "    \n",
    "    settings_ice= {# Basic input settings\n",
    "                 'satellite'      : {'input': 'icesat2'},\n",
    "                 'den_model'      : {'input': den},\n",
    "                 'run_type'       : {'input': 'DataReduction_PCE'},\n",
    "                 'run_specifier'  : {'input': '_'+str(y_num)+month},\n",
    "                 'cd_model'       : {'input': 'DRIA'},\n",
    "                 'file_string'    : {'input': 'DRIAscaled_'},\n",
    "                 'model_data_path' : {'input': run_dict[str(y_num)+month+den]['model_path']},\n",
    "                 # Force Model settings\n",
    "                  'cd_type'               : {'input':\"Fixed_CD\"},\n",
    "                  'cd_value'              : {'input':1.0 },\n",
    "                  'scaling_factor'        : {'input':True},\n",
    "                  'hours_between_cd_adj'  : {'input':scaling_cadence},\n",
    "                  #### Comment for unadjusted run:\n",
    "                  'cd_adjustment_boolean' : {'input':True },\n",
    "                #### DRIA CD Model Parameters\n",
    "                'cd_model_params' : {'input':{ \n",
    "                        'MS'     : '26.980D0'   ,  #!  molar mass for each panel (g/mol)\n",
    "                        'TW'     : '300.0D0'    ,  #!  temperature of panels  (K)\n",
    "                           ###  Alpha is b/w 0 and 1\n",
    "                        'ALPHA'  : '0.890D0'    ,  #!  accomodation coefficient\n",
    "                        'KL'     : '0.0D0'    ,    #!  langmuir parameter\n",
    "                        'FRACOX' : '1.0D0'   ,     #!  fraction of surface covered by atomic oxygen\n",
    "                   }},\n",
    "                  #### ---------------------------------------\n",
    "                 # Run\n",
    "                  'arc_type'       : {'input':'Nominal30hr_and_AB'},      \n",
    "                  'step'           : {'input': 10},\n",
    "                  'orbfil_step'    : {'input': 120.},\n",
    "                  'which_ICfile'   : {'input':file_raw_ICs},\n",
    "                  'which_g2bfile'  : {'input':file_g2b},\n",
    "                    #\n",
    "                  'arc'            : {'input': input_arcs},\n",
    "                  'epoch_start'    : {'input': input_epochstart},\n",
    "                  'epoch_stop'     : {'input': input_epochstop},  \n",
    "            'scaleparameter_times' : {'input': scaleparameter_times},  \n",
    "                   #                                \n",
    "                  'global_options' : {'input':'pso_2018'},\n",
    "                 # Request read on raw outputs\n",
    "                  'request_data'   : {'input': ['Trajectory_orbfil', \n",
    "                                               'Density', \n",
    "                                               'Residuals_summary',\n",
    "                                               'DragFile',\n",
    "                                               'AdjustedParams'\n",
    "                                               ]},\n",
    "              #end dict\n",
    "              }\n",
    "    return(settings_ice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92032303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T02:34:46.236071Z",
     "start_time": "2025-01-15T02:34:46.230665Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9001d9d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.093977Z",
     "start_time": "2025-01-28T19:11:16.679100Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2018.335    , 2018-11-30 21:18:00 ,  2018-12-02 02:42:00 , 29.4\n",
      "\n",
      " 2018.336    , 2018-12-01 21:18:00 ,  2018-12-03 02:42:00 , 29.4\n",
      "\n",
      " 2018.337    , 2018-12-02 21:18:00 ,  2018-12-04 02:42:00 , 29.4\n",
      "\n",
      " 2018.338    , 2018-12-03 21:18:00 ,  2018-12-05 02:42:00 , 29.4\n",
      "\n",
      " 2018.339A   , 2018-12-04 21:18:00 ,  2018-12-05 13:58:00 , 16.666666666666668\n",
      "             , [Timestamp('2018-12-05 00:00:00'), Timestamp('2018-12-05 03:00:00'), Timestamp('2018-12-05 06:00:00'), Timestamp('2018-12-05 09:00:00'), Timestamp('2018-12-05 12:00:00'), Timestamp('2018-12-05 13:58:00')]\n",
      "\n",
      " 2018.340A   , 2018-12-05 22:22:00 ,  2018-12-06 14:30:00 , 16.133333333333333\n",
      "             , [Timestamp('2018-12-06 00:00:00'), Timestamp('2018-12-06 03:00:00'), Timestamp('2018-12-06 06:00:00'), Timestamp('2018-12-06 09:00:00'), Timestamp('2018-12-06 12:00:00'), Timestamp('2018-12-06 14:30:00')]\n",
      "\n",
      " 2018.340B   , 2018-12-06 16:54:00 ,  2018-12-07 02:42:00 , 9.8\n",
      "             , [Timestamp('2018-12-06 00:00:00'), Timestamp('2018-12-06 03:00:00'), Timestamp('2018-12-06 06:00:00'), Timestamp('2018-12-06 09:00:00'), Timestamp('2018-12-06 12:00:00'), Timestamp('2018-12-06 15:00:00'), Timestamp('2018-12-06 18:00:00'), Timestamp('2018-12-06 21:00:00'), Timestamp('2018-12-07 00:00:00'), Timestamp('2018-12-07 02:42:00')]\n",
      "\n",
      " 2018.341    , 2018-12-06 21:18:00 ,  2018-12-08 02:42:00 , 29.4\n",
      "\n",
      " 2018.342A   , 2018-12-07 21:18:00 ,  2018-12-08 21:42:00 , 24.4\n",
      "             , [Timestamp('2018-12-08 00:00:00'), Timestamp('2018-12-08 03:00:00'), Timestamp('2018-12-08 06:00:00'), Timestamp('2018-12-08 09:00:00'), Timestamp('2018-12-08 12:00:00'), Timestamp('2018-12-08 15:00:00'), Timestamp('2018-12-08 18:00:00'), Timestamp('2018-12-08 21:00:00'), Timestamp('2018-12-08 21:42:00')]\n",
      "\n",
      " 2018.343A   , 2018-12-09 10:13:00 ,  2018-12-09 23:38:00 , 13.416666666666666\n",
      "             , [Timestamp('2018-12-09 00:00:00'), Timestamp('2018-12-09 03:00:00'), Timestamp('2018-12-09 06:00:00'), Timestamp('2018-12-09 09:00:00'), Timestamp('2018-12-09 12:00:00'), Timestamp('2018-12-09 15:00:00'), Timestamp('2018-12-09 18:00:00'), Timestamp('2018-12-09 21:00:00'), Timestamp('2018-12-09 23:38:00')]\n",
      "\n",
      " 2018.344A   , 2018-12-10 08:13:00 ,  2018-12-11 02:42:00 , 18.483333333333334\n",
      "             , [Timestamp('2018-12-10 00:00:00'), Timestamp('2018-12-10 03:00:00'), Timestamp('2018-12-10 06:00:00'), Timestamp('2018-12-10 09:00:00'), Timestamp('2018-12-10 12:00:00'), Timestamp('2018-12-10 15:00:00'), Timestamp('2018-12-10 18:00:00'), Timestamp('2018-12-10 21:00:00'), Timestamp('2018-12-11 00:00:00'), Timestamp('2018-12-11 02:42:00')]\n",
      "\n",
      " 2018.345    , 2018-12-10 21:18:00 ,  2018-12-12 02:42:00 , 29.4\n",
      "\n",
      " 2018.346A   , 2018-12-11 21:18:00 ,  2018-12-13 00:30:00 , 27.2\n",
      "             , [Timestamp('2018-12-12 00:00:00'), Timestamp('2018-12-12 03:00:00'), Timestamp('2018-12-12 06:00:00'), Timestamp('2018-12-12 09:00:00'), Timestamp('2018-12-12 12:00:00'), Timestamp('2018-12-12 15:00:00'), Timestamp('2018-12-12 18:00:00'), Timestamp('2018-12-12 21:00:00'), Timestamp('2018-12-13 00:00:00'), Timestamp('2018-12-13 00:30:00')]\n",
      "\n",
      " 2018.347A   , 2018-12-13 01:54:00 ,  2018-12-14 02:42:00 , 24.8\n",
      "             , [Timestamp('2018-12-13 00:00:00'), Timestamp('2018-12-13 03:00:00'), Timestamp('2018-12-13 06:00:00'), Timestamp('2018-12-13 09:00:00'), Timestamp('2018-12-13 12:00:00'), Timestamp('2018-12-13 15:00:00'), Timestamp('2018-12-13 18:00:00'), Timestamp('2018-12-13 21:00:00'), Timestamp('2018-12-14 00:00:00'), Timestamp('2018-12-14 02:42:00')]\n",
      "\n",
      " 2018.348    , 2018-12-13 21:18:00 ,  2018-12-15 02:42:00 , 29.4\n",
      "\n",
      " 2018.349    , 2018-12-14 21:18:00 ,  2018-12-16 02:42:00 , 29.4\n",
      "\n",
      " 2018.350    , 2018-12-15 21:18:00 ,  2018-12-17 02:42:00 , 29.4\n",
      "\n",
      " 2018.351    , 2018-12-16 21:18:00 ,  2018-12-18 02:42:00 , 29.4\n",
      "\n",
      " 2018.352    , 2018-12-17 21:18:00 ,  2018-12-19 02:42:00 , 29.4\n",
      "\n",
      " 2018.353    , 2018-12-18 21:18:00 ,  2018-12-20 02:42:00 , 29.4\n",
      "\n",
      " 2018.354A   , 2018-12-19 21:18:00 ,  2018-12-20 13:18:00 , 16.0\n",
      "             , [Timestamp('2018-12-20 00:00:00'), Timestamp('2018-12-20 03:00:00'), Timestamp('2018-12-20 06:00:00'), Timestamp('2018-12-20 09:00:00'), Timestamp('2018-12-20 12:00:00'), Timestamp('2018-12-20 13:18:00')]\n",
      "\n",
      " 2018.354B   , 2018-12-20 14:36:00 ,  2018-12-21 02:42:00 , 12.1\n",
      "             , [Timestamp('2018-12-20 00:00:00'), Timestamp('2018-12-20 03:00:00'), Timestamp('2018-12-20 06:00:00'), Timestamp('2018-12-20 09:00:00'), Timestamp('2018-12-20 12:00:00'), Timestamp('2018-12-20 15:00:00'), Timestamp('2018-12-20 18:00:00'), Timestamp('2018-12-20 21:00:00'), Timestamp('2018-12-21 00:00:00'), Timestamp('2018-12-21 02:42:00')]\n",
      "\n",
      " 2018.355    , 2018-12-20 21:18:00 ,  2018-12-22 02:42:00 , 29.4\n",
      "\n",
      " 2018.356    , 2018-12-21 21:18:00 ,  2018-12-23 02:42:00 , 29.4\n",
      "\n",
      " 2018.357    , 2018-12-22 21:18:00 ,  2018-12-24 02:42:00 , 29.4\n",
      "\n",
      " 2018.358    , 2018-12-23 21:18:00 ,  2018-12-25 02:42:00 , 29.4\n",
      "\n",
      " 2018.359    , 2018-12-24 21:18:00 ,  2018-12-26 02:42:00 , 29.4\n",
      "\n",
      " 2018.360A   , 2018-12-25 21:18:00 ,  2018-12-27 00:48:00 , 27.5\n",
      "             , [Timestamp('2018-12-26 00:00:00'), Timestamp('2018-12-26 03:00:00'), Timestamp('2018-12-26 06:00:00'), Timestamp('2018-12-26 09:00:00'), Timestamp('2018-12-26 12:00:00'), Timestamp('2018-12-26 15:00:00'), Timestamp('2018-12-26 18:00:00'), Timestamp('2018-12-26 21:00:00'), Timestamp('2018-12-27 00:00:00'), Timestamp('2018-12-27 00:48:00')]\n",
      "\n",
      " 2018.361A   , 2018-12-27 02:18:00 ,  2018-12-28 02:42:00 , 24.4\n",
      "             , [Timestamp('2018-12-27 00:00:00'), Timestamp('2018-12-27 03:00:00'), Timestamp('2018-12-27 06:00:00'), Timestamp('2018-12-27 09:00:00'), Timestamp('2018-12-27 12:00:00'), Timestamp('2018-12-27 15:00:00'), Timestamp('2018-12-27 18:00:00'), Timestamp('2018-12-27 21:00:00'), Timestamp('2018-12-28 00:00:00'), Timestamp('2018-12-28 02:42:00')]\n",
      "\n",
      " 2018.362A   , 2018-12-27 21:18:00 ,  2018-12-28 18:34:00 , 21.266666666666666\n",
      "             , [Timestamp('2018-12-28 00:00:00'), Timestamp('2018-12-28 03:00:00'), Timestamp('2018-12-28 06:00:00'), Timestamp('2018-12-28 09:00:00'), Timestamp('2018-12-28 12:00:00'), Timestamp('2018-12-28 15:00:00'), Timestamp('2018-12-28 18:00:00'), Timestamp('2018-12-28 18:34:00')]\n",
      "\n",
      " 2018.363A   , 2018-12-28 19:22:00 ,  2018-12-30 02:42:00 , 31.333333333333332\n",
      "             , [Timestamp('2018-12-29 00:00:00'), Timestamp('2018-12-29 03:00:00'), Timestamp('2018-12-29 06:00:00'), Timestamp('2018-12-29 09:00:00'), Timestamp('2018-12-29 12:00:00'), Timestamp('2018-12-29 15:00:00'), Timestamp('2018-12-29 18:00:00'), Timestamp('2018-12-29 21:00:00'), Timestamp('2018-12-30 00:00:00'), Timestamp('2018-12-30 02:42:00')]\n",
      "\n",
      " 2018.364    , 2018-12-29 21:18:00 ,  2018-12-31 02:42:00 , 29.4\n",
      "\n",
      " 2018.365    , 2018-12-30 21:18:00 ,  2019-01-01 02:42:00 , 29.4\n",
      "\n",
      "Using the ICESat-2 Class\n",
      "['2018-11-30 21:18:00', '2018-12-01 21:18:00']\n",
      "check sat ICESat2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bunzip2: Can't open input file icesat2_2018335_dtm2020_o.DRIAscaled_.bz2: No such file or directory.\n",
      "bunzip2: Can't open input file icesat2_2018335_dtm2020_o.DRIAscaled_drag_file.bz2: No such file or directory.\n",
      "bunzip2: Can't open input file icesat2_2018335_dtm2020_o.DRIAscaled__orb1.bz2: No such file or directory.\n",
      "bunzip2: Can't open input file icesat2_2018336_dtm2020_o.DRIAscaled_.bz2: No such file or directory.\n",
      "bunzip2: Can't open input file icesat2_2018336_dtm2020_o.DRIAscaled_drag_file.bz2: No such file or directory.\n",
      "bunzip2: Can't open input file icesat2_2018336_dtm2020_o.DRIAscaled__orb1.bz2: No such file or directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Arc: 2018.335\n",
      "---Reading PCE data and save as global var\n",
      "    - Arc: 2018.336\n",
      "deleting PCE_data_raw from globals. Allows reset for new month file.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from gc import collect as gc_collect\n",
    "import pickle \n",
    "import os\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "\n",
    "g2b_path = \"/data/SatDragModelValidation/data/inputs/sat_icesat2/g2b/\"\n",
    "\n",
    "dir_save    =  '/data/SatDragModelValidation/data/outputs_clean/'\\\n",
    "             + 'icesat2/FinalDatasets_SWJ2025/'\n",
    "\n",
    "obj = {}\n",
    "\n",
    "for y_num in year_list: #\n",
    "\n",
    "    for imonth,month in enumerate(month_list):\n",
    "        if month=='jan':  m_num = 1\n",
    "        if month=='feb':  m_num = 2\n",
    "        if month=='mar':  m_num = 3\n",
    "        if month=='apr':  m_num = 4\n",
    "        if month=='may':  m_num = 5\n",
    "        if month=='jun':  m_num = 6\n",
    "        if month=='jul':  m_num = 7\n",
    "        if month=='aug':  m_num = 8\n",
    "        if month=='sep':  m_num = 9\n",
    "        if month=='oct':  m_num = 10\n",
    "        if month=='nov':  m_num = 11\n",
    "        if month=='dec':  m_num = 12\n",
    "            \n",
    "        if y_num==2018 and m_num<10:\n",
    "            print(f'Skipping {y_num}.{m_num}')\n",
    "            continue\n",
    "#         if y_num==2019 and m_num<4:\n",
    "#             print(f'Skipping {y_num}.{m_num}')\n",
    "#             continue\n",
    "            \n",
    "            \n",
    "        file_raw_ICs = f\"{g2b_path}ICESat2_RawEphem_{y_num}_{m_num:02d}.txt\"\n",
    "        file_g2b     = f\"pce_icesat2_pso_{y_num}_{m_num:02d}\"\n",
    "    #     file_raw_ICs = f\"{g2b_path}ICESat2_RawEphem_20190331_20190503.txt\"\n",
    "    #     file_g2b     = f\"pce_icesat2_pso_20190331_20190503\"\n",
    "\n",
    "        input_arcs           = []\n",
    "        input_epochstart     = []\n",
    "        input_epochstop      = []\n",
    "        arc_length           = []\n",
    "        scaleparameter_times = []\n",
    "\n",
    "        for i,val in enumerate(arcs_yyyyddd):\n",
    "\n",
    "\n",
    "            if pd.to_datetime(val[:8],format=\"%Y.%j\").month == m_num and pd.to_datetime(val[:8],format=\"%Y.%j\").year == y_num:\n",
    "                epoch_delta  =  pd.to_timedelta(pd.to_datetime(epochstop[i]) - pd.to_datetime(epochstart[i]), 'hours')\n",
    "                arc_length.append(epoch_delta.total_seconds()/3600)\n",
    "\n",
    "                if val[8:] == 'A' or val[8:] == 'B':\n",
    "                    input_arcs.append(      arcs_yyyyddd[i])\n",
    "                    input_epochstart.append(epochstart[i])\n",
    "                    input_epochstop.append( epochstop[i])\n",
    "    #                 scaleparameter_times.append(dict_sftime[arcs_yyyyddd[i]])\n",
    "                    scalestart = str(pd.to_datetime(arcs_yyyyddd[i][:-1],format=\"%Y.%j\"))\n",
    "                    scalestop  = str(pd.to_datetime(arcs_yyyyddd[i][:-1],format=\"%Y.%j\") + pd.to_timedelta(24,'h'))\n",
    "                    scaletimes = pd.date_range(start = pd.to_datetime(scalestart),\n",
    "                                                              end   = pd.to_datetime( epochstop[i] ),\n",
    "                                                              freq=str(scale_cadence)+\"h\")\n",
    "                \n",
    "                    if epochstop[i] in scaletimes:  ## dont add repeats to the final epoch time\n",
    "                        ### Append the epoch end time to the end\n",
    "                        add_epochend = scaletimes.values.astype(np.int64) // 10 ** 9\n",
    "                                        #np.append(scaletimes.values.astype(np.int64) // 10 ** 9,\n",
    "                                      #pd.to_datetime(pd.Series(epochstop[i])).values.astype(np.int64) // 10 ** 9)\n",
    "\n",
    "                        scaleparameter_times.append([pd.to_datetime(datetime.strftime(datetime.fromtimestamp(ts), '%y%m%d%H%M%S.%f'),\n",
    "                            format ='%y%m%d%H%M%S.%f' )\n",
    "                                         for ts in add_epochend  ])\n",
    "                    else:\n",
    "                        ### Append the epoch end time to the end\n",
    "                        add_epochend = np.append(scaletimes.values.astype(np.int64) // 10 ** 9,\n",
    "                                      pd.to_datetime(pd.Series(epochstop[i])).values.astype(np.int64) // 10 ** 9)\n",
    "\n",
    "\n",
    "                        scaleparameter_times.append([pd.to_datetime(datetime.strftime(datetime.fromtimestamp(ts), '%y%m%d%H%M%S.%f'),\n",
    "                            format ='%y%m%d%H%M%S.%f' )\n",
    "                                         for ts in add_epochend ])\n",
    "                else:\n",
    "\n",
    "                    ### Use Arc text file times\n",
    "                    input_arcs.append(      arcs_yyyyddd[i])\n",
    "                    input_epochstart.append(epochstart[i])\n",
    "                    input_epochstop.append( epochstop[i])\n",
    "    #                 print(f\"epoch_top {epochstop[i]}\")\n",
    "                    scalestart = str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\"))\n",
    "                    scalestop  = str(pd.to_datetime(arcs_yyyyddd[i],format=\"%Y.%j\") + pd.to_timedelta(24,'h'))\n",
    "                    scaletimes = pd.date_range(start = pd.to_datetime(scalestart),\n",
    "                                                              end   = pd.to_datetime(scalestop ),\n",
    "                                                              freq=str(scale_cadence)+\"h\")\n",
    "\n",
    "                    ### Append the epoch end time to the end\n",
    "                    add_epochend = np.append(scaletimes.values.astype(np.int64) // 10 ** 9,\n",
    "                                  pd.to_datetime(pd.Series(epochstop[i])).values.astype(np.int64) // 10 ** 9)\n",
    "\n",
    "\n",
    "                    scaleparameter_times.append([pd.to_datetime(datetime.strftime(datetime.fromtimestamp(ts), '%y%m%d%H%M%S.%f'),\n",
    "                        format ='%y%m%d%H%M%S.%f' )\n",
    "                                     for ts in add_epochend ])\n",
    "\n",
    "        for i,val in enumerate(input_arcs):\n",
    "            print(f\" {input_arcs[i]:10}  , {input_epochstart[i]:20},  {input_epochstop[i]:20}, {arc_length[i]}\")\n",
    "            if val[8:] == 'A' or val[8:] == 'B':\n",
    "                print(f\" {'':10}  , {scaleparameter_times[i]}\")\n",
    "                print(\"\")\n",
    "\n",
    "            else:\n",
    "        #         print(f\" {'':10}  , {scaleparameter_times[i]}\")\n",
    "                print(\"\")     \n",
    "    \n",
    "#         for i,den in enumerate(run_list):\n",
    "#             if y_num == 2019 and month in ['jan','feb', 'mar','apr', 'may','jun','jul','aug','sep','oct','nov'] :\n",
    "#                 print(f\"already ran {month} for {den}\")\n",
    "\n",
    "# #                 'msis2',\n",
    "# #                 'jb2008',\n",
    "# #                 'dtm2020_o',\n",
    "\n",
    "#             elif y_num == 2019 and month == 'dec' and den in ['msis2', 'jb2008','dtm2020_o']:\n",
    "#                 print(f\"already ran {month} for {den}\")\n",
    "            \n",
    "#             elif y_num == 2019 and month == 'dec' and den == 'hasdm_oc':\n",
    "                \n",
    "#                 input_arcs           = input_arcs[:-1]\n",
    "#                 input_epochstart     = input_epochstart[:-1]\n",
    "#                 input_epochstop      = input_epochstop[:-1]\n",
    "#                 scaleparameter_times = scaleparameter_times[:-1]\n",
    "                \n",
    "#                 settings_ice = setsettings(den, y_num, month, run_dict, scaling_cadence, file_raw_ICs, file_g2b, \n",
    "#                                              input_arcs, \n",
    "#                                              input_epochstart, \n",
    "#                                              input_epochstop, \n",
    "#                                              scaleparameter_times)\n",
    "\n",
    "#                 sat = Pygeodyn(settings_ice, use_file=False)\n",
    "#                 sat.run_arcs()\n",
    "\n",
    "#             else:                \n",
    "#                 settings_ice = setsettings(den, y_num, month, run_dict, scaling_cadence, file_raw_ICs, file_g2b, \n",
    "#                                              input_arcs, \n",
    "#                                              input_epochstart, \n",
    "#                                              input_epochstop, \n",
    "#                                              scaleparameter_times)\n",
    "\n",
    "#                 sat = Pygeodyn(settings_ice, use_file=False)\n",
    "#                 sat.run_arcs()\n",
    "\n",
    "                \n",
    "        #2019.301\n",
    "                \n",
    "        for i,den in enumerate(run_list):\n",
    "            \n",
    "#                         print('y_num month',y_num, month)\n",
    "            if y_num==2018 and month not in ['oct', 'nov', 'dec']:\n",
    "                print(f'Skipping {y_num}.{month}')\n",
    "                \n",
    "#             elif y_num==2019 and month in ['jan', 'feb', 'mar', 'apr']:\n",
    "#                 print(f'Skipping {y_num}.{month}')\n",
    "                \n",
    "            elif y_num == 2019 and month == 'dec':\n",
    "                \n",
    "                input_arcs           = input_arcs[:-1]\n",
    "                input_epochstart     = input_epochstart[:-1]\n",
    "                input_epochstop      = input_epochstop[:-1]\n",
    "                scaleparameter_times = scaleparameter_times[:-1]\n",
    "                \n",
    "                settings_ice = setsettings(den, y_num, month, run_dict, scaling_cadence, file_raw_ICs, file_g2b, \n",
    "                                             input_arcs, \n",
    "                                             input_epochstart, \n",
    "                                             input_epochstop, \n",
    "                                             scaleparameter_times)\n",
    "                sat = Pygeodyn(settings_ice, use_file=False)\n",
    "\n",
    "            else:\n",
    "                settings_ice = setsettings(den,y_num, month, run_dict, scaling_cadence, file_raw_ICs, file_g2b, \n",
    "                                             input_arcs, \n",
    "                                             input_epochstart, \n",
    "                                             input_epochstop, \n",
    "                                             scaleparameter_times)\n",
    "                \n",
    "                sat = Pygeodyn(settings_ice, use_file=False)\n",
    "#             obj[str(y_num)+month+den] =  sat.getData_BigData_lowmemory(orbit_propagation=False)\n",
    "#             obj[str(y_num)+month+den] = vars(obj[str(y_num)+month+den])\n",
    "#             gc_collect()\n",
    "\n",
    "\n",
    "            pickleName = f'_{y_num}.{month}_DRIA_scale{scale_cadence}.pkl'\n",
    "\n",
    "            pickle_file = dir_save+den+pickleName\n",
    "            if not os.path.exists(pickle_file):\n",
    "                print('Must create pickle file...')\n",
    "                print('   ',  pickle_file)\n",
    "                print('   ', 'Reading Geodyn Data')\n",
    "\n",
    "                ### Load the data into an object\n",
    "                sat = Pygeodyn(settings_ice, use_file=False)\n",
    "                obj = sat.getData_BigData_lowmemory(orbit_propagation=False)\n",
    "                gc_collect()\n",
    "\n",
    "                #### Pickle the object to save it\n",
    "                print('   ', 'Saving pickle')\n",
    "                filehandler = open(pickle_file, 'wb') \n",
    "                pickle.dump(vars(obj), filehandler)\n",
    "                filehandler.close()\n",
    "                obj = 0\n",
    "                print('   ', 'Saved pickle')\n",
    "\n",
    "    for i,model in enumerate(run_list):\n",
    "#         print('RUNLIST',model)\n",
    "        for imonth,month in enumerate(month_list):\n",
    "            \n",
    "            print('y_num month',y_num, month)\n",
    "            if y_num==2018 and month not in ['oct', 'nov', 'dec']:\n",
    "                print(f'Skipping {y_num}.{month}')\n",
    "                \n",
    "#             elif y_num==2019 and month in ['jan', 'feb', 'mar', 'apr']:\n",
    "#                 print(f'Skipping {y_num}.{month}')\n",
    "                \n",
    "            else:\n",
    "                pickleName = f'_{y_num}.{month}_DRIA_scale{scale_cadence}.pkl'\n",
    "\n",
    "                ### Load the data if the pickles exist\n",
    "                print()\n",
    "                print()\n",
    "                gc_collect()\n",
    "\n",
    "                pickle_file = dir_save+model+pickleName\n",
    "\n",
    "                obj[str(y_num)+month+model] = pd.read_pickle(pickle_file)\n",
    "        #         filehandler = open(pickle_file, 'rb') \n",
    "        #         obj[month+model] = pickle.load(filehandler)\n",
    "        #         filehandler.close()\n",
    "                print('Loaded data from pickle... ',y_num, month, model)\n",
    "\n",
    "### Save space if doing density retrieval\n",
    "for model in run_dict.keys():\n",
    "    print(model)\n",
    "    del obj[model]['OrbitResids']\n",
    "    del obj[model]['Trajectory_orbfil']\n",
    "\n",
    "gc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df5070e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T01:20:09.612941Z",
     "start_time": "2025-01-27T01:20:09.571521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bbe86aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.116604Z",
     "start_time": "2025-01-28T19:11:34.097433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018.335', '2018.336', '2018.337', '2018.338', '2018.339A', '2018.340A', '2018.340B', '2018.341', '2018.342A', '2018.343A', '2018.344A', '2018.345', '2018.346A', '2018.347A', '2018.348', '2018.349', '2018.350', '2018.351', '2018.352', '2018.353', '2018.354A', '2018.354B', '2018.355', '2018.356', '2018.357', '2018.358', '2018.359', '2018.360A', '2018.361A', '2018.362A', '2018.363A', '2018.364', '2018.365']\n",
      "['2018-11-30 21:18:00', '2018-12-01 21:18:00', '2018-12-02 21:18:00', '2018-12-03 21:18:00', '2018-12-04 21:18:00', '2018-12-05 22:22:00', '2018-12-06 16:54:00', '2018-12-06 21:18:00', '2018-12-07 21:18:00', '2018-12-09 10:13:00', '2018-12-10 08:13:00', '2018-12-10 21:18:00', '2018-12-11 21:18:00', '2018-12-13 01:54:00', '2018-12-13 21:18:00', '2018-12-14 21:18:00', '2018-12-15 21:18:00', '2018-12-16 21:18:00', '2018-12-17 21:18:00', '2018-12-18 21:18:00', '2018-12-19 21:18:00', '2018-12-20 14:36:00', '2018-12-20 21:18:00', '2018-12-21 21:18:00', '2018-12-22 21:18:00', '2018-12-23 21:18:00', '2018-12-24 21:18:00', '2018-12-25 21:18:00', '2018-12-27 02:18:00', '2018-12-27 21:18:00', '2018-12-28 19:22:00', '2018-12-29 21:18:00', '2018-12-30 21:18:00']\n",
      "['2018-12-02 02:42:00', '2018-12-03 02:42:00', '2018-12-04 02:42:00', '2018-12-05 02:42:00', '2018-12-05 13:58:00', '2018-12-06 14:30:00', '2018-12-07 02:42:00', '2018-12-08 02:42:00', '2018-12-08 21:42:00', '2018-12-09 23:38:00', '2018-12-11 02:42:00', '2018-12-12 02:42:00', '2018-12-13 00:30:00', '2018-12-14 02:42:00', '2018-12-15 02:42:00', '2018-12-16 02:42:00', '2018-12-17 02:42:00', '2018-12-18 02:42:00', '2018-12-19 02:42:00', '2018-12-20 02:42:00', '2018-12-20 13:18:00', '2018-12-21 02:42:00', '2018-12-22 02:42:00', '2018-12-23 02:42:00', '2018-12-24 02:42:00', '2018-12-25 02:42:00', '2018-12-26 02:42:00', '2018-12-27 00:48:00', '2018-12-28 02:42:00', '2018-12-28 18:34:00', '2018-12-30 02:42:00', '2018-12-31 02:42:00', '2019-01-01 02:42:00']\n",
      "[[Timestamp('2018-12-01 00:00:00'), Timestamp('2018-12-01 03:00:00'), Timestamp('2018-12-01 06:00:00'), Timestamp('2018-12-01 09:00:00'), Timestamp('2018-12-01 12:00:00'), Timestamp('2018-12-01 15:00:00'), Timestamp('2018-12-01 18:00:00'), Timestamp('2018-12-01 21:00:00'), Timestamp('2018-12-02 00:00:00'), Timestamp('2018-12-02 02:42:00')], [Timestamp('2018-12-02 00:00:00'), Timestamp('2018-12-02 03:00:00'), Timestamp('2018-12-02 06:00:00'), Timestamp('2018-12-02 09:00:00'), Timestamp('2018-12-02 12:00:00'), Timestamp('2018-12-02 15:00:00'), Timestamp('2018-12-02 18:00:00'), Timestamp('2018-12-02 21:00:00'), Timestamp('2018-12-03 00:00:00'), Timestamp('2018-12-03 02:42:00')], [Timestamp('2018-12-03 00:00:00'), Timestamp('2018-12-03 03:00:00'), Timestamp('2018-12-03 06:00:00'), Timestamp('2018-12-03 09:00:00'), Timestamp('2018-12-03 12:00:00'), Timestamp('2018-12-03 15:00:00'), Timestamp('2018-12-03 18:00:00'), Timestamp('2018-12-03 21:00:00'), Timestamp('2018-12-04 00:00:00'), Timestamp('2018-12-04 02:42:00')], [Timestamp('2018-12-04 00:00:00'), Timestamp('2018-12-04 03:00:00'), Timestamp('2018-12-04 06:00:00'), Timestamp('2018-12-04 09:00:00'), Timestamp('2018-12-04 12:00:00'), Timestamp('2018-12-04 15:00:00'), Timestamp('2018-12-04 18:00:00'), Timestamp('2018-12-04 21:00:00'), Timestamp('2018-12-05 00:00:00'), Timestamp('2018-12-05 02:42:00')], [Timestamp('2018-12-05 00:00:00'), Timestamp('2018-12-05 03:00:00'), Timestamp('2018-12-05 06:00:00'), Timestamp('2018-12-05 09:00:00'), Timestamp('2018-12-05 12:00:00'), Timestamp('2018-12-05 13:58:00')], [Timestamp('2018-12-06 00:00:00'), Timestamp('2018-12-06 03:00:00'), Timestamp('2018-12-06 06:00:00'), Timestamp('2018-12-06 09:00:00'), Timestamp('2018-12-06 12:00:00'), Timestamp('2018-12-06 14:30:00')], [Timestamp('2018-12-06 00:00:00'), Timestamp('2018-12-06 03:00:00'), Timestamp('2018-12-06 06:00:00'), Timestamp('2018-12-06 09:00:00'), Timestamp('2018-12-06 12:00:00'), Timestamp('2018-12-06 15:00:00'), Timestamp('2018-12-06 18:00:00'), Timestamp('2018-12-06 21:00:00'), Timestamp('2018-12-07 00:00:00'), Timestamp('2018-12-07 02:42:00')], [Timestamp('2018-12-07 00:00:00'), Timestamp('2018-12-07 03:00:00'), Timestamp('2018-12-07 06:00:00'), Timestamp('2018-12-07 09:00:00'), Timestamp('2018-12-07 12:00:00'), Timestamp('2018-12-07 15:00:00'), Timestamp('2018-12-07 18:00:00'), Timestamp('2018-12-07 21:00:00'), Timestamp('2018-12-08 00:00:00'), Timestamp('2018-12-08 02:42:00')], [Timestamp('2018-12-08 00:00:00'), Timestamp('2018-12-08 03:00:00'), Timestamp('2018-12-08 06:00:00'), Timestamp('2018-12-08 09:00:00'), Timestamp('2018-12-08 12:00:00'), Timestamp('2018-12-08 15:00:00'), Timestamp('2018-12-08 18:00:00'), Timestamp('2018-12-08 21:00:00'), Timestamp('2018-12-08 21:42:00')], [Timestamp('2018-12-09 00:00:00'), Timestamp('2018-12-09 03:00:00'), Timestamp('2018-12-09 06:00:00'), Timestamp('2018-12-09 09:00:00'), Timestamp('2018-12-09 12:00:00'), Timestamp('2018-12-09 15:00:00'), Timestamp('2018-12-09 18:00:00'), Timestamp('2018-12-09 21:00:00'), Timestamp('2018-12-09 23:38:00')], [Timestamp('2018-12-10 00:00:00'), Timestamp('2018-12-10 03:00:00'), Timestamp('2018-12-10 06:00:00'), Timestamp('2018-12-10 09:00:00'), Timestamp('2018-12-10 12:00:00'), Timestamp('2018-12-10 15:00:00'), Timestamp('2018-12-10 18:00:00'), Timestamp('2018-12-10 21:00:00'), Timestamp('2018-12-11 00:00:00'), Timestamp('2018-12-11 02:42:00')], [Timestamp('2018-12-11 00:00:00'), Timestamp('2018-12-11 03:00:00'), Timestamp('2018-12-11 06:00:00'), Timestamp('2018-12-11 09:00:00'), Timestamp('2018-12-11 12:00:00'), Timestamp('2018-12-11 15:00:00'), Timestamp('2018-12-11 18:00:00'), Timestamp('2018-12-11 21:00:00'), Timestamp('2018-12-12 00:00:00'), Timestamp('2018-12-12 02:42:00')], [Timestamp('2018-12-12 00:00:00'), Timestamp('2018-12-12 03:00:00'), Timestamp('2018-12-12 06:00:00'), Timestamp('2018-12-12 09:00:00'), Timestamp('2018-12-12 12:00:00'), Timestamp('2018-12-12 15:00:00'), Timestamp('2018-12-12 18:00:00'), Timestamp('2018-12-12 21:00:00'), Timestamp('2018-12-13 00:00:00'), Timestamp('2018-12-13 00:30:00')], [Timestamp('2018-12-13 00:00:00'), Timestamp('2018-12-13 03:00:00'), Timestamp('2018-12-13 06:00:00'), Timestamp('2018-12-13 09:00:00'), Timestamp('2018-12-13 12:00:00'), Timestamp('2018-12-13 15:00:00'), Timestamp('2018-12-13 18:00:00'), Timestamp('2018-12-13 21:00:00'), Timestamp('2018-12-14 00:00:00'), Timestamp('2018-12-14 02:42:00')], [Timestamp('2018-12-14 00:00:00'), Timestamp('2018-12-14 03:00:00'), Timestamp('2018-12-14 06:00:00'), Timestamp('2018-12-14 09:00:00'), Timestamp('2018-12-14 12:00:00'), Timestamp('2018-12-14 15:00:00'), Timestamp('2018-12-14 18:00:00'), Timestamp('2018-12-14 21:00:00'), Timestamp('2018-12-15 00:00:00'), Timestamp('2018-12-15 02:42:00')], [Timestamp('2018-12-15 00:00:00'), Timestamp('2018-12-15 03:00:00'), Timestamp('2018-12-15 06:00:00'), Timestamp('2018-12-15 09:00:00'), Timestamp('2018-12-15 12:00:00'), Timestamp('2018-12-15 15:00:00'), Timestamp('2018-12-15 18:00:00'), Timestamp('2018-12-15 21:00:00'), Timestamp('2018-12-16 00:00:00'), Timestamp('2018-12-16 02:42:00')], [Timestamp('2018-12-16 00:00:00'), Timestamp('2018-12-16 03:00:00'), Timestamp('2018-12-16 06:00:00'), Timestamp('2018-12-16 09:00:00'), Timestamp('2018-12-16 12:00:00'), Timestamp('2018-12-16 15:00:00'), Timestamp('2018-12-16 18:00:00'), Timestamp('2018-12-16 21:00:00'), Timestamp('2018-12-17 00:00:00'), Timestamp('2018-12-17 02:42:00')], [Timestamp('2018-12-17 00:00:00'), Timestamp('2018-12-17 03:00:00'), Timestamp('2018-12-17 06:00:00'), Timestamp('2018-12-17 09:00:00'), Timestamp('2018-12-17 12:00:00'), Timestamp('2018-12-17 15:00:00'), Timestamp('2018-12-17 18:00:00'), Timestamp('2018-12-17 21:00:00'), Timestamp('2018-12-18 00:00:00'), Timestamp('2018-12-18 02:42:00')], [Timestamp('2018-12-18 00:00:00'), Timestamp('2018-12-18 03:00:00'), Timestamp('2018-12-18 06:00:00'), Timestamp('2018-12-18 09:00:00'), Timestamp('2018-12-18 12:00:00'), Timestamp('2018-12-18 15:00:00'), Timestamp('2018-12-18 18:00:00'), Timestamp('2018-12-18 21:00:00'), Timestamp('2018-12-19 00:00:00'), Timestamp('2018-12-19 02:42:00')], [Timestamp('2018-12-19 00:00:00'), Timestamp('2018-12-19 03:00:00'), Timestamp('2018-12-19 06:00:00'), Timestamp('2018-12-19 09:00:00'), Timestamp('2018-12-19 12:00:00'), Timestamp('2018-12-19 15:00:00'), Timestamp('2018-12-19 18:00:00'), Timestamp('2018-12-19 21:00:00'), Timestamp('2018-12-20 00:00:00'), Timestamp('2018-12-20 02:42:00')], [Timestamp('2018-12-20 00:00:00'), Timestamp('2018-12-20 03:00:00'), Timestamp('2018-12-20 06:00:00'), Timestamp('2018-12-20 09:00:00'), Timestamp('2018-12-20 12:00:00'), Timestamp('2018-12-20 13:18:00')], [Timestamp('2018-12-20 00:00:00'), Timestamp('2018-12-20 03:00:00'), Timestamp('2018-12-20 06:00:00'), Timestamp('2018-12-20 09:00:00'), Timestamp('2018-12-20 12:00:00'), Timestamp('2018-12-20 15:00:00'), Timestamp('2018-12-20 18:00:00'), Timestamp('2018-12-20 21:00:00'), Timestamp('2018-12-21 00:00:00'), Timestamp('2018-12-21 02:42:00')], [Timestamp('2018-12-21 00:00:00'), Timestamp('2018-12-21 03:00:00'), Timestamp('2018-12-21 06:00:00'), Timestamp('2018-12-21 09:00:00'), Timestamp('2018-12-21 12:00:00'), Timestamp('2018-12-21 15:00:00'), Timestamp('2018-12-21 18:00:00'), Timestamp('2018-12-21 21:00:00'), Timestamp('2018-12-22 00:00:00'), Timestamp('2018-12-22 02:42:00')], [Timestamp('2018-12-22 00:00:00'), Timestamp('2018-12-22 03:00:00'), Timestamp('2018-12-22 06:00:00'), Timestamp('2018-12-22 09:00:00'), Timestamp('2018-12-22 12:00:00'), Timestamp('2018-12-22 15:00:00'), Timestamp('2018-12-22 18:00:00'), Timestamp('2018-12-22 21:00:00'), Timestamp('2018-12-23 00:00:00'), Timestamp('2018-12-23 02:42:00')], [Timestamp('2018-12-23 00:00:00'), Timestamp('2018-12-23 03:00:00'), Timestamp('2018-12-23 06:00:00'), Timestamp('2018-12-23 09:00:00'), Timestamp('2018-12-23 12:00:00'), Timestamp('2018-12-23 15:00:00'), Timestamp('2018-12-23 18:00:00'), Timestamp('2018-12-23 21:00:00'), Timestamp('2018-12-24 00:00:00'), Timestamp('2018-12-24 02:42:00')], [Timestamp('2018-12-24 00:00:00'), Timestamp('2018-12-24 03:00:00'), Timestamp('2018-12-24 06:00:00'), Timestamp('2018-12-24 09:00:00'), Timestamp('2018-12-24 12:00:00'), Timestamp('2018-12-24 15:00:00'), Timestamp('2018-12-24 18:00:00'), Timestamp('2018-12-24 21:00:00'), Timestamp('2018-12-25 00:00:00'), Timestamp('2018-12-25 02:42:00')], [Timestamp('2018-12-25 00:00:00'), Timestamp('2018-12-25 03:00:00'), Timestamp('2018-12-25 06:00:00'), Timestamp('2018-12-25 09:00:00'), Timestamp('2018-12-25 12:00:00'), Timestamp('2018-12-25 15:00:00'), Timestamp('2018-12-25 18:00:00'), Timestamp('2018-12-25 21:00:00'), Timestamp('2018-12-26 00:00:00'), Timestamp('2018-12-26 02:42:00')], [Timestamp('2018-12-26 00:00:00'), Timestamp('2018-12-26 03:00:00'), Timestamp('2018-12-26 06:00:00'), Timestamp('2018-12-26 09:00:00'), Timestamp('2018-12-26 12:00:00'), Timestamp('2018-12-26 15:00:00'), Timestamp('2018-12-26 18:00:00'), Timestamp('2018-12-26 21:00:00'), Timestamp('2018-12-27 00:00:00'), Timestamp('2018-12-27 00:48:00')], [Timestamp('2018-12-27 00:00:00'), Timestamp('2018-12-27 03:00:00'), Timestamp('2018-12-27 06:00:00'), Timestamp('2018-12-27 09:00:00'), Timestamp('2018-12-27 12:00:00'), Timestamp('2018-12-27 15:00:00'), Timestamp('2018-12-27 18:00:00'), Timestamp('2018-12-27 21:00:00'), Timestamp('2018-12-28 00:00:00'), Timestamp('2018-12-28 02:42:00')], [Timestamp('2018-12-28 00:00:00'), Timestamp('2018-12-28 03:00:00'), Timestamp('2018-12-28 06:00:00'), Timestamp('2018-12-28 09:00:00'), Timestamp('2018-12-28 12:00:00'), Timestamp('2018-12-28 15:00:00'), Timestamp('2018-12-28 18:00:00'), Timestamp('2018-12-28 18:34:00')], [Timestamp('2018-12-29 00:00:00'), Timestamp('2018-12-29 03:00:00'), Timestamp('2018-12-29 06:00:00'), Timestamp('2018-12-29 09:00:00'), Timestamp('2018-12-29 12:00:00'), Timestamp('2018-12-29 15:00:00'), Timestamp('2018-12-29 18:00:00'), Timestamp('2018-12-29 21:00:00'), Timestamp('2018-12-30 00:00:00'), Timestamp('2018-12-30 02:42:00')], [Timestamp('2018-12-30 00:00:00'), Timestamp('2018-12-30 03:00:00'), Timestamp('2018-12-30 06:00:00'), Timestamp('2018-12-30 09:00:00'), Timestamp('2018-12-30 12:00:00'), Timestamp('2018-12-30 15:00:00'), Timestamp('2018-12-30 18:00:00'), Timestamp('2018-12-30 21:00:00'), Timestamp('2018-12-31 00:00:00'), Timestamp('2018-12-31 02:42:00')], [Timestamp('2018-12-31 00:00:00'), Timestamp('2018-12-31 03:00:00'), Timestamp('2018-12-31 06:00:00'), Timestamp('2018-12-31 09:00:00'), Timestamp('2018-12-31 12:00:00'), Timestamp('2018-12-31 15:00:00'), Timestamp('2018-12-31 18:00:00'), Timestamp('2018-12-31 21:00:00'), Timestamp('2019-01-01 00:00:00'), Timestamp('2019-01-01 02:42:00')]]\n"
     ]
    }
   ],
   "source": [
    "# print(input_arcs)\n",
    "# print(input_epochstart)\n",
    "# print(input_epochstop)\n",
    "# print(scaleparameter_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a007299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T21:27:52.082475Z",
     "start_time": "2025-01-25T21:27:52.082215Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1c31d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.140586Z",
     "start_time": "2025-01-28T19:11:34.120514Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34e00a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T22:47:34.092909Z",
     "start_time": "2025-01-17T22:47:34.036908Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be0f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.160089Z",
     "start_time": "2025-01-28T19:11:34.143902Z"
    }
   },
   "outputs": [],
   "source": [
    "# file_raw_ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b027a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.178978Z",
     "start_time": "2025-01-28T19:11:34.162513Z"
    }
   },
   "outputs": [],
   "source": [
    "# arcs_yyyyddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730a3a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.197623Z",
     "start_time": "2025-01-28T19:11:34.182321Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75003888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T23:11:51.727592Z",
     "start_time": "2025-01-14T23:11:51.695587Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3925faa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T23:11:44.581458Z",
     "start_time": "2025-01-14T23:11:44.543453Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5f3af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.215235Z",
     "start_time": "2025-01-28T19:11:34.199569Z"
    }
   },
   "outputs": [],
   "source": [
    "# pd.to_datetime(val[:8],format=\"%Y.%j\").year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126ef5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T17:41:25.873991Z",
     "start_time": "2024-07-15T17:41:25.849323Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a9735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.236610Z",
     "start_time": "2025-01-28T19:11:34.217625Z"
    }
   },
   "outputs": [],
   "source": [
    "# input_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e48f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.397926Z",
     "start_time": "2025-01-28T19:11:34.238447Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cleanformat_axes(fig, font_dict):\n",
    "    rownum, colnum = fig._get_subplot_rows_columns()\n",
    "\n",
    "    for i in rownum:\n",
    "        if len(rownum)==1:\n",
    "            L_ticklabel = True\n",
    "        else:\n",
    "            if i < len(rownum):\n",
    "                L_ticklabel = False\n",
    "            else:\n",
    "                L_ticklabel = True\n",
    "        fig.update_xaxes(### LINE at axis border\n",
    "                          showline=True,\n",
    "                          showticklabels=L_ticklabel,\n",
    "    #                       tickformat= '%m/%d',\n",
    "                          linecolor='black',\n",
    "                          linewidth=1,\n",
    "                         ### Major ticks\n",
    "                          ticks='inside',\n",
    "                          tickfont=font_dict,\n",
    "                          mirror=True,\n",
    "    #                       tickwidth=2,\n",
    "    #                       ticklen=9,\n",
    "                          tickcolor='grey',\n",
    "    #                       tick0=\"2018-11-9\" ,\n",
    "    #                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "                          #### Minor Ticks\n",
    "                           minor=dict(\n",
    "                             dtick=86400000.0, # milliseconds in a day\n",
    "                             tickwidth=1,\n",
    "                             ticklen=4,\n",
    "                             tickcolor='grey',\n",
    "                             ticks='inside'),\n",
    "                          ### GRID\n",
    "                           gridcolor='gainsboro',\n",
    "                           gridwidth=1,\n",
    "                           layer='above traces',\n",
    "                           tickangle=0,\n",
    "                           row=i, col=1)\n",
    "        fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                             showticklabels=True,\n",
    "                             linecolor='black',  # line color\n",
    "                             linewidth=1,        # line size\n",
    "                         ticks='inside',     # ticks outside axis\n",
    "                         tickfont=font_dict, # tick label font\n",
    "                         mirror='allticks',  # add ticks to top/right axes\n",
    "                         tickwidth=1,      # tick width\n",
    "                         tickcolor='black',  # tick color\n",
    "                         gridcolor='gainsboro',\n",
    "                         gridwidth=1,\n",
    "                         layer='above traces',\n",
    "                         row=i, col=1)\n",
    "    return(fig)\n",
    "\n",
    "from pygeodyn.pygeodyn_plot_scalingfactors import *\n",
    "\n",
    "coldict = {}\n",
    "coldict['msis2']     = \"#2ca02c\"  # 'tab:green'\n",
    "coldict['dtm2020_o'] = \"#d62728\"  # 'tab:red'\n",
    "coldict['jb2008']    = \"orange\"   \n",
    "coldict['hasdm_oc']  = \"#1f77b4\"     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df08c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.413242Z",
     "start_time": "2025-01-28T19:11:34.399668Z"
    }
   },
   "outputs": [],
   "source": [
    "# arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea698c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:11:34.783548Z",
     "start_time": "2025-01-28T19:11:34.415290Z"
    }
   },
   "outputs": [],
   "source": [
    "  \n",
    "satid = 1807001\n",
    "wgts = {}\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    wgts[model] = {}\n",
    "    ScalingFactors  = []\n",
    "    ScalingFactor_times = []\n",
    "\n",
    "    for ii,arc in enumerate(obj[model]['global_params']['arc_input']):\n",
    "        if arc == '2019.365':\n",
    "            continue\n",
    "        \n",
    "        epochstart = obj[model]['global_params']['prms']['epoch_start'][ii]\n",
    "        hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "        frachours =(hrs/24)\n",
    "        #\n",
    "        if len(arc) == 9:\n",
    "            maneuv_indicator = arc[8]\n",
    "        else:\n",
    "            maneuv_indicator = ''\n",
    "        arc_type = obj[model]['global_params']['prms']['arc_type']\n",
    "        if arc_type == \"Nominal30hr_and_AB\":\n",
    "            arc_name =arc[:8]+ maneuv_indicator\n",
    "            arc_name_DOY = arc[:8]\n",
    "        else:\n",
    "            arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "        ### Collect the weights for the ensemble average\n",
    "        inv_rms          = 1/obj[model]['Statistics'][arc_name]['T_RMS'].values[0]\n",
    "        wgts[model][arc_name_DOY] = inv_rms#/sum_wgts\n",
    "\n",
    "        iters = int(obj[model]['run_parameters'+arc_name]['total_iterations']) \n",
    "        for iit, itime in enumerate(obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'].keys()):\n",
    "            \n",
    "            numSFs = len(obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'])\n",
    "            \n",
    "            if iit == 0 or iit==numSFs-1:   # remove the first and last Scaling Factor to account for edge effects\n",
    "                pass\n",
    "            else:\n",
    "                CURRENT_VALUE = obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "                APRIORI_VALUE = obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "                ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "                ScalingFactor_times.append(itime)\n",
    "    run_dict[model]['ScalingFactor_times'] = ScalingFactor_times\n",
    "    run_dict[model]['ScalingFactors']      = ScalingFactors\n",
    "    run_dict[model]['Weight'] = wgts[model]\n",
    "    \n",
    "\n",
    "    \n",
    "# ###### SCALE THE DENSITIES:\n",
    "# models_dens = {}\n",
    "# for monthmodel in run_dict.keys():\n",
    "#     print(f\"---Making continuous scaled rho for {monthmodel}\")\n",
    "#     models_dens[monthmodel] = get_continuous_scaled_densities(obj, run_dict, monthmodel, scale_cadence)\n",
    "\n",
    "#     del obj[monthmodel]\n",
    "#     gc_collect()\n",
    "\n",
    "# del obj\n",
    "# gc_collect()\n",
    "\n",
    "# # Retrieve scaled ensemble weighted average\n",
    "# #     'Rho_x' denotes the ensemble weighted avg\n",
    "# print(f\"\")\n",
    "# print(f\"--- Processing Rho_x\")\n",
    "# yearmonth_list = [\n",
    "#                   '2019jan',\n",
    "#                   '2019feb',\n",
    "#                   '2019mar',\n",
    "#                   '2019apr',\n",
    "#                   '2019may',\n",
    "#                   '2019jun',\n",
    "#                   '2019jul',\n",
    "#                   '2019aug',\n",
    "#                   '2019sep',\n",
    "#                   '2019oct',\n",
    "#                   '2019nov',\n",
    "#                   '2019dec',\n",
    "#                  ]\n",
    "# models_dens =  calc_rho_ScaledEnsembleWgtAvg(models_dens, run_dict, yearmonth_list, run_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ea294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.517790Z",
     "start_time": "2025-01-28T19:11:34.785510Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def PLOT_retrievedRHO(fig, obj_m1,  model_dict, model_name):\n",
    "    obj_m1=obj_m1[model_name]\n",
    "    model_m1 = model_name[7:]\n",
    "    \n",
    "#     if model_m1 == 'dtm2020_o':\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=pd.to_datetime(model_dict['ScalingFactor_times'])-pd.to_timedelta(scale_cadence/2, 'h'),\n",
    "                               y=model_dict['ScalingFactors'],\n",
    "                               name= model,\n",
    "                               mode='markers',\n",
    "                               opacity=1,\n",
    "#                                    marker=dict(color=coldict[model_m1], \n",
    "#                                                size=5,\n",
    "#                                                symbol='line-ew',\n",
    "#                                                line = dict(color = coldict[model_m1], width=3)), #symbol='diamond-wide'),\n",
    "                                   marker=dict(color=coldict[model_m1], size=5),\n",
    "                               line = dict(shape = 'hvh',dash ='dot', color = coldict[model_m1], width=1),\n",
    "                               showlegend=False),\n",
    "                               secondary_y=False,row=1, col=1)\n",
    "\n",
    "    if model_m1 == 'dtm2020_o':\n",
    "        \n",
    "    \n",
    "        for ii,arc in enumerate(obj_m1['global_params']['arc_input']):\n",
    "            epochstart = obj_m1['global_params']['prms']['epoch_start'][ii]\n",
    "            hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "            frachours =(hrs/24)\n",
    "            #\n",
    "            if len(arc) == 9:\n",
    "                maneuv_indicator = arc[8]\n",
    "            else:\n",
    "                maneuv_indicator = ''\n",
    "            arc_type = obj_m1['global_params']['prms']['arc_type']\n",
    "            if arc_type == \"Nominal30hr_and_AB\":\n",
    "                arc_name =arc[:8]+ maneuv_indicator\n",
    "            else:\n",
    "                arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "\n",
    "            drag_data        = obj_m1['DragFile'][arc_name]\n",
    "            drag_data[\"Lat\"] = obj_m1['Density' ][arc_name]['Lat']\n",
    "            den_df           = obj_m1['Density' ][arc_name]\n",
    "\n",
    "    #         print(arc[:8])\n",
    "            ### Cut off the extra time for the regular days\n",
    "            start_arc = pd.to_datetime(arc[:8], format='%Y.%j')\n",
    "            end_arc   = pd.to_datetime(arc[:8], format = '%Y.%j')+pd.to_timedelta(24, 'h')-pd.to_timedelta(1, 'm')\n",
    "\n",
    "    #         print(f\" {arc_name:10}|   , {start_arc},  {end_arc}\")\n",
    "\n",
    "            ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "            drag_data = drag_data.query( \\\n",
    "                    f\"{start_arc.year}\"         \\\n",
    "                   +f\"{start_arc.month:02d}\"    \\\n",
    "                   +f\"{start_arc.day:02d}\"      \\\n",
    "                   +f\"{start_arc.hour:02d}\"     \\\n",
    "                   +f\"{start_arc.minute:02d}\"   \\\n",
    "                   +f\"{start_arc.second:02d}\"   \\\n",
    "                   +f\" <= Date < \"                     \\\n",
    "                   +f\"{end_arc.year}\"       \\\n",
    "                   +f\"{end_arc.month:02d}\"  \\\n",
    "                   +f\"{end_arc.day:02d}\"    \\\n",
    "                   +f\"{end_arc.hour:02d}\"   \\\n",
    "                   +f\"{end_arc.minute:02d}\" \\\n",
    "                   +f\"{end_arc.second:02d}\" \\\n",
    "                )\n",
    "\n",
    "            indplot = 4\n",
    "            fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "                                   y=drag_data['TOTAREA'][::indplot],\n",
    "                                 mode='markers',\n",
    "                                 opacity=1,\n",
    "                                 marker=dict(color= 'gray',size=2,),\n",
    "                                 showlegend=False,),\n",
    "                                 secondary_y=False,\n",
    "                                 row=2, col=1,)\n",
    "            \n",
    "            (time_avg, avg_area) = orbit_avg_generic(drag_data['Date'],drag_data['TOTAREA'],drag_data['Lat'])    \n",
    "            fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                                     y=avg_area,\n",
    "    #                                  y=avg_cd,\n",
    "                               mode='lines',\n",
    "                               opacity=1,\n",
    "                                   line = dict(dash ='solid', color = 'black', width=3),\n",
    "                               showlegend=False), row=2, col=1)\n",
    "            \n",
    "            fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "                                   y=drag_data['CD'][::indplot],\n",
    "                                 mode='markers',\n",
    "                                 opacity=1,\n",
    "                                 marker=dict(color= 'gray',size=2,),\n",
    "                                 showlegend=False,),\n",
    "                                 secondary_y=False,\n",
    "                                 row=3, col=1,)\n",
    "            \n",
    "            (time_avg, avg_cd ) = orbit_avg_generic(drag_data['Date'],drag_data['CD'],drag_data['Lat'])    \n",
    "            fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                                     y=avg_cd,\n",
    "    #                                  y=avg_cd,\n",
    "                               mode='lines',\n",
    "                               opacity=1,\n",
    "                                   line = dict(dash ='solid', color = 'black', width=3),\n",
    "                               showlegend=False), row=3, col=1)\n",
    "            \n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                    y=drag_data['SpeedRatio'][::indplot],\n",
    "#                                  mode='markers',\n",
    "#                                  opacity=1,\n",
    "#                                  marker=dict(color= 'gray',size=2,),\n",
    "#                                  showlegend=False,),\n",
    "#                                  secondary_y=False,\n",
    "#                                  row=4, col=1,)\n",
    "            \n",
    "            (time_avg, avg_SpeedRatio ) = orbit_avg_generic(drag_data['Date'],drag_data['SpeedRatio'],drag_data['Lat'])    \n",
    "            fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                                     y=avg_SpeedRatio,\n",
    "    #                                  y=avg_cd,\n",
    "                               mode='lines',\n",
    "                               opacity=1,\n",
    "                                   line = dict(dash ='solid', color = 'black', width=3),\n",
    "                               showlegend=False), row=4, col=1)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "             \n",
    "    return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig  = make_subplots(\n",
    "    rows=4, cols=1,\n",
    "    vertical_spacing = 0.05,\n",
    "    shared_xaxes=True)\n",
    "\n",
    "\n",
    "\n",
    "# run_dict = { }\n",
    "# rms_total_return = {}\n",
    "\n",
    "for model in run_dict.keys():\n",
    "    print(model)\n",
    "#     for imonth,month in enumerate(month_list):\n",
    "\n",
    "#     fig = PLOT_retrievedRHO(fig, obj[model],   models_dens[model], run_dict[model], model)\n",
    "    fig = PLOT_retrievedRHO(fig, obj,    run_dict[model], model)\n",
    "\n",
    "    \n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=11,color='black')\n",
    "## automate the specification of the axes for subplots\n",
    "rownum, colnum = fig._get_subplot_rows_columns()\n",
    "for i in rownum:\n",
    "    if len(rownum)==1:\n",
    "        L_ticklabel = True\n",
    "    else:\n",
    "        if i < len(rownum):\n",
    "            L_ticklabel = False\n",
    "        else:\n",
    "            L_ticklabel = True\n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,\n",
    "                      showticklabels=L_ticklabel,\n",
    "#                       tickformat= '%m/%d',\n",
    "                      linecolor='black',\n",
    "                      linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',\n",
    "                      tickfont=font_dict,\n",
    "                      mirror=True,\n",
    "#                       tickwidth=2,\n",
    "#                       ticklen=9,\n",
    "                      tickcolor='grey',\n",
    "#                       tick0=\"2018-11-9\" ,\n",
    "#                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(\n",
    "                         dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,\n",
    "                         ticklen=4,\n",
    "                         tickcolor='grey',\n",
    "                         ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',\n",
    "                       gridwidth=1,\n",
    "                       layer='above traces',\n",
    "                       tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                         showticklabels=True,\n",
    "                         linecolor='black',  # line color\n",
    "                         linewidth=1,        # line size\n",
    "                     ticks='inside',     # ticks outside axis\n",
    "                     tickfont=font_dict, # tick label font\n",
    "                     mirror='allticks',  # add ticks to top/right axes\n",
    "                     tickwidth=1,      # tick width\n",
    "                     tickcolor='black',  # tick color\n",
    "                     gridcolor='gainsboro',\n",
    "                     gridwidth=1,\n",
    "                     layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Scaling Factor\", \n",
    "                     exponentformat= 'power',row=1, col=1)\n",
    "\n",
    "#     yaxis_range = [-13.7 -.55 ,  -12.6+.25]# ] #full_fig.layout.yaxis2.range\n",
    "\n",
    "#     fig.update_yaxes(title_text=\"Scaled Density\", \n",
    "#                      type=\"log\", \n",
    "# #                       range=yaxis_range,\n",
    "#                      exponentformat= 'power',row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"A\", \n",
    "#                       type=\"log\", \n",
    "#                       range=yaxis_range,\n",
    "                     exponentformat= 'power',row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"CD_DRIA\", \n",
    "#                       type=\"log\", \n",
    "#                       range=yaxis_range,\n",
    "                     exponentformat= 'power',row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"SpeedRatio\", \n",
    "#                       type=\"log\", \n",
    "#                       range=yaxis_range,\n",
    "                     exponentformat= 'power',row=4, col=1)\n",
    "    \n",
    "    \n",
    "fig.update_layout(margin=dict(l=20, r=20, t=20, b=20),)\n",
    "\n",
    "# a='input'\n",
    "# s=settings_icesat2\n",
    "\n",
    "fig.add_vline(x=datetime.strptime(\"2018-10-27 21:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,\n",
    "                            annotation_text=\"Sailboat (+B)\", \n",
    "                            annotation_position=\"top left\",\n",
    "                            annotation_font_size=12,\n",
    "                            annotation_font_color=\"#FC1CBF\",\n",
    "                            line_width=1, line_dash=\"dash\",\n",
    "                            row=1, col=1)\n",
    "\n",
    "fig.add_vline(x=datetime.strptime(\"2018-10-27 21:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,\n",
    "                            annotation_text=\"Airplane (+B)\", \n",
    "                            annotation_position=\"top right\",\n",
    "                            annotation_font_size=12,\n",
    "                            annotation_font_color=\"green\",\n",
    "                            line_width=0, line_dash=\"dash\",\n",
    "                              row=1, col=1)\n",
    "\n",
    "fig.add_vline(x=datetime.strptime(\"2018-12-29 03:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000, \n",
    "                          annotation_text=\"Airplane (-B)\", \n",
    "                            annotation_position=\"top right\",\n",
    "                            annotation_font_size=12,\n",
    "                            annotation_font_color=\"green\",\n",
    "                            line_width=1, line_dash=\"dash\",\n",
    "                          row=1, col=1)\n",
    "fig.add_vline(x=datetime.strptime(\"2019-02-27 04:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,                \n",
    "                            annotation_text=\"Sailboat(-B)\", \n",
    "                            annotation_position=\"top right\",\n",
    "                            annotation_font_size=12,\n",
    "                            annotation_font_color=\"#FC1CBF\",\n",
    "                            line_width=1, line_dash=\"dash\",\n",
    "                          row=1, col=1)\n",
    "fig.add_vline(x=datetime.strptime(\"2019-06-27 00:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,                \n",
    "                            annotation_text=\"Airplane (-B)\", \n",
    "                            annotation_position=\"top right\",\n",
    "                            annotation_font_size=12,\n",
    "                            annotation_font_color=\"green\",\n",
    "                            line_width=2, line_dash=\"dash\",\n",
    "                          row=1, col=1)\n",
    "\n",
    "fig.add_vline(x=datetime.strptime(\"2019-09-07 00:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,                \n",
    "                            annotation_text=\"Airplane (+B)\", \n",
    "                            annotation_position=\"top right\",\n",
    "                            annotation_font_size=12,\n",
    "                            annotation_font_color=\"green\",\n",
    "                            line_width=2, line_dash=\"dash\",\n",
    "                          row=1, col=1)\n",
    "\n",
    "fig.add_vline(x=datetime.strptime(\"2019-11-17 00:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,                \n",
    "                            annotation_text=\"Sailboat (+B)\", \n",
    "                            annotation_position=\"top right\",\n",
    "                            annotation_font_size=12,\n",
    "                            annotation_font_color=\"#FC1CBF\",\n",
    "                            line_width=2, line_dash=\"dash\",\n",
    "                          row=1, col=1)\n",
    "\n",
    "#####################################################################################\n",
    "for i in rownum:\n",
    "    fig.add_vline(x=datetime.strptime(\"2018-10-27 21:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,\n",
    "                                annotation_text=\"\", \n",
    "                                annotation_position=\"top left\",\n",
    "                                annotation_font_size=12,\n",
    "                                annotation_font_color=\"#FC1CBF\",\n",
    "                                line_width=1, line_dash=\"dash\",\n",
    "                                row=i, col=1)\n",
    "    fig.add_vline(x=datetime.strptime(\"2018-10-27 21:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,\n",
    "                                annotation_text=\"\", \n",
    "                                annotation_position=\"top right\",\n",
    "                                annotation_font_size=12,\n",
    "                                annotation_font_color=\"green\",\n",
    "                                line_width=0, line_dash=\"dash\",\n",
    "                                  row=i, col=1)\n",
    "\n",
    "    fig.add_vline(x=datetime.strptime(\"2018-12-29 03:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000, \n",
    "                              annotation_text=\"\", \n",
    "                                annotation_position=\"top right\",\n",
    "                                annotation_font_size=12,\n",
    "                                annotation_font_color=\"green\",\n",
    "                                line_width=1, line_dash=\"dash\",\n",
    "                              row=i, col=1)\n",
    "    fig.add_vline(x=datetime.strptime(\"2019-02-27 04:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,                \n",
    "                                annotation_text=\"\", \n",
    "                                annotation_position=\"top right\",\n",
    "                                annotation_font_size=12,\n",
    "                                annotation_font_color=\"#FC1CBF\",\n",
    "                                line_width=1, line_dash=\"dash\",\n",
    "                              row=i, col=1)\n",
    "    fig.add_vline(x=datetime.strptime(\"2019-06-27 00:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,                \n",
    "                            annotation_text=\" \", \n",
    "                            annotation_position=\"top right\",\n",
    "                            annotation_font_size=12,\n",
    "                            annotation_font_color=\"green\",\n",
    "                            line_width=2, line_dash=\"dash\",\n",
    "                          row=i, col=1)\n",
    "\n",
    "    fig.add_vline(x=datetime.strptime(\"2019-09-07 00:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,                \n",
    "                                annotation_text=\" \", \n",
    "                                annotation_position=\"top right\",\n",
    "                                annotation_font_size=12,\n",
    "                                annotation_font_color=\"green\",\n",
    "                                line_width=2, line_dash=\"dash\",\n",
    "                              row=i, col=1)\n",
    "\n",
    "    fig.add_vline(x=datetime.strptime(\"2019-11-17 00:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,                \n",
    "                                annotation_text=\" \", \n",
    "                                annotation_position=\"top right\",\n",
    "                                annotation_font_size=12,\n",
    "                                annotation_font_color=\"#FC1CBF\",\n",
    "                                line_width=2, line_dash=\"dash\",\n",
    "                              row=i, col=1)\n",
    "\n",
    "fig.update_xaxes(range=[pd.to_datetime( \"181013-000000\", format='%y%m%d-%H%M%S'),\n",
    "                        pd.to_datetime( \"200102-000000\", format='%y%m%d-%H%M%S')])\n",
    "\n",
    "\n",
    "fig.update_layout(#title=f\"{s['cd_model'][a]}, {s['hours_between_cd_adj'][a]}-hr Scale from CD={s['cd_value'][a]}\",\n",
    "#                     title=f\"BWDRAG, 3-hr Scale from CD=2.5 \",\n",
    "                  autosize=False,    width=1000,    height=600,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "# fig.update_annotations(font_size=12)  # Increase size of subplot title\n",
    "fig.show(config= dict({\n",
    "                'displayModeBar': False,\n",
    "                'responsive': True,\n",
    "                'staticPlot': False,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                }),\n",
    "#          renderer='jpg',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee81f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.536579Z",
     "start_time": "2025-01-28T19:14:01.519690Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Retrieve scaled ensemble weighted average\n",
    "# #     'Rho_x' denotes the ensemble weighted avg\n",
    "# yearmonth_list = ['2018oct',\n",
    "#               '2018nov',\n",
    "#               '2018dec',\n",
    "#               '2019jan',\n",
    "#               '2019feb',\n",
    "#               '2019mar',\n",
    "#               '2019apr']\n",
    "# print(f\"--- Processing Rho_x\")\n",
    "# models_dens =  calc_rho_ScaledEnsembleWgtAvg(models_dens, run_dict, yearmonth_list, run_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e946cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.958647Z",
     "start_time": "2025-01-28T19:14:01.538693Z"
    }
   },
   "outputs": [],
   "source": [
    "# models_dens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e847bc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.979960Z",
     "start_time": "2025-01-28T19:14:01.979943Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for ii,arc in enumerate(obj[model]['global_params']['arc_input']):\n",
    "#     print()\n",
    "#     epochstart = obj[model]['global_params']['prms']['epoch_start'][ii]\n",
    "#     hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "#     frachours =(hrs/24)\n",
    "#     #\n",
    "#     if len(arc) == 9:\n",
    "#         maneuv_indicator = arc[8]\n",
    "#     else:\n",
    "#         maneuv_indicator = ''\n",
    "#     arc_type = obj[model]['global_params']['prms']['arc_type']\n",
    "#     if arc_type == \"Nominal30hr_and_AB\":\n",
    "#         arc_name =arc[:8]+ maneuv_indicator\n",
    "#         arc_name_DOY = arc[:8]\n",
    "#     else:\n",
    "#         arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "#     ### Collect the weights for the ensemble average\n",
    "#     inv_rms          = 1/obj[model]['Statistics'][arc_name]['T_RMS'].values[0]\n",
    "#     wgts[model][arc_name_DOY] = inv_rms#/sum_wgts\n",
    "\n",
    "#     iters = int(obj[model]['run_parameters'+arc_name]['total_iterations']) \n",
    "#     for iit, itime in enumerate(obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'].keys()):\n",
    "\n",
    "#         numSFs = len(obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'])\n",
    "\n",
    "#         if iit == 0 or iit==numSFs-1:   # remove the first and last Scaling Factor to account for edge effects\n",
    "#             pass\n",
    "#         else:\n",
    "#             CURRENT_VALUE = obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "#             APRIORI_VALUE = obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "#             ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "#             ScalingFactor_times.append(itime)\n",
    "#             print(f\"{itime} : {CURRENT_VALUE/APRIORI_VALUE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bbdeb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.981176Z",
     "start_time": "2025-01-28T19:14:01.981161Z"
    }
   },
   "outputs": [],
   "source": [
    "# for iit, itime in enumerate(obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'].keys()):\n",
    "\n",
    "#     numSFs = len(obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'])\n",
    "\n",
    "# #         if iit == 0 or iit==numSFs-1:   # remove the first and last Scaling Factor to account for edge effects\n",
    "# #             pass\n",
    "# #         else:\n",
    "#     CURRENT_VALUE = obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'][itime]['CURRENT_VALUE']\n",
    "#     APRIORI_VALUE = obj[model]['AdjustedParams'][arc_name][iters][satid]['0CD'][itime]['APRIORI_VALUE']\n",
    "# #     ScalingFactors.append(CURRENT_VALUE/APRIORI_VALUE)\n",
    "# #     ScalingFactor_times.append(itime)\n",
    "    \n",
    "#     print(f\"{itime} : {CURRENT_VALUE/APRIORI_VALUE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06672d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbf233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d900e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T21:08:08.930527Z",
     "start_time": "2025-01-10T21:07:52.868351Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a0a69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T21:08:08.951412Z",
     "start_time": "2025-01-10T21:08:08.932265Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd6a94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T21:23:45.950197Z",
     "start_time": "2025-01-10T21:23:45.930816Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd602d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T21:08:09.960255Z",
     "start_time": "2025-01-10T21:08:09.041392Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e10ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5c099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9861f339",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T21:08:09.984934Z",
     "start_time": "2025-01-10T21:08:09.962320Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d9b9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T21:26:04.265600Z",
     "start_time": "2024-12-04T21:25:58.851691Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c697f203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.982212Z",
     "start_time": "2025-01-28T19:14:01.982197Z"
    }
   },
   "outputs": [],
   "source": [
    "import linecache\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path_to_flux = \"/data/SatDragModelValidation/src/geodyn_code/support/geodyn_support/make_tables/\"\n",
    "\n",
    "\n",
    "dateS   = []\n",
    "dateAP  = []\n",
    "dateKP8 = []\n",
    "\n",
    "fluxS   = []\n",
    "fluxAP  = []\n",
    "fluxKP8 = []\n",
    "\n",
    "switch = 0\n",
    "with open(path_to_flux+\"new_master\", 'r') as f:\n",
    "    for line_no, string in enumerate(f):\n",
    "#         string = linecache.getline(\"new_master\",line+1) #\n",
    "\n",
    "        if 'MASTER' in string:        \n",
    "            switch = 'skip'\n",
    "            continue\n",
    "            \n",
    "        ### Skip the title lines and any dates before Y2K\n",
    "        if 'FLUXS' in string:        \n",
    "            switch = 'readfluxS'\n",
    "            print(switch)\n",
    "            continue\n",
    "\n",
    "        if 'FLUXAP' in string:        \n",
    "            switch = 'readfluxAP'\n",
    "            print(switch)\n",
    "            continue\n",
    "        if 'FLUXKP8' in string:        \n",
    "            switch = 'readfluxKP8'\n",
    "            print(switch)\n",
    "            continue\n",
    "\n",
    "        if switch =='skip':\n",
    "            continue\n",
    "            \n",
    "        if int(string[:2]) >= 58:\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            if int(string[:2]) < 18 or int(string[:2]) > 19:\n",
    "                continue\n",
    "                \n",
    "            if switch == 'readfluxS':\n",
    "                ### Load the Solar Flux values after 2000. The date leading each line represents\n",
    "                ### the first flux value in that line.  The following n values are that day + n days.\n",
    "                ###  All Solar Flux values are mulitplied by 10 for some reason...\n",
    "\n",
    "                for n in range(0,12):\n",
    "                    dateS.append(pd.to_datetime(string[:6],format='%y%m%d') + n*pd.to_timedelta(1,'d') )\n",
    "                fluxS.append(int(string[11:15]) / 10)\n",
    "                fluxS.append(int(string[16:20]) / 10)\n",
    "                fluxS.append(int(string[21:25]) / 10)\n",
    "                fluxS.append(int(string[26:30]) / 10)\n",
    "                fluxS.append(int(string[31:35]) / 10)\n",
    "                fluxS.append(int(string[36:40]) / 10)\n",
    "                fluxS.append(int(string[41:45]) / 10)\n",
    "                fluxS.append(int(string[46:50]) / 10)\n",
    "                fluxS.append(int(string[51:55]) / 10)\n",
    "                fluxS.append(int(string[56:60]) / 10)\n",
    "                fluxS.append(int(string[61:65]) / 10)\n",
    "                fluxS.append(int(string[66:70]) / 10)\n",
    "\n",
    "            if switch == 'readfluxAP':\n",
    "                ### Load the AP values after 2000. These are formatted the same as the FLUXS section\n",
    "                for n in range(0,12):\n",
    "                    dateAP.append(pd.to_datetime(string[:6],format='%y%m%d') + n*pd.to_timedelta(1,'d') )\n",
    "                fluxAP.append(int(string[11:15]) / 10)\n",
    "                fluxAP.append(int(string[16:20]) / 10)\n",
    "                fluxAP.append(int(string[21:25]) / 10)\n",
    "                fluxAP.append(int(string[26:30]) / 10)\n",
    "                fluxAP.append(int(string[31:35]) / 10)\n",
    "                fluxAP.append(int(string[36:40]) / 10)\n",
    "                fluxAP.append(int(string[41:45]) / 10)\n",
    "                fluxAP.append(int(string[46:50]) / 10)\n",
    "                fluxAP.append(int(string[51:55]) / 10)\n",
    "                fluxAP.append(int(string[56:60]) / 10)\n",
    "                fluxAP.append(int(string[61:65]) / 10)\n",
    "                fluxAP.append(int(string[66:70]) / 10)\n",
    "\n",
    "            if switch == 'readfluxKP8':\n",
    "                ### Load the KP values after 2000. These are formatted such that each line is a day\n",
    "                ### and each nth value in the line is n*3hrs for the day\n",
    "                for n in range(0,8):\n",
    "                    dateKP8.append(pd.to_datetime(string[:6],format='%y%m%d') + n*pd.to_timedelta(3,'h') )\n",
    "                fluxKP8.append(int(string[7:11])  / 100)\n",
    "                fluxKP8.append(int(string[12:16]) / 100)\n",
    "                fluxKP8.append(int(string[17:21]) / 100)\n",
    "                fluxKP8.append(int(string[22:26]) / 100)\n",
    "                fluxKP8.append(int(string[27:31]) / 100)\n",
    "                fluxKP8.append(int(string[32:36]) / 100)\n",
    "                fluxKP8.append(int(string[37:41]) / 100)\n",
    "                fluxKP8.append(int(string[42:46]) / 100)\n",
    "\n",
    "fluxS = np.array(fluxS)\n",
    "fluxAP = np.array(fluxAP)\n",
    "fluxKP8 = np.array(fluxKP8)\n",
    "                \n",
    "fluxS   = np.where(fluxS  == 0., np.nan, fluxS  )\n",
    "fluxAP  = np.where(fluxAP ==0., np.nan, fluxAP )\n",
    "fluxKP8 = np.where(fluxKP8==0., np.nan, fluxKP8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b026bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.983331Z",
     "start_time": "2025-01-28T19:14:01.983315Z"
    }
   },
   "outputs": [],
   "source": [
    "dateS[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186c836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25274077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.984325Z",
     "start_time": "2025-01-28T19:14:01.984310Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "def PLOT_resids(fig,  den_dict, model_dict, _model_name_):\n",
    "    \n",
    "    SHOW_alldata = True\n",
    "    \n",
    "    model_m1 = _model_name_[7:]\n",
    "#     print('model_m1', model_m1)\n",
    "\n",
    "    fig.add_trace(go.Scattergl(x=pd.to_datetime(model_dict['ScalingFactor_times'])-pd.to_timedelta(scale_cadence/2, 'h'),\n",
    "                           y=model_dict['ScalingFactors'],\n",
    "                           name= model,\n",
    "                           mode='markers',\n",
    "                           opacity=1,\n",
    "                           marker=dict(color=coldict[model_m1], size=5),\n",
    "#                                marker=dict(color=coldict[model_m1], \n",
    "#                                            size=6,\n",
    "#                                            symbol='line-ew',\n",
    "#                                            line = dict(color = coldict[model_m1], width=3)), #symbol='diamond-wide'),\n",
    "#                            line = dict(shape = 'hvh',dash ='dash', color = coldict[model_m1], width=1),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=2, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    time_avg,dscale_avg = orbit_avg_generic(den_dict['dates'], den_dict['denscaled'], den_dict['lat'])\n",
    "    ## -----------------------------------------------------------------------------------------------------\n",
    "    ##     Orbit Averaged Density\n",
    "    fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                               y=dscale_avg,\n",
    "                               ### name= model_m1,\n",
    "                               mode='markers+lines',\n",
    "                               opacity=1,\n",
    "                                   marker=dict(color=coldict[model_m1],size=2),\n",
    "                                   line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "                               showlegend=False), row=4, col=1)\n",
    "#     fig.add_trace(go.Scattergl(x=den_dict['dates'],\n",
    "#                                y=den_dict['denscaled'],\n",
    "#                                ### name= model_m1,\n",
    "#                                mode='markers+lines',\n",
    "#                                opacity=1,\n",
    "#                                    marker=dict(color=coldict[model_m1],size=2),\n",
    "#                                    line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                                showlegend=False), row=3, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    time_avg,d_avg = orbit_avg_generic(den_dict['dates'], den_dict['dens'], den_dict['lat'])\n",
    "    ### -----------------------------------------------------------------------------------------------------\n",
    "    ###     Orbit Averaged Density\n",
    "#     fig.add_trace(go.Scattergl(x=den_dict['dates'], #time_avg,\n",
    "#                                y=den_dict['dens'], #d_avg,\n",
    "#                                ### name= model_m1,\n",
    "#                                mode='markers+lines',\n",
    "#                                opacity=1,\n",
    "#                                    marker=dict(color=coldict[model_m1],size=1),\n",
    "#                                    line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                                showlegend=False), row=2, col=1)\n",
    "\n",
    "    ###     Orbit Averaged Density\n",
    "    fig.add_trace(go.Scattergl(x=time_avg,\n",
    "                               y=d_avg,\n",
    "                               ### name= model_m1,\n",
    "                               mode='markers+lines',\n",
    "                               opacity=1,\n",
    "                                   marker=dict(color= coldict[model_m1],size=2),\n",
    "                                   line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "                               showlegend=False), row=3, col=1)\n",
    "    \n",
    "    \n",
    "#                 time_avg,CD_avg, area_avg_rolling, CD_std = orb_avg_param(obj_m1.__dict__['DragFile'], arc_string, 'TOTAREA')\n",
    "#                 fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                            y=area_avg_rolling,\n",
    "#     #                                          name= plot_name+arc,\n",
    "#                                              mode='markers+lines',\n",
    "#                                              opacity=1,\n",
    "#                                              marker=dict(color=col,size=2,),\n",
    "#                                              line = dict(shape='hvh', dash ='solid', color = col, width=3),\n",
    "#                                              showlegend=False, ),\n",
    "#                                              secondary_y=False,\n",
    "#                                              row=3, col=1,\n",
    "#                                          )\n",
    "\n",
    "    return(fig)\n",
    "\n",
    "\n",
    "fig  = make_subplots(\n",
    "    rows=4, cols=1,\n",
    "    vertical_spacing = 0.05,\n",
    "    shared_xaxes=True)\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=4, cols=1, row_heights=[0.1, 0.3, 0.3, 0.3],#],\n",
    "                    specs=[[{\"secondary_y\": True}],\n",
    "                           [{\"secondary_y\": False}],\n",
    "                           [{\"secondary_y\": False}],\n",
    "                           [{\"secondary_y\": False}]],\n",
    "                           shared_xaxes=True,\n",
    "                           vertical_spacing=0.02)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scattergl(x=dateS,\n",
    "                           y=fluxS,\n",
    "                           name= 'F107d_1AU',\n",
    "                           mode='lines',\n",
    "                           opacity=1,\n",
    "                           line = dict(shape = 'hvh',dash='dash', color = 'blue', width=2),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=True,row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scattergl(x=dateKP8,\n",
    "                           y=fluxKP8,\n",
    "                           name= 'Kp',\n",
    "                           mode='lines',\n",
    "                           opacity=1,\n",
    "                           line = dict(shape = 'hvh', color = 'black', width=2),\n",
    "                           showlegend=False),\n",
    "                           secondary_y=False,row=1, col=1) \n",
    "\n",
    "fig.update_yaxes(title_text=\"Kp\", \n",
    "                 exponentformat= 'power',\n",
    "#                  range=[0,7],\n",
    "                 secondary_y=False,\n",
    "                 row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"F10.7\", \n",
    "                 exponentformat= 'power',\n",
    "                 range=[35,170],\n",
    "                 secondary_y=True,\n",
    "                 tickfont=dict(color=\"blue\"),\n",
    "                 titlefont=dict(color=\"blue\"),\n",
    "                 row=1, col=1)\n",
    "\n",
    "for model in run_dict.keys():\n",
    "#     for imonth,month in enumerate(month_list):\n",
    "#     print('model', model)\n",
    "\n",
    "    fig = PLOT_resids(fig, models_dens[model], run_dict[model], model)\n",
    "\n",
    "    \n",
    "#######################################################\n",
    "font_dict=dict(family='Arial',size=11,color='black')\n",
    "## automate the specification of the axes for subplots\n",
    "rownum, colnum = fig._get_subplot_rows_columns()\n",
    "for i in rownum:\n",
    "    if len(rownum)==1:\n",
    "        L_ticklabel = True\n",
    "    else:\n",
    "        if i < len(rownum):\n",
    "            L_ticklabel = True\n",
    "        else:\n",
    "            L_ticklabel = True\n",
    "    fig.update_xaxes(### LINE at axis border\n",
    "                      showline=True,\n",
    "                      showticklabels=L_ticklabel,\n",
    "#                       tickformat= '%m/%d',\n",
    "                      linecolor='black',\n",
    "                      linewidth=1,\n",
    "                     ### Major ticks\n",
    "                      ticks='inside',\n",
    "                      tickfont=font_dict,\n",
    "                      mirror=True,\n",
    "#                       tickwidth=2,\n",
    "#                       ticklen=9,\n",
    "                      tickcolor='grey',\n",
    "#                       tick0=\"2018-11-9\" ,\n",
    "#                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "                      #### Minor Ticks\n",
    "                       minor=dict(\n",
    "                         dtick=86400000.0, # milliseconds in a day\n",
    "                         tickwidth=1,\n",
    "                         ticklen=4,\n",
    "                         tickcolor='grey',\n",
    "                         ticks='inside'),\n",
    "                      ### GRID\n",
    "                       gridcolor='gainsboro',\n",
    "                       gridwidth=1,\n",
    "                       layer='above traces',\n",
    "                       tickangle=0,\n",
    "                       row=i, col=1)\n",
    "    fig.update_yaxes(showline=True,      # add line at x=0\n",
    "                         showticklabels=True,\n",
    "                         linecolor='black',  # line color\n",
    "                         linewidth=1,        # line size\n",
    "                     ticks='inside',     # ticks outside axis\n",
    "                     tickfont=font_dict, # tick label font\n",
    "                     mirror='allticks',  # add ticks to top/right axes\n",
    "                     tickwidth=1,      # tick width\n",
    "                     tickcolor='black',  # tick color\n",
    "                     gridcolor='gainsboro',\n",
    "                     gridwidth=1,\n",
    "                     layer='above traces',\n",
    "                     row=i, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Scaling Factor\", \n",
    "                     exponentformat= 'power',row=2, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Density\", \n",
    "                     type=\"log\", \n",
    "                     exponentformat= 'power',row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Scaled Density\", \n",
    "                      type=\"log\", \n",
    "                     exponentformat= 'power',row=4, col=1)\n",
    "\n",
    "# for month in yearmonth_list:\n",
    "\n",
    "#     time_avg,Rho_x = orbit_avg_generic(models_dens[month+'Rho_x']['date'],\n",
    "#                                             models_dens[month+'Rho_x']['Rho_x'],\n",
    "#                                             models_dens[month+'Rho_x']['lat'])\n",
    "\n",
    "#     time_avg,Rho_std = orbit_avg_generic(models_dens[month+'Rho_x']['date'],\n",
    "#                                             models_dens[month+'Rho_x']['Rho_std'],\n",
    "#                                             models_dens[month+'Rho_x']['lat'])\n",
    "\n",
    "\n",
    "#     fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                y=Rho_x,\n",
    "#                                ### name= model_m1,\n",
    "#                                mode='markers+lines',\n",
    "#                                opacity=1,\n",
    "#                                marker=dict(color='black',size=5),\n",
    "#                                    line = dict( dash ='solid', color = 'black', width=4),\n",
    "#                                showlegend=False), row=4, col=1)\n",
    "    ## ERRROR BARS\n",
    "#     fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                y=np.array(Rho_x)\\\n",
    "#                                    +np.array(Rho_std),\n",
    "#                                ### name= model_m1,\n",
    "#                                mode='lines',\n",
    "#                                opacity=.8,\n",
    "#                                    line = dict( dash ='dash', color = 'grey', width=3),\n",
    "#                                showlegend=False), row=4, col=1)\n",
    "#     fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                y=np.array(Rho_x)\\\n",
    "#                                   -np.array(Rho_std),\n",
    "#                                ### name= model_m1,\n",
    "#                                mode='lines',\n",
    "#                                opacity=.8,\n",
    "#                                    line = dict( dash ='dash', color = 'grey', width=3),\n",
    "#                                showlegend=False), row=4, col=1)\n",
    "\n",
    "    \n",
    "fig.update_xaxes(range=[pd.to_datetime('2018-10-14 00:00:00'), pd.to_datetime('2019-12-31 00:00:00')])\n",
    "    \n",
    "a='input'\n",
    "s=settings_ice\n",
    "fig.update_layout(title=f\" ICESat-2 {s['cd_model'][a]}, {s['hours_between_cd_adj'][a]}-hr Scale\", \n",
    "                  autosize=False,    width=850,    height=900,\n",
    "                  legend= {'itemsizing': 'trace'},\n",
    "                  font=font_dict,\n",
    "                  plot_bgcolor='white', \n",
    "                 )\n",
    "fig.update_annotations(font_size=16)  # Increase size of subplot title\n",
    "\n",
    "\n",
    "\n",
    "fig.add_vline(x=datetime.strptime(\"2019-06-20 00:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,                \n",
    "#                             annotation_text=\"Sailboat (-B)\", \n",
    "                            annotation_position=\"top right\",\n",
    "                            annotation_font_size=12,\n",
    "                            annotation_font_color=\"#FC1CBF\",\n",
    "                            line_width=2, line_dash=\"dash\",\n",
    "#                           row=3, col=1)\n",
    "                         )\n",
    "\n",
    "\n",
    "fig.add_vline(x=datetime.strptime(\"2019-09-06 20:00\", \"%Y-%m-%d %H:%M\").timestamp() * 1000,                \n",
    "#                             annotation_text=\"Sailboat (-B)\", \n",
    "                            annotation_position=\"top right\",\n",
    "                            annotation_font_size=12,\n",
    "                            annotation_font_color=\"#FC1CBF\",\n",
    "                            line_width=2, line_dash=\"dash\",\n",
    "#                           row=3, col=1)\n",
    "                         )\n",
    "\n",
    "# fig.show(config=config)\n",
    "fig.show(config= dict({\n",
    "                'displayModeBar': False,\n",
    "                'responsive': True,\n",
    "                'staticPlot': False,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                }),\n",
    "#          renderer='jpg',\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dcda76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.985516Z",
     "start_time": "2025-01-28T19:14:01.985502Z"
    }
   },
   "outputs": [],
   "source": [
    "# obj['mardtm2020_o']['OrbitResids']['2019.078'].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8044880",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.986876Z",
     "start_time": "2025-01-28T19:14:01.986861Z"
    }
   },
   "outputs": [],
   "source": [
    "# obj['mardtm2020_o']['OrbitResids']['2019.078']['resids'].keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b68799d",
   "metadata": {},
   "source": [
    "### NTW residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338adef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.988858Z",
     "start_time": "2025-01-28T19:14:01.988841Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# fig  = make_subplots(\n",
    "#     rows=3, cols=1,\n",
    "#     vertical_spacing = 0.05,\n",
    "#     shared_xaxes=True)\n",
    "\n",
    "# for ii,arc in enumerate(obj['mardtm2020_o']['global_params']['arc_input']):\n",
    "#     epochstart = obj['mardtm2020_o']['global_params']['prms']['epoch_start'][ii]\n",
    "#     hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "#     frachours =(hrs/24)\n",
    "#     #\n",
    "#     if len(arc) == 9:\n",
    "#         maneuv_indicator = arc[8]\n",
    "#     else:\n",
    "#         maneuv_indicator = ''\n",
    "#     arc_type = obj['mardtm2020_o']['global_params']['prms']['arc_type']\n",
    "#     if arc_type == \"Nominal30hr_and_AB\":\n",
    "#         arc_name =arc[:8]+ maneuv_indicator\n",
    "#     else:\n",
    "#         arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "#     fig.add_trace(go.Scattergl(x=obj['mardtm2020_o']['OrbitResids'][arc_name]['resids']['Date'],\n",
    "#                                y=obj['mardtm2020_o']['OrbitResids'][arc_name]['resids']['N'],\n",
    "#                                mode='markers+lines',\n",
    "#                                opacity=1,\n",
    "#                                marker=dict(color='blue', size=3),\n",
    "#                                    showlegend=False),\n",
    "#                                    secondary_y=False,row=1, col=1)\n",
    "# #     fig.add_trace(go.Scattergl(x=obj['mardtm2020_o']['OrbitResids'][arc_name]['data_orbfil']['Date'],\n",
    "# #                                y=obj['mardtm2020_o']['OrbitResids'][arc_name]['data_orbfil']['N'],\n",
    "# #                            mode='markers',\n",
    "# #                            opacity=1,\n",
    "# #                                marker=dict(color='red', size=3),\n",
    "# #                                showlegend=False),\n",
    "# #                                secondary_y=False,row=1, col=1)\n",
    "    \n",
    "#     fig.add_trace(go.Scattergl(x=obj['mardtm2020_o']['OrbitResids'][arc_name]['resids']['Date'],\n",
    "#                                y=obj['mardtm2020_o']['OrbitResids'][arc_name]['resids']['T'],\n",
    "#                                mode='markers+lines',\n",
    "#                                opacity=1,\n",
    "#                                marker=dict(color='blue', size=3),\n",
    "#                                    showlegend=False),\n",
    "#                                    secondary_y=False,row=2, col=1)\n",
    "# #     fig.add_trace(go.Scattergl(x=obj['mardtm2020_o']['OrbitResids'][arc_name]['data_orbfil']['Date'],\n",
    "# #                                y=obj['mardtm2020_o']['OrbitResids'][arc_name]['data_orbfil']['T'],\n",
    "# #                            mode='markers',\n",
    "# #                            opacity=1,\n",
    "# #                                marker=dict(color='red', size=3),\n",
    "# #                                showlegend=False),\n",
    "# #                                secondary_y=False,row=2, col=1)\n",
    "\n",
    "#     fig.add_trace(go.Scattergl(x=obj['mardtm2020_o']['OrbitResids'][arc_name]['resids']['Date'],\n",
    "#                                y=obj['mardtm2020_o']['OrbitResids'][arc_name]['resids']['W'],\n",
    "#                                mode='markers+lines',\n",
    "#                                opacity=1,\n",
    "#                                marker=dict(color='blue', size=3),\n",
    "#                                    showlegend=False),\n",
    "#                                    secondary_y=False,row=3, col=1)\n",
    "# #     fig.add_trace(go.Scattergl(x=obj['mardtm2020_o']['OrbitResids'][arc_name]['data_orbfil']['Date'],\n",
    "# #                                y=obj['mardtm2020_o']['OrbitResids'][arc_name]['data_orbfil']['W'],\n",
    "# #                            mode='markers',\n",
    "# #                            opacity=1,\n",
    "# #                                marker=dict(color='red', size=3),\n",
    "# #                                showlegend=False),\n",
    "# #                                secondary_y=False,row=3, col=1)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# fig.show(config= dict({\n",
    "#                 'displayModeBar': False,\n",
    "#                 'responsive': False,\n",
    "#                 'staticPlot': True,\n",
    "#                 'displaylogo': False,\n",
    "#                 'showTips': False,\n",
    "#                 }),\n",
    "#         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da49406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62fb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a1f90d8",
   "metadata": {},
   "source": [
    "### SF and CD*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8893c1ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.990225Z",
     "start_time": "2025-01-28T19:14:01.990210Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "# def PLOT_retrievedRHO(fig, obj_m1, den_dict, model_dict, model_name):\n",
    "        \n",
    "#     obj_m1=obj_m1[model_name]\n",
    "# #     print(model_name)\n",
    "#     model_m1 = model_name[3:]#obj_m1['global_params']['prms']['den_model']\n",
    "\n",
    "#     fig.add_trace(go.Scattergl(x=pd.to_datetime(model_dict['ScalingFactor_times'])-pd.to_timedelta(scale_cadence/2, 'h'),\n",
    "#                                y=model_dict['ScalingFactors'],\n",
    "#                                name= model,\n",
    "#                                mode='markers',\n",
    "#                                opacity=1,\n",
    "# #                                    marker=dict(color=coldict[model_m1], \n",
    "# #                                                size=5,\n",
    "# #                                                symbol='line-ew',\n",
    "# #                                                line = dict(color = coldict[model_m1], width=3)), #symbol='diamond-wide'),\n",
    "#                                    marker=dict(color=coldict[model_m1], size=5),\n",
    "#                                line = dict(shape = 'hvh',dash ='dot', color = coldict[model_m1], width=1),\n",
    "#                                showlegend=False),\n",
    "#                                secondary_y=False,row=1, col=1)\n",
    "\n",
    "#     for ii,arc in enumerate(obj_m1['global_params']['arc_input']):\n",
    "#         epochstart = obj_m1['global_params']['prms']['epoch_start'][ii]\n",
    "#         hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "#         frachours =(hrs/24)\n",
    "#         #\n",
    "#         if len(arc) == 9:\n",
    "#             maneuv_indicator = arc[8]\n",
    "#         else:\n",
    "#             maneuv_indicator = ''\n",
    "#         arc_type = obj_m1['global_params']['prms']['arc_type']\n",
    "#         if arc_type == \"Nominal30hr_and_AB\":\n",
    "#             arc_name =arc[:8]+ maneuv_indicator\n",
    "#         else:\n",
    "#             arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "        \n",
    "#         drag_data        = obj_m1['DragFile'][arc_name]\n",
    "#         drag_data[\"Lat\"] = obj_m1['Density' ][arc_name]['Lat']\n",
    "#         den_df           = obj_m1['Density' ][arc_name]\n",
    "        \n",
    "# #         print(arc[:8])\n",
    "#         ### Cut off the extra time for the regular days\n",
    "#         start_arc = pd.to_datetime(arc[:8], format='%Y.%j')\n",
    "#         end_arc   = pd.to_datetime(arc[:8], format = '%Y.%j')+pd.to_timedelta(24, 'h')-pd.to_timedelta(1, 'm')\n",
    "\n",
    "# #         print(f\" {arc_name:10}|   , {start_arc},  {end_arc}\")\n",
    "        \n",
    "#         ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "#         drag_data = drag_data.query( \\\n",
    "#                 f\"{start_arc.year}\"         \\\n",
    "#                +f\"{start_arc.month:02d}\"    \\\n",
    "#                +f\"{start_arc.day:02d}\"      \\\n",
    "#                +f\"{start_arc.hour:02d}\"     \\\n",
    "#                +f\"{start_arc.minute:02d}\"   \\\n",
    "#                +f\"{start_arc.second:02d}\"   \\\n",
    "#                +f\" <= Date < \"                     \\\n",
    "#                +f\"{end_arc.year}\"       \\\n",
    "#                +f\"{end_arc.month:02d}\"  \\\n",
    "#                +f\"{end_arc.day:02d}\"    \\\n",
    "#                +f\"{end_arc.hour:02d}\"   \\\n",
    "#                +f\"{end_arc.minute:02d}\" \\\n",
    "#                +f\"{end_arc.second:02d}\" \\\n",
    "#             )\n",
    "\n",
    "#         indplot = 4\n",
    "#         fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                y=drag_data['CD'][::indplot]*drag_data['TOTAREA'][::indplot],\n",
    "#                              mode='markers',\n",
    "#                              opacity=0.3,\n",
    "#                              marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                              showlegend=False,),\n",
    "#                              secondary_y=False,\n",
    "#                              row=2, col=1,\n",
    "#                          )\n",
    "    \n",
    "#         (time_avg, avg_area) = orbit_avg_generic(drag_data['Date'],drag_data['TOTAREA'],drag_data['Lat'])    \n",
    "#         (time_avg, avg_cd ) = orbit_avg_generic(drag_data['Date'],drag_data['CD'],drag_data['Lat'])    \n",
    "\n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg_cd*avg_area,\n",
    "# #                                  y=avg_cd,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=2, col=1)\n",
    "    \n",
    "    \n",
    "             \n",
    "#     return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig  = make_subplots(\n",
    "#     rows=2, cols=1,\n",
    "#     vertical_spacing = 0.05,\n",
    "#     shared_xaxes=True)\n",
    "\n",
    "\n",
    "\n",
    "# # run_dict = { }\n",
    "# # rms_total_return = {}\n",
    "\n",
    "# for model in run_dict.keys():\n",
    "#     print(model)\n",
    "# #     for imonth,month in enumerate(month_list):\n",
    "\n",
    "# #     fig = PLOT_retrievedRHO(fig, obj[model],   models_dens[model], run_dict[model], model)\n",
    "#     fig = PLOT_retrievedRHO(fig, obj,   models_dens[model], run_dict[model], model)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# # time_avg,Rho_x = orbit_avg_generic(models_dens['novRho_x']['date'],\n",
    "# #                                         models_dens['novRho_x']['Rho_x'],\n",
    "# #                                         models_dens['novRho_x']['lat'])\n",
    "\n",
    "# # time_avg,Rho_std = orbit_avg_generic(models_dens['novRho_x']['date'],\n",
    "# #                                         models_dens['novRho_x']['Rho_std'],\n",
    "# #                                         models_dens['novRho_x']['lat'])\n",
    "\n",
    "\n",
    "# # fig.add_trace(go.Scattergl(x=time_avg,\n",
    "# #                            y=Rho_x,\n",
    "# #                            ### name= model_m1,\n",
    "# #                            mode='markers+lines',\n",
    "# #                            opacity=1,\n",
    "# #                            marker=dict(color='black',size=5),\n",
    "# #                                line = dict( dash ='solid', color = 'black', width=4),\n",
    "# #                            showlegend=False), row=2, col=1)\n",
    "# # ## ERRROR BARS\n",
    "# # fig.add_trace(go.Scattergl(x=time_avg,\n",
    "# #                            y=np.array(Rho_x)\\\n",
    "# #                                +np.array(Rho_std),\n",
    "# #                            ### name= model_m1,\n",
    "# #                            mode='lines',\n",
    "# #                            opacity=.8,\n",
    "# #                                line = dict( dash ='dash', color = 'grey', width=3),\n",
    "# #                            showlegend=False), row=2, col=1)\n",
    "# # fig.add_trace(go.Scattergl(x=time_avg,\n",
    "# #                            y=np.array(Rho_x)\\\n",
    "# #                               -np.array(Rho_std),\n",
    "# #                            ### name= model_m1,\n",
    "# #                            mode='lines',\n",
    "# #                            opacity=.8,\n",
    "# #                                line = dict( dash ='dash', color = 'grey', width=3),\n",
    "# #                            showlegend=False), row=2, col=1)\n",
    "\n",
    "    \n",
    "    \n",
    "# #######################################################\n",
    "# font_dict=dict(family='Arial',size=11,color='black')\n",
    "# ## automate the specification of the axes for subplots\n",
    "# rownum, colnum = fig._get_subplot_rows_columns()\n",
    "# for i in rownum:\n",
    "#     if len(rownum)==1:\n",
    "#         L_ticklabel = True\n",
    "#     else:\n",
    "#         if i < len(rownum):\n",
    "#             L_ticklabel = True\n",
    "#         else:\n",
    "#             L_ticklabel = True\n",
    "#     fig.update_xaxes(### LINE at axis border\n",
    "#                       showline=True,\n",
    "#                       showticklabels=L_ticklabel,\n",
    "# #                       tickformat= '%m/%d',\n",
    "#                       linecolor='black',\n",
    "#                       linewidth=1,\n",
    "#                      ### Major ticks\n",
    "#                       ticks='inside',\n",
    "#                       tickfont=font_dict,\n",
    "#                       mirror=True,\n",
    "# #                       tickwidth=2,\n",
    "# #                       ticklen=9,\n",
    "#                       tickcolor='grey',\n",
    "# #                       tick0=\"2018-11-9\" ,\n",
    "# #                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "#                       #### Minor Ticks\n",
    "#                        minor=dict(\n",
    "#                          dtick=86400000.0, # milliseconds in a day\n",
    "#                          tickwidth=1,\n",
    "#                          ticklen=4,\n",
    "#                          tickcolor='grey',\n",
    "#                          ticks='inside'),\n",
    "#                       ### GRID\n",
    "#                        gridcolor='gainsboro',\n",
    "#                        gridwidth=1,\n",
    "#                        layer='above traces',\n",
    "#                        tickangle=0,\n",
    "#                        row=i, col=1)\n",
    "#     fig.update_yaxes(showline=True,      # add line at x=0\n",
    "#                          showticklabels=True,\n",
    "#                          linecolor='black',  # line color\n",
    "#                          linewidth=1,        # line size\n",
    "#                      ticks='inside',     # ticks outside axis\n",
    "#                      tickfont=font_dict, # tick label font\n",
    "#                      mirror='allticks',  # add ticks to top/right axes\n",
    "#                      tickwidth=1,      # tick width\n",
    "#                      tickcolor='black',  # tick color\n",
    "#                      gridcolor='gainsboro',\n",
    "#                      gridwidth=1,\n",
    "#                      layer='above traces',\n",
    "#                      row=i, col=1)\n",
    "\n",
    "#     fig.update_yaxes(title_text=\"Scaling Factor\", \n",
    "#                      exponentformat= 'power',row=1, col=1)\n",
    "\n",
    "# #     yaxis_range = [-13.7 -.55 ,  -12.6+.25]# ] #full_fig.layout.yaxis2.range\n",
    "\n",
    "# #     fig.update_yaxes(title_text=\"Scaled Density\", \n",
    "# #                      type=\"log\", \n",
    "# # #                       range=yaxis_range,\n",
    "# #                      exponentformat= 'power',row=2, col=1)\n",
    "#     fig.update_yaxes(title_text=\"CD*A\", \n",
    "# #                       type=\"log\", \n",
    "# #                       range=yaxis_range,\n",
    "#                      exponentformat= 'power',row=2, col=1)\n",
    "    \n",
    "    \n",
    "# fig.update_layout(margin=dict(l=20, r=20, t=20, b=20),)\n",
    "\n",
    "# # a='input'\n",
    "# # s=settings_icesat2\n",
    "\n",
    "# fig.update_layout(#title=f\"{s['cd_model'][a]}, {s['hours_between_cd_adj'][a]}-hr Scale from CD={s['cd_value'][a]}\",\n",
    "# #                     title=f\"BWDRAG, 3-hr Scale from CD=2.5 \",\n",
    "#                   autosize=False,    width=900,    height=550,\n",
    "#                   legend= {'itemsizing': 'trace'},\n",
    "#                   font=font_dict,\n",
    "#                   plot_bgcolor='white', \n",
    "#                  )\n",
    "# fig.update_annotations(font_size=16)  # Increase size of subplot title\n",
    "# fig.show(config= dict({\n",
    "#                 'displayModeBar': False,\n",
    "#                 'responsive': True,\n",
    "#                 'staticPlot': False,\n",
    "#                 'displaylogo': False,\n",
    "#                 'showTips': False,\n",
    "#                 }),\n",
    "# #          renderer='jpg',\n",
    "# )\n",
    "\n",
    "\n",
    "# # pio.write_image(fig, 'ScalingFactors_ScaledRho.jpg', scale=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1b8f1",
   "metadata": {},
   "source": [
    "### ful drag state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2877f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:14:01.991590Z",
     "start_time": "2025-01-28T19:14:01.991575Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "# def PLOT__SATDRAG_STATE(fig, obj_m1, den_dict):\n",
    "    \n",
    "#     SHOW_alldata = True\n",
    "    \n",
    "#     model_m1 = obj_m1['global_params']['prms']['den_model']\n",
    "#     if model!='hasdm_oc':\n",
    "#         opac_val = 1\n",
    "#     else:\n",
    "#         opac_val = 1\n",
    "\n",
    "#     for ii,arc in enumerate(obj_m1['global_params']['arc_input']):\n",
    "#         epochstart = obj_m1['global_params']['prms']['epoch_start'][ii]\n",
    "#         hrs = pd.to_datetime(epochstart, format='%Y-%m-%d %H:%M:%S').hour\n",
    "#         frachours =(hrs/24)\n",
    "#         #\n",
    "#         if len(arc) == 9:\n",
    "#             maneuv_indicator = arc[8]\n",
    "#         else:\n",
    "#             maneuv_indicator = ''\n",
    "#         arc_type = obj_m1['global_params']['prms']['arc_type']\n",
    "#         if arc_type == \"Nominal30hr_and_AB\":\n",
    "#             arc_name =arc[:8]+ maneuv_indicator\n",
    "#         else:\n",
    "#             arc_name =arc[:8]+('%.3f'%frachours).lstrip('0')+ maneuv_indicator\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#         drag_data        = obj_m1['DragFile'][arc_name]\n",
    "#         drag_data[\"Lat\"] = obj_m1['Density' ][arc_name]['Lat']\n",
    "#         den_df           = obj_m1['Density' ][arc_name]\n",
    "        \n",
    "# #         print(arc[:8])\n",
    "#         ### Cut off the extra time for the regular days\n",
    "#         start_arc = pd.to_datetime(arc[:8], format='%Y.%j')\n",
    "#         end_arc   = pd.to_datetime(arc[:8], format = '%Y.%j')+pd.to_timedelta(24, 'h')-pd.to_timedelta(1, 'm')\n",
    "\n",
    "# #         print(f\" {arc_name:10}|   , {start_arc},  {end_arc}\")\n",
    "        \n",
    "#         ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "#         drag_data = drag_data.query( \\\n",
    "#                 f\"{start_arc.year}\"         \\\n",
    "#                +f\"{start_arc.month:02d}\"    \\\n",
    "#                +f\"{start_arc.day:02d}\"      \\\n",
    "#                +f\"{start_arc.hour:02d}\"     \\\n",
    "#                +f\"{start_arc.minute:02d}\"   \\\n",
    "#                +f\"{start_arc.second:02d}\"   \\\n",
    "#                +f\" <= Date < \"                     \\\n",
    "#                +f\"{end_arc.year}\"       \\\n",
    "#                +f\"{end_arc.month:02d}\"  \\\n",
    "#                +f\"{end_arc.day:02d}\"    \\\n",
    "#                +f\"{end_arc.hour:02d}\"   \\\n",
    "#                +f\"{end_arc.minute:02d}\" \\\n",
    "#                +f\"{end_arc.second:02d}\" \\\n",
    "#             )\n",
    "#         ### SELECT ONLY THE MIDDLE 24-HOURS\n",
    "#         den_df = den_df.query( \\\n",
    "#                 f\"{start_arc.year}\"         \\\n",
    "#                +f\"{start_arc.month:02d}\"    \\\n",
    "#                +f\"{start_arc.day:02d}\"      \\\n",
    "#                +f\"{start_arc.hour:02d}\"     \\\n",
    "#                +f\"{start_arc.minute:02d}\"   \\\n",
    "#                +f\"{start_arc.second:02d}\"   \\\n",
    "#                +f\" <= Date < \"                     \\\n",
    "#                +f\"{end_arc.year}\"       \\\n",
    "#                +f\"{end_arc.month:02d}\"  \\\n",
    "#                +f\"{end_arc.day:02d}\"    \\\n",
    "#                +f\"{end_arc.hour:02d}\"   \\\n",
    "#                +f\"{end_arc.minute:02d}\" \\\n",
    "#                +f\"{end_arc.second:02d}\" \\\n",
    "#             )\n",
    "\n",
    "\n",
    "#         indplot=3\n",
    "\n",
    "# #         date_rms.append(pd.to_datetime(datetime.datetime(int(arc.split('.')[0]), 1, 1) + datetime.timedelta(int(arc.split('.')[1]))- datetime.timedelta(hours=12) ))\n",
    "# #         rms_totals.append(obj_m1['Statistics'][arc]['T_RMS'].values[0])\n",
    "\n",
    "# #         iters = obj_m1['run_parameters'+arc_name]['total_iterations']\n",
    "# #         for itime in obj_m1['AdjustedParams'][arc_string][iters][satid]['0CD']:\n",
    "# #             date_scalefactor.append(itime)\n",
    "# #             ScalingFactor.append(obj_m1['AdjustedParams'][arc_string][iters][satid]['0CD'][itime]['CURRENT_VALUE'])\n",
    "\n",
    "\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                        y=drag_data['CD'][::indplot],\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=0.5,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                                      showlegend=False,),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=2, col=1,\n",
    "#                                  )\n",
    "#         (time_avg, avg_cd ) = orbit_avg_generic(drag_data['Date'],drag_data['CD'],drag_data['Lat'])    \n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg_cd,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=2, col=1)\n",
    "\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                        y=drag_data['TOTAREA'][::indplot],\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=0.5,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                                      showlegend=False,),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=3, col=1,\n",
    "#                                  )\n",
    "#         (time_avg, avg_area) = orbit_avg_generic(drag_data['Date'],drag_data['TOTAREA'],drag_data['Lat'])    \n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg_area,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=3, col=1)\n",
    "\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                        y=drag_data['CD'][::indplot]*drag_data['TOTAREA'][::indplot],\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=0.5,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                                      showlegend=False,),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=4, col=1,\n",
    "#                                  )\n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg_cd*avg_area,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=4, col=1)\n",
    "\n",
    "        \n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                        y=drag_data['VELREL'][::indplot],\n",
    "# #                                          name= plot_name+arc,\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=0.5,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                                      line = dict(shape='hvh', dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                                      showlegend=False, ),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=5, col=1,\n",
    "#                                  )\n",
    "#         (time_avg, avg ) = orbit_avg_generic(drag_data['Date'],drag_data['VELREL'],drag_data['Lat'])    \n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=5, col=1)\n",
    "\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=drag_data['Date'][::indplot],\n",
    "#                                    y=drag_data['SpeedRatio'][::indplot],\n",
    "# #                                          name= plot_name+arc,\n",
    "#                                      mode='markers',\n",
    "#                                      opacity=0.5,\n",
    "#                                      marker=dict(color= coldict[model_m1],size=2,),\n",
    "#                                      line = dict(shape='hvh', dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                                      showlegend=False, ),\n",
    "#                                      secondary_y=False,\n",
    "#                                      row=6, col=1,\n",
    "#                                  )\n",
    "#         (time_avg, avg ) = orbit_avg_generic(drag_data['Date'],drag_data['SpeedRatio'],drag_data['Lat'])    \n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=avg,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=6, col=1)\n",
    "#         if SHOW_alldata:\n",
    "#             fig.add_trace(go.Scattergl(x=den_df['Date'][::indplot],\n",
    "#                                  y=den_df['rho (kg/m**3)'][::indplot],\n",
    "#                        ### name= model_m1,\n",
    "#                        mode='markers',\n",
    "#                        opacity=0.5,\n",
    "#                            marker=dict(color=coldict[model_m1],size=2),\n",
    "#                            line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "#                        showlegend=False), row=1, col=1)\n",
    "        \n",
    "#         (time_avg, d_avg ) = orbit_avg_generic(den_df['Date'],den_df['rho (kg/m**3)'],\n",
    "#                                                den_df['Lat'])    \n",
    "#         fig.add_trace(go.Scattergl(x=time_avg,\n",
    "#                                  y=d_avg,\n",
    "#                            mode='lines',\n",
    "#                            opacity=1,\n",
    "#                                marker=dict(color=coldict[model_m1],size=1),\n",
    "#                                line = dict(dash ='solid', color = coldict[model_m1], width=3),\n",
    "#                            showlegend=False), row=1, col=1)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# #     (time_avg, d_avg ) = orbit_avg_generic(den_dict['dates'],\n",
    "# #                                    den_dict['den'],\n",
    "# #                                    den_dict['lat'])\n",
    "# #     ### -----------------------------------------------------------------------------------------------------\n",
    "# #     ###     Orbit Averaged Density\n",
    "# #     fig.add_trace(go.Scattergl(x=time_avg,\n",
    "# #                                y=d_avg,\n",
    "# #                                ### name= model_m1,\n",
    "# #                                mode='markers',\n",
    "# #                                opacity=opac_val,\n",
    "# #                                    marker=dict(color= coldict[model_m1],size=2),\n",
    "# #                                    line = dict(dash ='solid', color = coldict[model_m1], width=2),\n",
    "# #                                showlegend=False), row=1, col=1)\n",
    "    \n",
    "    \n",
    "# #                 time_avg,CD_avg, area_avg_rolling, CD_std = orb_avg_param(obj_m1.__dict__['DragFile'], arc_string, 'TOTAREA')\n",
    "# #                 fig.add_trace(go.Scattergl(x=time_avg,\n",
    "# #                                            y=area_avg_rolling,\n",
    "# #     #                                          name= plot_name+arc,\n",
    "# #                                              mode='markers+lines',\n",
    "# #                                              opacity=1,\n",
    "# #                                              marker=dict(color=col,size=2,),\n",
    "# #                                              line = dict(shape='hvh', dash ='solid', color = col, width=3),\n",
    "# #                                              showlegend=False, ),\n",
    "# #                                              secondary_y=False,\n",
    "# #                                              row=3, col=1,\n",
    "# #                                          )\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "#     return(fig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig  = make_subplots(\n",
    "#     rows=6, cols=1,\n",
    "# #     subplot_titles=(['Density (kg/m^3)'   , \n",
    "# # #                      'CD*A'               ,\n",
    "# #                      'CD'                 ,   \n",
    "# #                      'Relative Velocity'  , \n",
    "# #                      'Speed Ratio',\n",
    "# #                     ]),\n",
    "#     vertical_spacing = 0.05,\n",
    "# #     horizontal_spacing = 0.05,\n",
    "#     shared_xaxes=True)\n",
    "\n",
    "\n",
    "\n",
    "# # run_dict = { }\n",
    "# # rms_total_return = {}\n",
    "\n",
    "# for model in run_dict.keys():\n",
    "# #     for imonth,month in enumerate(month_list):\n",
    "\n",
    "# #     for ialph,alpha in enumerate(alphas):   \n",
    "#          # fig,rms_total_return = PLOT__intrack_residuals_w_rms_w_cd(fig, Obj_Geodyn['msis2'] , 0,  arc_listlist)\n",
    "# #         run_dict[val+\"alpha_\"+alpha] = ialph\n",
    "\n",
    "#     fig = PLOT__SATDRAG_STATE(fig, obj[model],   models_dens[model])\n",
    "\n",
    "    \n",
    "# #######################################################\n",
    "# font_dict=dict(family='Arial',size=11,color='black')\n",
    "# ## automate the specification of the axes for subplots\n",
    "# rownum, colnum = fig._get_subplot_rows_columns()\n",
    "# for i in rownum:\n",
    "#     if len(rownum)==1:\n",
    "#         L_ticklabel = True\n",
    "#     else:\n",
    "#         if i < len(rownum):\n",
    "#             L_ticklabel = True\n",
    "#         else:\n",
    "#             L_ticklabel = True\n",
    "#     fig.update_xaxes(### LINE at axis border\n",
    "#                       showline=True,\n",
    "#                       showticklabels=L_ticklabel,\n",
    "# #                       tickformat= '%m/%d',\n",
    "#                       linecolor='black',\n",
    "#                       linewidth=1,\n",
    "#                      ### Major ticks\n",
    "#                       ticks='inside',\n",
    "#                       tickfont=font_dict,\n",
    "#                       mirror=True,\n",
    "# #                       tickwidth=2,\n",
    "# #                       ticklen=9,\n",
    "#                       tickcolor='grey',\n",
    "# #                       tick0=\"2018-11-9\" ,\n",
    "# #                       dtick=86400000.0*1,    # milliseconds in a day, every 7 days\n",
    "#                       #### Minor Ticks\n",
    "#                        minor=dict(\n",
    "#                          dtick=86400000.0, # milliseconds in a day\n",
    "#                          tickwidth=1,\n",
    "#                          ticklen=4,\n",
    "#                          tickcolor='grey',\n",
    "#                          ticks='inside'),\n",
    "#                       ### GRID\n",
    "#                        gridcolor='gainsboro',\n",
    "#                        gridwidth=1,\n",
    "#                        layer='above traces',\n",
    "#                        tickangle=0,\n",
    "#                        row=i, col=1)\n",
    "#     fig.update_yaxes(showline=True,      # add line at x=0\n",
    "#                          showticklabels=True,\n",
    "#                          linecolor='black',  # line color\n",
    "#                          linewidth=1,        # line size\n",
    "#                      ticks='inside',     # ticks outside axis\n",
    "#                      tickfont=font_dict, # tick label font\n",
    "#                      mirror='allticks',  # add ticks to top/right axes\n",
    "#                      tickwidth=1,      # tick width\n",
    "#                      tickcolor='black',  # tick color\n",
    "#                      gridcolor='gainsboro',\n",
    "#                      gridwidth=1,\n",
    "#                      layer='above traces',\n",
    "#                      row=i, col=1)\n",
    "\n",
    "    \n",
    "#     fig.update_yaxes(title_text=\"Density\", \n",
    "#                      type=\"log\", \n",
    "#                      exponentformat= 'power',row=1, col=1)\n",
    "#     fig.update_yaxes(title_text=\"CD\", \n",
    "#                      exponentformat= 'power',row=2, col=1)\n",
    "#     fig.update_yaxes(title_text=\"Total Area\", \n",
    "#                      exponentformat= 'power',row=3, col=1)\n",
    "#     fig.update_yaxes(title_text=\"CD*Area\", \n",
    "#                      exponentformat= 'power',row=4, col=1)\n",
    "\n",
    "#     fig.update_yaxes(title_text=\"Rel. Velocity [m/s] \", \n",
    "#                      exponentformat= 'power',row=5, col=1)\n",
    "#     fig.update_yaxes(title_text=\"Speed Ratio\", \n",
    "#                      exponentformat= 'power',row=6, col=1)\n",
    "\n",
    "#     ###\n",
    "#     ###  DATE on Final x-Axis only\n",
    "# #     fig.update_xaxes(title=\"Date\",\n",
    "# #                      row=4, col=1)\n",
    "# #     fig.update_xaxes(title=\"Date\",\n",
    "# #                      row=5, col=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fig.update_layout(\n",
    "# #                   title = '',\n",
    "#                   autosize=False,    width=1000,    height=1100,\n",
    "#                   legend= {'itemsizing': 'trace'},\n",
    "#                   font=font_dict,\n",
    "#                   plot_bgcolor='white', \n",
    "#                  )\n",
    "# fig.update_annotations(font_size=16)  # Increase size of subplot title\n",
    "\n",
    "\n",
    "\n",
    "# # fig.add_vrect(x0=\"2018-10-16 23:00:00\" ,\n",
    "# #               x1=\"2018-10-17 00:24:00\" ,\n",
    "# #                 fillcolor=\"red\",\n",
    "# #                 opacity=0.25,\n",
    "# #                 line_width=0)\n",
    "# # fig.add_vrect(x0=\"2018-10-28 16:00:00\" ,\n",
    "# #               x1=\"2018-10-28 17:36:00\" ,\n",
    "# #                 fillcolor=\"red\",\n",
    "# #                 opacity=0.25,\n",
    "# #                 line_width=0)\n",
    "# # fig.add_vrect(x0=\"2018-10-29 10:18:00\" ,\n",
    "# #               x1=\"2018-10-29 11:42:00\" ,\n",
    "# #                 fillcolor=\"red\",\n",
    "# #                 opacity=0.25,\n",
    "# #                 line_width=0)\n",
    "# # fig.add_vrect(x0=\"\" ,\n",
    "# #               x1=\"\" ,\n",
    "# #                 fillcolor=\"red\",\n",
    "# #                 opacity=0.25,\n",
    "# #                 line_width=0)\n",
    "# # fig.add_vrect(x0=\"\" ,\n",
    "# #               x1=\"\" ,\n",
    "# #                 fillcolor=\"red\",\n",
    "# #                 opacity=0.25,\n",
    "# #                 line_width=0)\n",
    "\n",
    "# fig.show(config=config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2205e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bf30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a33566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "604.889px",
    "left": "22px",
    "top": "443.806px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
