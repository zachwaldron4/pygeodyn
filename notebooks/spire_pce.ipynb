{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0821746f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:17.880561Z",
     "start_time": "2023-02-06T21:13:17.877712Z"
    }
   },
   "outputs": [],
   "source": [
    "#---+----1----+----2----+----3----+----4----+----5----+----6----+----7----+----8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5e9c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:18.254341Z",
     "start_time": "2023-02-06T21:13:17.882212Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pygeodyn.PYGEODYN import Pygeodyn\n",
    "from gc import collect as gc_collect\n",
    "\n",
    "# run_settings = Pygeodyn.print_input(options=False, info=False)\n",
    "\n",
    "\n",
    "settings_SPIRE= {# Basic input settings\n",
    "                 'satellite'      : {'input': 'spire83'},\n",
    "                 'den_model'      : {'input': 'jb2008'},\n",
    "                 'run_type'       : {'input': 'DataReduction_PCE'},\n",
    "                 'run_specifier'  : {'input': '_test_infrastruc'},\n",
    "                 'cd_model'       : {'input': 'BWDRAG'},\n",
    "                 'file_string'    : {'input': 'CD_2p3'},\n",
    "               # Force Model settings\n",
    "                  'cd_type'               : {'input':\"Fixed_CD\"},\n",
    "                  'cd_value'              : {'input':2.300000},\n",
    "                  'scaling_factor'        : {'input':False},\n",
    "                  'cd_adjustment_boolean' : {'input':False },\n",
    "                  'hours_between_cd_adj'  : {'input':6 },\n",
    "               # Run\n",
    "                  'step'           : {'input': 10.},\n",
    "                  #\n",
    "#                   'arc'            : {'input':['2018.313',]},\n",
    "                  'arc'            : {'input':['2018.314',]},\n",
    "#                   'epoch_start'    : {'input':[\"2018-11-09 00:00:00\"]},\n",
    "#                   'epoch_start'    : {'input':[\"2018-11-09 00:05:35\"]},\n",
    "#                   'epoch_stop'     : {'input':[\"2018-11-10 00:00:00\"]},\n",
    "                  'epoch_start'    : {'input':[\"2018-11-10 00:00:00\"]},\n",
    "                  'epoch_stop'     : {'input':[\"2018-11-11 00:00:00\"]},\n",
    "#                   'initial_conditions':{'input':[-1367775.262313638,\n",
    "#                                                 -5125780.359399426,\n",
    "#                                                 -4361445.789580496,\n",
    "#                                                 6645.941518838111,\n",
    "#                                                 1215.197770462808,\n",
    "#                                                 -3507.908078628219]} ,\n",
    "\n",
    "                   \n",
    "                  'global_options': {'input':'pso_2018'},\n",
    "               # Request read on raw outputs\n",
    "                  'request_data'   : {'input': ['Trajectory_orbfil',\n",
    "                                                'Density',\n",
    "                                                'DragFile',\n",
    "                                                #'Residuals_summary',\n",
    "                                               ]},\n",
    "              #end dict\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287c60ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.444612Z",
     "start_time": "2023-02-06T21:13:18.257187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/\n",
      "/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/\n",
      "/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/\n",
      "/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-08/\n",
      "/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/\n",
      "/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-10/\n",
      "files_with_sat ['/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/2018-11-05T00-41-19_2018-11-05T01-36-55_083/leoOrb_2018-11-05T00-41-19Z.1058054.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/2018-11-05T02-52-52_2018-11-05T03-46-55_083/leoOrb_2018-11-05T02-52-52Z.1058087.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/2018-11-05T05-02-49_2018-11-05T05-56-55_083/leoOrb_2018-11-05T05-02-49Z.1058129.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/2018-11-05T07-11-26_2018-11-05T08-06-55_083/leoOrb_2018-11-05T07-11-26Z.1058132.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/2018-11-05T09-21-19_2018-11-05T10-16-56_083/leoOrb_2018-11-05T09-21-19Z.1058151.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/2018-11-05T13-41-48_2018-11-05T14-36-54_083/leoOrb_2018-11-05T13-41-48Z.1057206.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/2018-11-05T15-51-48_2018-11-05T16-46-56_083/leoOrb_2018-11-05T15-51-48Z.1056822.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/2018-11-05T18-01-25_2018-11-05T18-56-54_083/leoOrb_2018-11-05T18-01-25Z.1058247.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/2018-11-05T20-11-19_2018-11-05T21-07-53_083/leoOrb_2018-11-05T20-11-19Z.1057259.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-05/2018-11-05T22-21-18_2018-11-05T23-16-52_083/leoOrb_2018-11-05T22-21-18Z.1058273.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/2018-11-06T00-31-48_2018-11-06T01-26-53_083/leoOrb_2018-11-06T00-31-48Z.1058347.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/2018-11-06T02-41-49_2018-11-06T03-36-54_083/leoOrb_2018-11-06T02-41-49Z.1056843.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/2018-11-06T04-51-49_2018-11-06T05-46-54_083/leoOrb_2018-11-06T04-51-49Z.1056874.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/2018-11-06T09-11-19_2018-11-06T10-06-54_083/leoOrb_2018-11-06T09-11-19Z.1057613.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/2018-11-06T11-21-48_2018-11-06T12-16-53_083/leoOrb_2018-11-06T11-21-48Z.1057615.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/2018-11-06T13-31-54_2018-11-06T14-26-53_083/leoOrb_2018-11-06T13-31-54Z.1058373.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/2018-11-06T15-41-24_2018-11-06T16-36-53_083/leoOrb_2018-11-06T15-41-24Z.1057009.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/2018-11-06T17-51-18_2018-11-06T18-46-52_083/leoOrb_2018-11-06T17-51-18Z.1058361.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/2018-11-06T20-01-19_2018-11-06T20-56-54_083/leoOrb_2018-11-06T20-01-19Z.1058397.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-06/2018-11-06T22-11-48_2018-11-06T23-06-54_083/leoOrb_2018-11-06T22-11-48Z.1057045.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/2018-11-07T00-22-18_2018-11-07T01-16-53_083/leoOrb_2018-11-07T00-22-18Z.1057039.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/2018-11-07T02-31-24_2018-11-07T03-26-53_083/leoOrb_2018-11-07T02-31-24Z.1057079.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/2018-11-07T04-41-18_2018-11-07T05-36-52_083/leoOrb_2018-11-07T04-41-18Z.1057457.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/2018-11-07T06-51-18_2018-11-07T07-46-54_083/leoOrb_2018-11-07T06-51-18Z.1057796.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/2018-11-07T09-01-48_2018-11-07T09-57-53_083/leoOrb_2018-11-07T09-01-48Z.1058423.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/2018-11-07T11-11-49_2018-11-07T12-06-53_083/leoOrb_2018-11-07T11-11-49Z.1057477.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/2018-11-07T13-21-24_2018-11-07T14-16-53_083/leoOrb_2018-11-07T13-21-24Z.1057865.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/2018-11-07T15-31-19_2018-11-07T16-26-55_083/leoOrb_2018-11-07T15-31-19Z.1058663.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/2018-11-07T19-51-49_2018-11-07T20-46-53_083/leoOrb_2018-11-07T19-51-49Z.1057909.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-07/2018-11-07T22-01-26_2018-11-07T22-56-55_083/leoOrb_2018-11-07T22-01-26Z.1057208.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-08/2018-11-08T00-11-48_2018-11-08T01-06-53_083/leoOrb_2018-11-08T00-11-48Z.1057257.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-08/2018-11-08T02-21-49_2018-11-08T03-16-53_083/leoOrb_2018-11-08T02-21-49Z.1057986.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-08/2018-11-08T04-31-18_2018-11-08T05-26-52_083/leoOrb_2018-11-08T04-31-18Z.1058793.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-08/2018-11-08T08-51-24_2018-11-08T09-46-53_083/leoOrb_2018-11-08T08-51-24Z.1057207.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-08/2018-11-08T11-01-48_2018-11-08T11-56-53_083/leoOrb_2018-11-08T11-01-48Z.1057214.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-08/2018-11-08T13-11-23_2018-11-08T14-06-53_083/leoOrb_2018-11-08T13-11-23Z.1058912.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-08/2018-11-08T15-21-18_2018-11-08T16-16-53_083/leoOrb_2018-11-08T15-21-18Z.1057233.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-08/2018-11-08T19-42-19_2018-11-08T20-36-53_083/leoOrb_2018-11-08T19-42-19Z.1057418.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-08/2018-11-08T21-51-54_2018-11-08T22-46-53_083/leoOrb_2018-11-08T21-51-54Z.1057420.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/2018-11-09T00-01-49_2018-11-09T00-56-54_083/leoOrb_2018-11-09T00-01-49Z.1057454.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/2018-11-09T02-11-19_2018-11-09T03-06-54_083/leoOrb_2018-11-09T02-11-19Z.1057701.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/2018-11-09T08-41-25_2018-11-09T09-36-54_083/leoOrb_2018-11-09T08-41-25Z.1059142.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/2018-11-09T10-51-19_2018-11-09T11-46-53_083/leoOrb_2018-11-09T10-51-19Z.1057481.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/2018-11-09T13-01-19_2018-11-09T13-56-56_083/leoOrb_2018-11-09T13-01-19Z.1059161.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/2018-11-09T15-11-49_2018-11-09T16-06-52_083/leoOrb_2018-11-09T15-11-49Z.1057791.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/2018-11-09T17-21-54_2018-11-09T18-16-54_083/leoOrb_2018-11-09T17-21-54Z.0520395.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/2018-11-09T19-31-24_2018-11-09T20-26-53_083/leoOrb_2018-11-09T19-31-24Z.1057548.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/2018-11-09T21-41-48_2018-11-09T22-36-53_083/leoOrb_2018-11-09T21-41-48Z.1057561.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-09/2018-11-09T23-51-18_2018-11-10T00-46-55_083/leoOrb_2018-11-09T23-51-18Z.1059271.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-10/2018-11-10T02-01-48_2018-11-10T02-56-54_083/leoOrb_2018-11-10T02-01-48Z.1059423.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-10/2018-11-10T08-31-49_2018-11-10T09-26-54_083/leoOrb_2018-11-10T08-31-49Z.1057746.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-10/2018-11-10T12-51-49_2018-11-10T13-46-53_083/leoOrb_2018-11-10T12-51-49Z.1057776.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-10/2018-11-10T15-01-24_2018-11-10T15-56-54_083/leoOrb_2018-11-10T15-01-24Z.1057780.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-10/2018-11-10T17-11-55_2018-11-10T18-06-54_083/leoOrb_2018-11-10T17-11-55Z.1059192.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-10/2018-11-10T19-21-24_2018-11-10T20-17-23_083/leoOrb_2018-11-10T19-21-24Z.1057803.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-10/2018-11-10T21-31-18_2018-11-10T22-26-54_083/leoOrb_2018-11-10T21-31-18Z.1059578.083.sp3', '/data/SatDragModelValidation/data/inputs/sat_spire83/data_Spire/arcs/2018-11-10/2018-11-10T23-41-48_2018-11-11T00-36-54_083/leoOrb_2018-11-10T23-41-48Z.1058095.083.sp3']\n",
      "read_SpireLeoOrbPOD_sp3c(): Reading ephemeris data from   57 files.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1e6b93ff0221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# sat = Pygeodyn(settings_icesat, use_file=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_arcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/PYGEODYN.py\u001b[0m in \u001b[0;36mrun_arcs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Locate G2B data (In the Satellite __init__() for now. )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_g2b_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/prep_inputs.py\u001b[0m in \u001b[0;36mprep_g2b_check\u001b[0;34m(self, bool_overwrite, verbose)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_G2B\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbool_overwrite\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.tab} Making PCE g2b file: {self.file_G2B}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_write_g2b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"G2B file exists:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_G2B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/prep_inputs.py\u001b[0m in \u001b[0;36mmake_write_g2b\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_satinput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ephem_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m### Satellite specific function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msat_process_raw_ephemeris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/satellite_spire.py\u001b[0m in \u001b[0;36msat_process_raw_ephemeris\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m#### Load raw data from all found files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mleoOrb_ecef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_SpireLeoOrbPOD_sp3c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_with_sat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mfiles_with_sat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/satellite_spire.py\u001b[0m in \u001b[0;36mread_SpireLeoOrbPOD_sp3c\u001b[0;34m(filelist_sat)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;31m### convert date back to datetime from unixtime float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     leoOrb_dict['date_gps'] =  [pd_to_datetime(\n\u001b[0m\u001b[1;32m   1030\u001b[0m             \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%y%m%d%H%M%S.%f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m                 format ='%y%m%d%H%M%S.%f' )\n",
      "\u001b[0;32m/data/SatDragModelValidation/pygeodyn/pygeodyn/satellite_spire.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;31m### convert date back to datetime from unixtime float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m     leoOrb_dict['date_gps'] =  [pd_to_datetime(\n\u001b[0m\u001b[1;32m   1030\u001b[0m             \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%y%m%d%H%M%S.%f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m                 format ='%y%m%d%H%M%S.%f' )\n",
      "\u001b[0;32m/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/miniconda3/envs/pygeodyn/lib/python3.8/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;31m# format because this path makes process slower in this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# special case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0mformat_is_iso8601\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_is_iso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat_is_iso8601\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mrequire_iso8601\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sat = Pygeodyn(settings_SPIRE, use_file=False)\n",
    "# sat = Pygeodyn(settings_icesat, use_file=False)\n",
    "\n",
    "sat.run_arcs()\n",
    "obj = sat.getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2da6745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T18:27:27.494153Z",
     "start_time": "2023-02-01T18:27:27.472968Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe7132",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T18:39:49.717862Z",
     "start_time": "2023-02-01T18:39:47.534Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b43c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc56e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.449501Z",
     "start_time": "2023-02-06T21:13:17.827Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df8efc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T18:54:00.770597Z",
     "start_time": "2023-02-01T18:54:00.743679Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45311fff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.450669Z",
     "start_time": "2023-02-06T21:13:17.829Z"
    }
   },
   "outputs": [],
   "source": [
    "arc = settings_SPIRE['arc']['input'][0]\n",
    "\n",
    "X_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['X j2000']\n",
    "Y_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Y j2000']\n",
    "Z_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Z j2000']\n",
    "#\n",
    "Xdot_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['X_dot j2000']\n",
    "Ydot_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Y_dot j2000']\n",
    "Zdot_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Z_dot j2000']\n",
    "\n",
    "date_prop = obj.__dict__['Trajectory_orbfil'][arc]['data_record']['Date_UTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae63d77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.451455Z",
     "start_time": "2023-02-06T21:13:17.830Z"
    }
   },
   "outputs": [],
   "source": [
    "date_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ece7238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.452387Z",
     "start_time": "2023-02-06T21:13:17.831Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_start = settings_SPIRE['epoch_start']['input'][0]\n",
    "\n",
    "\n",
    "prms_arc={}\n",
    "prms_arc['epoch_start'] = epoch_start\n",
    "prms_arc['epoch_startDT'] = pd.to_datetime(prms_arc['epoch_start'],\\\n",
    "                                            format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "epoch_startDT = prms_arc['epoch_startDT']\n",
    "file_statevector_ICs = \"/data/SatDragModelValidation/data/inputs/\"\\\n",
    "                        +\"sat_spire83/setups/Spire83_initialconditions_Nov2018_v1.txt\"\n",
    "\n",
    "datetype = 'datetime_string'\n",
    "\n",
    "date_in_file_flag= False\n",
    "import linecache\n",
    "\n",
    "### Only need to use accuracy to within 1 second (ignore the microseconds in the file)\n",
    "\n",
    "if datetype == 'datetime_string':\n",
    "    date_str = str(epoch_startDT)\n",
    "elif datetype == 'YYMMDDHHMMSS':\n",
    "    date_str = datetime.strftime(epoch_startDT, '%y%m%d%H%M%S')\n",
    "\n",
    "\n",
    "with open(file_statevector_ICs, 'r') as f:\n",
    "    ### Find the dates that have the same hour    \n",
    "    if datetype == 'datetime_string':\n",
    "        date_roundhour_str = str(epoch_startDT)[:10]\n",
    "    elif datetype == 'YYMMDDHHMMSS':\n",
    "        date_roundhour_str = datetime.strftime(epoch_startDT, '%y%m%d%H%M%S')\n",
    "\n",
    "    ### Scan through IC file and append a list of dates within the same hour\n",
    "    line_no_list = []\n",
    "    line_list = []\n",
    "    with open(file_statevector_ICs, 'r') as f:\n",
    "        for line_no, line_text in enumerate(f):\n",
    "            if date_roundhour_str in line_text:\n",
    "                line_no_list.append(line_no)\n",
    "    for i in np.arange(line_no_list[0]-10, line_no_list[-1]+10):\n",
    "        line = linecache.getline(file_statevector_ICs,i)\n",
    "        line_list.append(line)\n",
    "    dates = []\n",
    "    for i ,val in enumerate(line_list):\n",
    "        if datetype == 'datetime_string':\n",
    "            dates.append(pd.to_datetime(line_list[i][:19],format='%Y-%m-%d %H:%M:%S'))\n",
    "        elif datetype == 'YYMMDDHHMMSS':\n",
    "            dates.append(pd.to_datetime(line_list[i][:19],format='%y%m%d%H%M%S.%f'))\n",
    "            \n",
    "            \n",
    "            \n",
    "xyzline = pd.read_csv(file_statevector_ICs, \n",
    "            skiprows = line_no_list[0], \n",
    "            nrows=line_no_list[-1]- line_no_list[0],           \n",
    "            sep = '\\s+',\n",
    "            dtype=object,\n",
    "            names = [\n",
    "                'DateYMD',\n",
    "                'DateHMS',\n",
    "                'X',\n",
    "                'Y',\n",
    "                'Z',\n",
    "                'X_dot',\n",
    "                'Y_dot',\n",
    "                'Z_dot',\n",
    "                    ],)\n",
    "\n",
    "xyzline['Date'] =  pd.to_datetime(xyzline['DateYMD']+xyzline['DateHMS'], format='%Y-%m-%d%H:%M:%S')\n",
    "del xyzline['DateYMD'], xyzline['DateHMS']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0d3fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.453147Z",
     "start_time": "2023-02-06T21:13:17.833Z"
    }
   },
   "outputs": [],
   "source": [
    "line_no_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac133de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.453944Z",
     "start_time": "2023-02-06T21:13:17.836Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "config = dict({\n",
    "                'displayModeBar': True,\n",
    "                'responsive': False,\n",
    "                'staticPlot': True,\n",
    "                'displaylogo': False,\n",
    "                'showTips': False,\n",
    "                })\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=3, cols=1)\n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(xyzline['Date']),\n",
    "            y=xyzline['X'].values.astype(float),\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=1, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(xyzline['Date']),\n",
    "            y=xyzline['Y'].values.astype(float),\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=2, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(xyzline['Date']),\n",
    "            y=xyzline['Z'].values.astype(float),\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color=\"blue\"),     \n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=3, col=1,)\n",
    "\n",
    "### ==============================================================\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(date_prop),\n",
    "            y=X_prop.values.astype(float),\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color='red'),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=1, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(date_prop),\n",
    "            y=Y_prop.values.astype(float),\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color='red'),\n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=2, col=1,)\n",
    "\n",
    "fig.add_trace(go.Scattergl(\n",
    "            x=pd.to_datetime(date_prop),\n",
    "            y=Z_prop.values.astype(float),\n",
    "                mode='markers',\n",
    "                opacity=1,\n",
    "                marker=dict(size=3, color='red'),     \n",
    "                showlegend=False),\n",
    "                secondary_y=False, row=3, col=1,)\n",
    "\n",
    "fig.update_yaxes( title=\"X\",  exponentformat= 'power',row=1, col=1)\n",
    "fig.update_yaxes( title=\"Y\",  exponentformat= 'power',row=2, col=1)\n",
    "fig.update_yaxes( title=\"Z\",  exponentformat= 'power',row=3, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(title='PCE (blue, Spire LeoOrb POD); Orbit Fit (red, data reduction with PCE)',\n",
    "        autosize=True\n",
    "#         width=800,height=900,\n",
    "                )\n",
    "fig.show(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3a1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.454706Z",
     "start_time": "2023-02-06T21:13:17.837Z"
    }
   },
   "outputs": [],
   "source": [
    "# # First run of a new satellite:\n",
    "#     - generate some sort of initial conditions file\n",
    "#     - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb16813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-31T21:24:51.273003Z",
     "start_time": "2023-01-31T21:24:51.252092Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e0943d0",
   "metadata": {},
   "source": [
    "# Load input data\n",
    "Load the data from whatever source, and define the format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111219e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.455480Z",
     "start_time": "2023-02-06T21:13:17.839Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy  as np\n",
    "# import pandas as pd\n",
    "# from  datetime import datetime,timedelta\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f7d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.456238Z",
     "start_time": "2023-02-06T21:13:17.841Z"
    }
   },
   "outputs": [],
   "source": [
    "# #### INPUTS ----------------------------------------------------\n",
    "dir_input = '/data/SatDragModelValidation/data/inputs'\n",
    "dir_spire_sourcetraj = dir_input+'/sat_spire83/data_Spire/arcs'\n",
    "# file_IC = dir_input+'/sat_spire83/setups/statevector_ICs_eci_epochA.txt'\n",
    "# spire_sat_num = 83\n",
    "# days          = np.arange(1,32)\n",
    "# #### INPUTS ----------------------------------------------------  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95de277",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.457110Z",
     "start_time": "2023-02-06T21:13:17.843Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "###  Make the file if not exist\n",
    "if os.path.exists(file_IC):\n",
    "    print(f\"Raw initial conditions file: {file_IC}\")\n",
    "    print('File exists and does not need to be re-written.')\n",
    "    \n",
    "    \n",
    "    epoch_start =settings_SPIRE['epoch_start']['input'][0]\n",
    "    prms_arc={}\n",
    "    prms_arc['epoch_start'] = epoch_start\n",
    "    prms_arc['epoch_startDT'] = pd.to_datetime(prms_arc['epoch_start'],\\\n",
    "                                           format='%Y-%m-%d %H:%M:%S')\n",
    "    #inputs----------------------------------\n",
    "    datetype = 'datetime_string'\n",
    "    file_statevector_ICs=file_IC                                     \n",
    "    epoch_startDT = prms_arc['epoch_startDT']\n",
    "    #inputs----------------------------------\n",
    "    date_in_file_flag= False\n",
    "    import linecache\n",
    "    #\n",
    "    ### Only need to use accuracy to within 1 second (ignore the microseconds)\n",
    "    if datetype == 'datetime_string':\n",
    "        date_str = str(epoch_startDT)\n",
    "    elif datetype == 'YYMMDDHHMMSS':\n",
    "        date_str = datetime.strftime(epoch_startDT, '%y%m%d%H%M%S')\n",
    "    #\n",
    "    with open(file_statevector_ICs, 'r') as f:\n",
    "        for line_no, line_text in enumerate(f):\n",
    "            if date_str in line_text:\n",
    "                date_in_file_flag= True\n",
    "                print('    ','xyzline',line_no,line_text)\n",
    "                break\n",
    "    if date_in_file_flag == False:\n",
    "        ### Find the dates that have the same hour    \n",
    "        if datetype == 'datetime_string':\n",
    "            date_roundhour_str = str(epoch_startDT)[:10]\n",
    "        elif datetype == 'YYMMDDHHMMSS':\n",
    "            date_roundhour_str = datetime.strftime(epoch_startDT, '%y%m%d%H%M%S')\n",
    "        ### Scan through IC file and append a list of dates within the same hour\n",
    "        line_no_list = []\n",
    "        line_list = []\n",
    "        with open(file_statevector_ICs, 'r') as f:\n",
    "            for line_no, line_text in enumerate(f):\n",
    "                if date_roundhour_str in line_text:\n",
    "                    line_no_list.append(line_no)\n",
    "        for i in np.arange(line_no_list[0]-10, line_no_list[-1]+10):\n",
    "            line = linecache.getline(file_statevector_ICs,i)\n",
    "            line_list.append(line)\n",
    "        dates = []\n",
    "        for i ,val in enumerate(line_list):\n",
    "            if datetype == 'datetime_string':\n",
    "                dates.append(pd.to_datetime(line_list[i][:19],format='%Y-%m-%d %H:%M:%S'))\n",
    "            elif datetype == 'YYMMDDHHMMSS':\n",
    "                dates.append(pd.to_datetime(line_list[i][:19],format='%y%m%d%H%M%S.%f'))\n",
    "    #\n",
    "    xyzline = pd.read_csv(file_statevector_ICs, \n",
    "                skiprows = line_no_list[0], \n",
    "                nrows=line_no_list[-1]- line_no_list[0],           \n",
    "                sep = '\\s+',\n",
    "                dtype=object,\n",
    "                names = [\n",
    "                    'DateYMD',\n",
    "                    'DateHMS',\n",
    "                    'X',\n",
    "                    'Y',\n",
    "                    'Z',\n",
    "                    'X_dot',\n",
    "                    'Y_dot',\n",
    "                    'Z_dot',\n",
    "                        ],)\n",
    "    #\n",
    "    xyzline['Date'] =  pd.to_datetime(xyzline['DateYMD']+xyzline['DateHMS'], format='%Y-%m-%d%H:%M:%S')\n",
    "    del xyzline['DateYMD'], xyzline['DateHMS']\n",
    "#     pass\n",
    "else:\n",
    "    \n",
    "    #### Find files throught dir tree containing Satellite's LeoOrb POD\n",
    "    files_with_sat = []\n",
    "    ## Loop through the daily directories\n",
    "    for iday,day in enumerate(days):\n",
    "        dir_set   = dir_spire_sourcetraj + f'/2018-11-{day:02d}/'\n",
    "        #\n",
    "        ## Loop through the arc directories for that day,\n",
    "        ## Identify the leoOrb..._{sat#}.sp3 (Spire \"POD\") files\n",
    "        for root, dirs, files in os.walk(dir_set, topdown=False):\n",
    "            for name in files:\n",
    "                if 'leoOrb'in name and f'{spire_sat_num:03d}.sp3' in name:\n",
    "                    files_with_sat.append(os.path.join(root, name))\n",
    "    del root, dirs, files, name\n",
    "    del days, iday, day\n",
    "\n",
    "\n",
    "\n",
    "    #### Load raw data from all found files\n",
    "    from pygeodyn.satellite_spire import read_SpireLeoOrbPOD_sp3c\n",
    "    leoOrb_ecef = read_SpireLeoOrbPOD_sp3c(files_with_sat)\n",
    "    del files_with_sat\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    ## Load coordinate transformation functions\n",
    "    from pygeodyn.util_dir.coordinate_systems import iau06_Call_ecef2eci\n",
    "    from pygeodyn.util_dir.time_systems import time_gps_to_utc,\\\n",
    "                                               get_leapseconds, jday           \n",
    "    ### Get the leapseconds for time period of interest\n",
    "    dAT = get_leapseconds(leoOrb_ecef['date_gps'][0].year,\n",
    "                          leoOrb_ecef['date_gps'][0].month,\n",
    "                          leoOrb_ecef['date_gps'][0].day,)\n",
    "    ## Convert to UTC\n",
    "    leoOrb_ecef['date_utc'] = [time_gps_to_utc(time, dAT) \\\n",
    "                                  for time in leoOrb_ecef['date_gps']]\n",
    "    del leoOrb_ecef['date_gps']\n",
    "    del leoOrb_ecef['clock_microsec']\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    ### Convert all ephemerides from ECEF-igs08 to ECI-j2000\n",
    "    import time\n",
    "    start = time.time()\n",
    "    conv_dms2kms = 1/10000.\n",
    "    #\n",
    "    len_ecef = np.shape(leoOrb_ecef['date_utc'])[0]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    f = open(file_IC, \"w\")\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    ### Write to file\n",
    "    with open(file_IC, 'r+') as file:\n",
    "\n",
    "        #### Manually write the header units\n",
    "        header_units =\\\n",
    "                 f\"{'UTC'.rjust(len(str(leoOrb_ecef['date_utc'][1]))-1,' ') }\"\\\n",
    "                +f\"  {'(m)'.rjust(15,' ')}\"\\\n",
    "                +f\"  {'(m)'.rjust(15,' ')}\"\\\n",
    "                +f\"  {'(m)'.rjust(15,' ')}\"\\\n",
    "                +f\"  {'(m/s)'.rjust(15,' ')}\"\\\n",
    "                +f\"  {'(m/s)'.rjust(15,' ')}\"\\\n",
    "                +f\"  {'(m/s)'.rjust(15,' ')}\"\\\n",
    "\n",
    "        #### Manually write the header field names\n",
    "        header_names =\\\n",
    "                 f\"{'Date'.rjust(len(str(leoOrb_ecef['date_utc'][1]))-1,' ') }\"\\\n",
    "                +f\"  {'X'.rjust(15,' ')}\"\\\n",
    "                +f\"  {'Y'.rjust(15,' ')}\"\\\n",
    "                +f\"  {'Z'.rjust(15,' ')}\"\\\n",
    "                +f\"  {'X_dot'.rjust(15,' ')}\"\\\n",
    "                +f\"  {'Y_dot'.rjust(15,' ')}\"\\\n",
    "                +f\"  {'Z_dot'.rjust(15,' ')}\"\\\n",
    "\n",
    "        #### Manually write the detailed header description\n",
    "        header_meta = \\\n",
    "        f'''### Initial conditions file\n",
    "    ### -----------------------\n",
    "    ###     Satellite: Spire_083 (1804607)\n",
    "    ###     Epoch: +start____ 2018  9 23  0 12  0.0300000 \n",
    "    ###            +stop_____ 2018 12  9 23 43 35.9080000 \n",
    "    ###     Last modified: {datetime.now()-timedelta(hours=7)}\n",
    "    ###\n",
    "    ### Source\n",
    "    ### -------\n",
    "    ###     leoAtt_2018-09-23T00-12-00Z.9999999.083.log\n",
    "    ###     (long quaternion file)\n",
    "    ###     %spire version 1.3  revision   1 2019 07 05 00:00 Spire     Spire Processing Center\n",
    "    ###\n",
    "    ### Contents\n",
    "    ### --------\n",
    "    ###     Date: (YYYY-MM-DD hh:mm:ss.ssssss) (UTC, converted from gps time)\n",
    "    ###     pvi: Position and velocity (X, Y, Z, X_dot, Y_dot, Z_dot)\n",
    "    ###          coordinate: ECI-J2000, (converted from ECEF-IGS08)\n",
    "    ###          unit: m\n",
    "    ###\n",
    "    #{header_units}\n",
    "    #{header_names}\n",
    "    ### %eoh\n",
    "    '''\n",
    "        \n",
    "        file.write(header_meta)  \n",
    "        for indx,valdate in enumerate(leoOrb_ecef['date_utc']):\n",
    "            ## position vector earth fixed  ( km )\n",
    "            recef = [leoOrb_ecef['x_km'][indx],  \n",
    "                     leoOrb_ecef['y_km'][indx], \n",
    "                     leoOrb_ecef['z_km'][indx]]\n",
    "            ## velocity vector earth fixed  (km/s)\n",
    "            vecef = [leoOrb_ecef['xdot_dms'][indx]*conv_dms2kms, \n",
    "                     leoOrb_ecef['ydot_dms'][indx]*conv_dms2kms,\n",
    "                     leoOrb_ecef['zdot_dms'][indx]*conv_dms2kms]\n",
    "            ### convert the data to correct coordinate ref frame\n",
    "            (reci, veci, _)= iau06_Call_ecef2eci(\\\n",
    "                                          recef, vecef, None,\n",
    "                                          leoOrb_ecef['date_utc'][indx].year  , \n",
    "                                          leoOrb_ecef['date_utc'][indx].month , \n",
    "                                          leoOrb_ecef['date_utc'][indx].day   , \n",
    "                                          leoOrb_ecef['date_utc'][indx].hour  , \n",
    "                                          leoOrb_ecef['date_utc'][indx].minute, \n",
    "                                          leoOrb_ecef['date_utc'][indx].second, \n",
    "                                          calc_accel = False)\n",
    "        #### Manually write each row of the data.\n",
    "            row =   f\"{leoOrb_ecef['date_utc'][indx]}\"\\\n",
    "                   +f\"  {reci[0,0]*1000:15.5f}\"\\\n",
    "                   +f\"  {reci[1,0]*1000:15.5f}\"\\\n",
    "                   +f\"  {reci[2,0]*1000:15.5f}\"\\\n",
    "                   +f\"  {veci[0,0]*1000:15.5f}\"\\\n",
    "                   +f\"  {veci[1,0]*1000:15.5f}\"\\\n",
    "                   +f\"  {veci[2,0]*1000:15.5f}\"\\\n",
    "                   +f\"\\n\"\n",
    "            file.write(row)\n",
    "    #\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    #\n",
    "    print()\n",
    "    print(f'       indxes: 0 -',indx,'') \n",
    "    print(f'       Time: ',np.round(elapsed,5),'secs') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9daad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.457867Z",
     "start_time": "2023-02-06T21:13:17.845Z"
    }
   },
   "outputs": [],
   "source": [
    "# xyzline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963b9dc",
   "metadata": {},
   "source": [
    "# Making PCE:\n",
    " 1. Identify source ephemeris   \n",
    "    - format and define  \n",
    "  \n",
    "  \n",
    " 2. Prepare ephemeris for fortran code  \n",
    "     - convert to asciitraj.txt file\n",
    " \n",
    " 3.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3370c5ec",
   "metadata": {},
   "source": [
    "## Make ascii txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea82be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.458639Z",
     "start_time": "2023-02-06T21:13:17.847Z"
    }
   },
   "outputs": [],
   "source": [
    "from pygeodyn.util_dir.time_systems import  time_utc_to_gps,\\\n",
    "                                            ymdhms_to_mjds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41704c92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.459422Z",
     "start_time": "2023-02-06T21:13:17.849Z"
    }
   },
   "outputs": [],
   "source": [
    "# ### Prepare inputs\n",
    "# import math\n",
    "\n",
    "# pce_in = {}\n",
    "\n",
    "# ### Convert UTC to GPS time and convert to MJDsec\n",
    "# mjdsec_gps = [ymdhms_to_mjds(time_utc_to_gps(date, 37).year,\n",
    "#                                        time_utc_to_gps(date, 37).month,\n",
    "#                                        time_utc_to_gps(date, 37).day,\n",
    "#                                        time_utc_to_gps(date, 37).hour,\n",
    "#                                        time_utc_to_gps(date, 37).minute,\n",
    "#                                        time_utc_to_gps(date, 37).second)\n",
    "#                                            for date in xyzline['Date'].values]\n",
    "\n",
    "\n",
    "# pce_in['mjdsec_gps'],\\\n",
    "# pce_in['frac_sec']    = map(list,  \\\n",
    "#                             zip(*[[int(math.modf(date)[1]),\\\n",
    "#                                    math.modf(date)[0]]\\\n",
    "#                                   for date in mjdsec_gps ]))\n",
    "# pce_in['gps_offset'] = -18.0\n",
    "# pce_in['X_j2000_m']          = xyzline['X'].values.astype(float)\n",
    "# pce_in['Y_j2000_m']          = xyzline['Y'].values.astype(float)\n",
    "# pce_in['Z_j2000_m']          = xyzline['Z'].values.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac7980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.460163Z",
     "start_time": "2023-02-06T21:13:17.851Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# pce_in_df = pd.DataFrame(pce_in)\n",
    "# pce_in_df.insert(1, 'utc_offset' , pce_in_df['frac_sec'] + pce_in_df['gps_offset'])\n",
    "\n",
    "# del pce_in_df['frac_sec']\n",
    "# del pce_in_df['gps_offset']\n",
    "# # pce_in_df\n",
    "\n",
    "\n",
    "# ##### Save as an unadorned txt file\n",
    "# pce_in_df.to_csv('TRAJ.txt',      \\\n",
    "#                       sep=' ',      \\\n",
    "#                       index = False,\\\n",
    "#                       header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652c6c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T22:22:52.940664Z",
     "start_time": "2023-01-30T22:22:52.729941Z"
    }
   },
   "source": [
    "## call fortran function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ec060",
   "metadata": {},
   "source": [
    "- pass paths into fortran using env vars\n",
    "- fix the input options to be satellite specific\n",
    "- add checks and writes to the fortran function\n",
    "\n",
    "- re-write the function so that it is more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677d7f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.460965Z",
     "start_time": "2023-02-06T21:13:17.853Z"
    }
   },
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "\n",
    "\n",
    "# path_to_data = '/data/SatDragModelValidation/notebooks/'\n",
    "# path_to_PCE_fortran = '/data/SatDragModelValidation/pygeodyn/pygeodyn/util_preprocessing/'\n",
    "# path_preprocessing  = '/data/SatDragModelValidation/pygeodyn/pygeodyn/util_preprocessing/'\n",
    "# in_filename  = 'TRAJ.txt'\n",
    "# out_filename = 'g2b_pce'\n",
    "\n",
    "# ### CHANGE DIRECTORY to where the fortran code is hosted\n",
    "# os.chdir(path_to_PCE_fortran)\n",
    "\n",
    "# #### Write the inputs to the fortran code to a file to be read in variably:\n",
    "# file_FTN_opts = open(path_to_PCE_fortran +\"options_fortrancode.txt\",\"w+\")\n",
    "# file_FTN_opts.writelines(path_to_data+'/'+ '\\n') \n",
    "# file_FTN_opts.writelines(in_filename     +'\\n')\n",
    "# file_FTN_opts.writelines(out_filename    +'\\n')\n",
    "# file_FTN_opts.close()        \n",
    "\n",
    "\n",
    "\n",
    "# #### Compile the pce code:\n",
    "# command_1 = './compile_pce_f.sh'\n",
    "# subprocess.run(command_1, shell = True)\n",
    "# print('pce_fortran.f compiled')\n",
    "\n",
    "# #### Execute the pce code\n",
    "# command_2 = './ExecutePCE.exe > out_pce 2> err_execute'\n",
    "# subprocess.run(command_2, shell = True)\n",
    "# print('pce_fortran.f executed')\n",
    "# print('')\n",
    "\n",
    "# # os.system('gzip -vr '+ path_to_data+'/'+out_filename)\n",
    "\n",
    "# # os.system('mv '+ path_to_data+'/'+out_filename+'.gz'+ ' '+'/data/data_geodyn/inputs/icesat2/g2b/')\n",
    "# # os.system('rm'+' '+path_preprocessing + '/TRAJ.txt')\n",
    "\n",
    "# # if os.path.exists('/data/data_geodyn/inputs/icesat2/g2b/'+out_filename+'.gz'):\n",
    "# #     print('The G2B file has been saved to: ','/data/data_geodyn/inputs/icesat2/g2b/',out_filename,'.gz')\n",
    "# # else:\n",
    "# #     print('The G2B binary file has been saved to: ',path_to_data,'/',out_filename, sep='')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1ca93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.461884Z",
     "start_time": "2023-02-06T21:13:17.855Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "tabtab = '        '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e7204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.462831Z",
     "start_time": "2023-02-06T21:13:17.857Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     TRAJ.txt for input to PCE_converter.f\n",
    "\n",
    "# Requirements:\n",
    "#     - File titled TRAJ.txt\n",
    "#     - Each line of TRAJ.txt has one integer and four floating point words\n",
    "\n",
    "#         Word #     Fmt     Description    \n",
    "#         ------     ---     -----------\n",
    "#            1       int     MJDSEC_secs_timeGPS\n",
    "#            2      float    RSEC_fractional_secs + GPS_offset_secs_utc\n",
    "#            3      float    X   (j2000)\n",
    "#            4      float    Y   (j2000)\n",
    "#            5      float    Z   (j2000)\n",
    "\n",
    "# The integer and the first floating point word form the time tag of the \n",
    "#     record (this is just the first word of the RVG data record converted \n",
    "#     to an int).\n",
    "#     The first floating point is the sum of words 2 and 3 of the RVG data \n",
    "#     record.\n",
    "#     The last three words are the X, Y and Z coordinates of the satellite\n",
    "#     in the J2000 coordinate system. The X, Y and Z values are words \n",
    "#     5, 6 and 7 of the RVG data record.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2c22e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-06T21:13:25.463730Z",
     "start_time": "2023-02-06T21:13:17.859Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #### First call the functions that convert RVG files to a dataframe\n",
    "\n",
    "\n",
    "# print()\n",
    "# print(tabtab,'=======================================================')\n",
    "# print(tabtab,'STEP 3: Make ASCII.txt file to be read by FORTRAN code.')\n",
    "# print(tabtab,'=======================================================')\n",
    "# print()\n",
    "\n",
    "# df_traj_txt = copy.deepcopy(RVG_FINAL)\n",
    "\n",
    "# #### We need to prepare the dataframe to be saved to a CSV according \n",
    "# ####        to the requirements of the fortran code\n",
    "# #### first integer of TRAJ.txt is just the first word \n",
    "# ####      of RVG data record converted to an integer \n",
    "# df_traj_txt.insert(0, 'first_int', df_traj_txt['MJDSEC_secs_timeGPS'].astype(int))\n",
    "\n",
    "# del df_traj_txt['Date']\n",
    "# del df_traj_txt['MJDSEC_secs_timeGPS']\n",
    "# del df_traj_txt['XDOT_statevector_m_s']\n",
    "# del df_traj_txt['YDOT_statevector_m_s']\n",
    "# del df_traj_txt['ZDOT_statevector_m_s']\n",
    "\n",
    "# #### The first floating point of TRAJ.txt is just \n",
    "# #        the sum of words 2 and 3 of the RVG data record\n",
    "# sum_words_2_and_3 = df_traj_txt['RSEC_fractional_secs'] + df_traj_txt['GPS_offset_secs_utc']\n",
    "# df_traj_txt.insert(1, 'first_float', sum_words_2_and_3)\n",
    "# del df_traj_txt['RSEC_fractional_secs'] \n",
    "# del df_traj_txt['GPS_offset_secs_utc']\n",
    "\n",
    "# ##### Save as a txt file with pandas built-in function\n",
    "# df_traj_txt.to_csv(path_preprocessing + '/TRAJ.txt', sep=' ', index = False, header=False)\n",
    "\n",
    "# del df_traj_txt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
