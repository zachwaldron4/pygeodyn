{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwA1lhIZp7g4"
   },
   "source": [
    "## Input the Parameters of the Starlette-SLR GEODYN run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 346644\r\n",
      "-rw-rw-r--. 1 m_geodyn 354960125 Feb 17 22:42 iss190420_2dy.goco05s\r\n"
     ]
    }
   ],
   "source": [
    "ll /data/runs_geodyn/iss/results/msis2/msis2_accelon/IIEOUT/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1610413104781,
     "user": {
      "displayName": "Zach Waldron",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCzdVXYLG9FLe6I24HOvjA1RBs2DVFXIEkOXNT=s64",
      "userId": "03255003422937377828"
     },
     "user_tz": 420
    },
    "id": "kiHxh_w9yQfp",
    "outputId": "2808bcf2-0814-4ac8-f585-d59ed00d200e"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "########################\n",
    "# INPUT PARAMETERS:\n",
    "########################\n",
    "sat_file = 'iss'\n",
    "arc = '190420_2dy'\n",
    "grav_id ='goco05s' \n",
    "local_path = '/data/analysis/ISS_GPS_analysis/'\n",
    "SAT_ID = 9806701\n",
    "accel_card = 'accelon'\n",
    "\n",
    "\n",
    "#######################################\n",
    "# PATH TO DENSITY MODEL RUN of Choice:\n",
    "#######################################\n",
    "msis2_model = 'msis2'\n",
    "path_to_msis2 = '/data/runs_geodyn/'+sat_file+'/results/'+ msis2_model+'/'+ msis2_model+ '_' +accel_card+'/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wBFhigzFaV7"
   },
   "source": [
    "### Call the prep-function that loads the data\n",
    "\n",
    "This may take a few minutes to load."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSIS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46682,
     "status": "ok",
     "timestamp": 1610413155447,
     "user": {
      "displayName": "Zach Waldron",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCzdVXYLG9FLe6I24HOvjA1RBs2DVFXIEkOXNT=s64",
      "userId": "03255003422937377828"
     },
     "user_tz": 420
    },
    "id": "0mWARLwq6OiY",
    "outputId": "667aa347-c5a6-4602-de99-43634ae4e60b"
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# import sys  \n",
    "# sys.path.insert(0, '/data/analysis/util_funcs/py_geodynreader_gps/')\n",
    "\n",
    "# from a_ReadISS import ReadISS\n",
    "\n",
    "# AdjustedParams, Trajectory, Density, Resids = ReadISS(arc, \n",
    "#                                                            sat_file,\n",
    "#                                                            grav_id, \n",
    "#                                                            local_path, \n",
    "#                                                            path_to_msis2,\n",
    "#                                                            True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base file name for this arc is: iss190420_2dy.goco05s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WONKY INPUTS:\n",
    "path_to_data = path_to_msis2\n",
    "AccelStatus = True\n",
    "\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '/data/analysis/notebooks/util_funcs/py_geodynreader_gps/')\n",
    "SAT_ID = 9806701\n",
    "sat = sat_file\n",
    "file_name =  sat + arc + '.'+ grav_id\n",
    "print('The base file name for this arc is:',file_name,'\\n' )\n",
    "import os\n",
    "\n",
    "iieout_file  = '/data/analysis/IIEOUT_'+file_name   #path_to_data + 'IIEOUT/'+ file_name\n",
    "\n",
    "\n",
    "# from b_ReadISS import Save_AdjustedParameters_ISS\n",
    "# SatMain_AdjustedParams = Save_AdjustedParameters_ISS(SAT_ID, iieout_file, AccelStatus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_datetime_column_resids(resid_df, YR):\n",
    "    VERBOSE_timer = False\n",
    "    if VERBOSE_timer == True:\n",
    "        import time\n",
    "        start = time.time()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # resid_df['YYMMDD'] = resid_df['YYMMDD'].astype(int).astype(str)\n",
    "    # resid_df['HHMM'] =  resid_df['HHMM'].astype(int)\n",
    "    # resid_df['SEC_UTC'] =  resid_df['SEC_UTC'].astype(float).astype(str)\n",
    "\n",
    "    resid_df['YYMMDD'] = resid_df['YYMMDD'].astype(int).astype(str)\n",
    "    resid_df['HHMM'] = resid_df['HHMM'].astype(int).astype(str)\n",
    "\n",
    "\n",
    "    timeHHMM = [] \n",
    "    for i,val in enumerate(resid_df['HHMM']):\n",
    "    #     print(val)\n",
    "    #     print(len(val))\n",
    "        if len(val) == 3:\n",
    "            timehhmm_val = '0'+ val\n",
    "            timeHHMM.append(timehhmm_val)\n",
    "        elif len(val) == 2:\n",
    "            timehhmm_val = '00'+ val\n",
    "            timeHHMM.append(timehhmm_val)\n",
    "        elif len(val) == 1:\n",
    "            timehhmm_val = '000'+ val\n",
    "            timeHHMM.append(timehhmm_val)\n",
    "        elif len(val) == 4:\n",
    "            timehhmm_val = val\n",
    "            timeHHMM.append(timehhmm_val)\n",
    "    #     else:\n",
    "    #         print('NO WORK')\n",
    "\n",
    "\n",
    "    #     np.shape(timeHHMM)\n",
    "    resid_df['timeHHMM'] = timeHHMM\n",
    "\n",
    "    year  = []\n",
    "    month = []\n",
    "    day   = []\n",
    "    hours  = []\n",
    "    minutes = []\n",
    "    secs  = []\n",
    "    microsecs = []\n",
    "    for i,val in enumerate(resid_df['YYMMDD']):\n",
    "    #         print(val[:2])\n",
    "        if YR < 10:\n",
    "            year.append('200' + val[:1])\n",
    "            month.append(val[1:3])\n",
    "            day.append(val[3:])\n",
    "\n",
    "            hours.append(resid_df['timeHHMM'][i][:2])\n",
    "            minutes.append(resid_df['timeHHMM'][i][2:4])\n",
    "\n",
    "            secs.append(resid_df['SEC_UTC'][i][:2])\n",
    "            microsecs.append(resid_df['SEC_UTC'][i][3:])\n",
    "        else:\n",
    "            year.append('20' + val[:2])\n",
    "            month.append(val[2:4])\n",
    "            day.append(val[4:])\n",
    "\n",
    "            hours.append(resid_df['timeHHMM'][i][:2])\n",
    "            minutes.append(resid_df['timeHHMM'][i][2:4])\n",
    "\n",
    "            secs.append(resid_df['SEC_UTC'][i][:2])\n",
    "            microsecs.append(resid_df['SEC_UTC'][i][3:])\n",
    "\n",
    "    resid_df['year']  = year\n",
    "    resid_df['month'] = month\n",
    "    resid_df['day']   = day\n",
    "    resid_df['hours']  = hours\n",
    "    resid_df['minutes'] = minutes\n",
    "    resid_df['secs']  = secs\n",
    "    resid_df['microsecs'] = microsecs\n",
    "    if VERBOSE_timer == True:\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        print(\"Loop through and extract indiv date vals:\",elapsed)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    fix_decimal = []\n",
    "    for i,val in enumerate(resid_df['secs'].astype(str)):\n",
    "    #     print(i,val)\n",
    "        if val.find('.') == 1:\n",
    "    #             print(i, val)\n",
    "            fix_decimal.append( '0'+val[:-1])\n",
    "    #             print(newval)\n",
    "        else:\n",
    "            fix_decimal.append( val)\n",
    "\n",
    "    if VERBOSE_timer == True:\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        print(\"Fix decimals in the seconds column:\",elapsed)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    year= list(map(int, resid_df['year'].values))\n",
    "    month= list(map(int, resid_df['month'].values))\n",
    "    day= list(map(int, resid_df['day'].values))\n",
    "    hour= list(map(int, resid_df['hours'].values))\n",
    "    minute = list(map(int, resid_df['minutes'].values))\n",
    "    second = list(map(int, fix_decimal))\n",
    "    microsecond= list(map(int, resid_df['microsecs'].values))\n",
    "\n",
    "    DATE = list(map(datetime, year,month, day, hour,minute,second,microsecond ))\n",
    "\n",
    "    if VERBOSE_timer == True:\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "    #         print(\"Put all dates in a single column:\",elapsed)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    return(DATE)\n",
    "\n",
    "\n",
    "def iteration_number(iieout_file):\n",
    "    '''\n",
    "    This function opens the iieout file, and returns the final iteration number\n",
    "    '''\n",
    "    with open(iieout_file, 'r') as f:\n",
    "        for line_no, line in enumerate(f):\n",
    "            if 'CONVERGENCE' in line:\n",
    "                line_text = line\n",
    "                # print(line)\n",
    "    num_iters = float(line_text[39:42])-1\n",
    "    return num_iters\n",
    "\n",
    "def read_observed_resids_gps(iieout_file, Year = 19, VERBOSE_timer = False):\n",
    "    '''\n",
    "    This function reads in the residuals from the massive IIEOUT file.\n",
    "\n",
    "\n",
    "    For residuals, there are specific station-satellite configurations.  \n",
    "    It is prudent to read in each configuration and save which satellites make it up.  \n",
    "    This is much harder to do than simply reading in all resuiduals (as I did before)\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if VERBOSE_timer == True:\n",
    "        import time\n",
    "        start = time.time()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    #############################\n",
    "    # - BEGIN RESIDUAL READER -\n",
    "    #############################\n",
    "\n",
    "\n",
    "    # How many iterations are in this run?\n",
    "    iteration = str(int(iteration_number(iieout_file)))\n",
    "    VERBOSE_timer = True\n",
    "    #\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    #\n",
    "    # We first find how many observations there are. \n",
    "    # We use the observation number to find where to STOP reading in data. \n",
    "    # We find this by finding the Summary by Measurment Header\n",
    "    text_smry_meas = 'RESIDUAL SUMMARY BY MEASUREMENT TYPE FOR ARC  1 INNER ITERATION  '+ (iteration) +' OF GLOBAL ITERATION 1'\n",
    "    #\n",
    "    # Loop through the iieout file and find where the above header exists (it should only show up once)\n",
    "    # For ISS-GPS runs, there are four TYPES of residuals.  We would like to read these in automatically\n",
    "    #        PCE X\n",
    "    #        PCE X\n",
    "    #        PCE X\n",
    "    #        DSS1WRNG \n",
    "    #\n",
    "    with open(iieout_file, 'r') as f:\n",
    "        for line_no, line_text in enumerate(f):\n",
    "            if text_smry_meas in line_text:\n",
    "                # Save the exact number where this section (based on the header) appears:\n",
    "                text_smry_meas_line_no = line_no\n",
    "    #\n",
    "    # Save out the Observation residual types:\n",
    "    # I read in the whole section and stop reading in when the first value of the line is no longer 0\n",
    "    count_lines = 1\n",
    "    line = linecache.getline(iieout_file,text_smry_meas_line_no+count_lines)\n",
    "    if int(line[0]) == 1: \n",
    "        is_integer = True\n",
    "    else:\n",
    "        print('Started out as wrong value in SUMMRY of MEASURMENTS')\n",
    "        is_integer = False\n",
    "\n",
    "    while is_integer == True:\n",
    "        try:\n",
    "            int(line[0])\n",
    "    #         print('Its an INTEGER')\n",
    "            line = linecache.getline(iieout_file,text_smry_meas_line_no+count_lines)\n",
    "            count_lines += 1\n",
    "            is_integer = True\n",
    "        except:\n",
    "    #         print(line[0])\n",
    "    #         print('not an INTEGER')\n",
    "            is_integer = False\n",
    "            count_lines -= 3\n",
    "    # print(count_lines)\n",
    "    # print(linecache.getline(iieout_file,text_smry_meas_line_no+count_lines))\n",
    "    resid_meas_summry = pd.read_csv(iieout_file, \n",
    "                               skiprows = text_smry_meas_line_no + 2  , \n",
    "                               nrows =  count_lines-2,\n",
    "                               sep = '\\s+',\n",
    "                               names =['Binary' ,\n",
    "                                        'NUMBER' ,\n",
    "                                        'MEAN' ,\n",
    "                                        'RMS' ,\n",
    "                                        'No.-WTD' ,\n",
    "                                        'WTD-MEAN' ,\n",
    "                                        'WTD-RMS' ,\n",
    "                                        'TYPE1' ,\n",
    "                                        'TYPE2' ,\n",
    "                                        ] ,\n",
    "                                        )\n",
    "    # Fix some formatting issues with the way the TYPES were read in\n",
    "    # concatenate the PCE and X (Y, Z) to make one column\n",
    "    type_fixed = []\n",
    "    for i,val in resid_meas_summry.iterrows():\n",
    "        try:\n",
    "            float(val['TYPE2'])\n",
    "            type_fixed.append(val['TYPE1'])\n",
    "            pass\n",
    "        except:\n",
    "            type_fixed.append(val['TYPE1'] + val['TYPE2'])\n",
    "    resid_meas_summry['TYPE'] = type_fixed          \n",
    "\n",
    "    #\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    #\n",
    "    '''\n",
    "    Now find all the instances of the OBSERVATION RESIDUALS \n",
    "    header at the last iteration.  \n",
    "\n",
    "    We will want to store these into a dictionary and save out:\n",
    "        - configuration type\n",
    "        - contributing satellites\n",
    "\n",
    "        It will probably be best to input data base on BLOCK number\n",
    "\n",
    "    '''\n",
    "    text_obs_resid = 'OBSERVATION RESIDUALS FOR ARC  1 FOR INNER ITERATION  '+ (iteration)\n",
    "    end_of_section = 'RESIDUAL SUMMARY BY STATION AND TYPE FOR ARC  1 INNER ITERATION  '+ (iteration)\n",
    "    lines_list_1 = [] \n",
    "    lines_list_2 = []\n",
    "\n",
    "    # The below grabs the line numbers of the section headers \n",
    "    # The Observation Residuals end at the first instance of the Summary by Station\n",
    "    with open(iieout_file, 'r') as f:\n",
    "        for line_no, line in enumerate(f):\n",
    "            if text_obs_resid in line:\n",
    "                lines_list_1.append(line_no)\n",
    "            elif end_of_section in line:\n",
    "                lines_list_2.append(line_no)\n",
    "\n",
    "    residual_range  = np.arange(lines_list_1[0], lines_list_2[0]+1)\n",
    "    # block_num_counter = 0\n",
    "\n",
    "    list_config_type  = []\n",
    "    list_SAT_main     = []\n",
    "    list_note         = []\n",
    "    list_SAT_1        = []\n",
    "    list_SAT_2        = []\n",
    "    list_YYMMDD       = []\n",
    "    list_HHMM         = []\n",
    "    list_SEC_UTC      = []\n",
    "    list_Observation  = []\n",
    "    list_Residual     = []\n",
    "    list_RatiotoSigma = []\n",
    "    list_Elev1        = []\n",
    "    list_Elev2        = []\n",
    "    list_OBS_No       = []\n",
    "    list_Block        = []\n",
    "\n",
    "    for i,val in enumerate(residual_range):\n",
    "        line = linecache.getline(iieout_file,val)\n",
    "        if 'STATION-SATELLITE CONFIGURATION' in line:\n",
    "    #         print('HEADER Type 1')\n",
    "            config_type = line[35:44]\n",
    "            SAT_main = line[54:62]\n",
    "            SAT_1 = line[72:80]\n",
    "            SAT_2 = line[90:98]\n",
    "            note = np.nan\n",
    "            # print(Stat_Sat_Config[35:43])\n",
    "            # print(Stat_Sat_Config[54:62])\n",
    "            # print(Stat_Sat_Config[72:80])\n",
    "            # print(Stat_Sat_Config[90:98])\n",
    "        elif 'STATION-SAT CONFIG.' in line:\n",
    "            if 'DSS1WRNG' in line:\n",
    "    #             print('HEADER Type 2-1')\n",
    "                config_type = line[46:56]\n",
    "                SAT_main = line[65:73]\n",
    "                note = np.nan\n",
    "                SAT_1 = line[83:91]\n",
    "                SAT_2 = line[100:109]\n",
    "            else:\n",
    "    #             print('HEADER Type 2-2')\n",
    "                config_type = line[46:56]\n",
    "                SAT_main = np.nan\n",
    "                note = line[55:63]\n",
    "                SAT_1 = line[65:74]\n",
    "                SAT_2 = np.nan\n",
    "\n",
    "        try:\n",
    "            BLOCK_no = int(line[117:125])\n",
    "            YYMMDD       = line[1:8]\n",
    "            HHMM         = line[8:13]\n",
    "            SEC_UTC      = line[13:23]\n",
    "            Observation  = line[26:43]\n",
    "            Residual     = line[46:58]\n",
    "            RatiotoSigma = line[60:70]\n",
    "            Elev1        = line[71:84]\n",
    "            Elev2        = line[85:96]\n",
    "            OBS_No       = line[106:117]\n",
    "            Block        = line[117:125]\n",
    "\n",
    "            list_config_type.append(config_type)\n",
    "            list_SAT_main.append(SAT_main)\n",
    "            list_note.append(note)\n",
    "            list_SAT_1.append(SAT_1)\n",
    "            list_SAT_2.append(SAT_2)\n",
    "            list_YYMMDD.append(YYMMDD)\n",
    "            list_HHMM.append(HHMM)\n",
    "            list_SEC_UTC.append(SEC_UTC)\n",
    "            list_Observation.append(Observation)\n",
    "            list_Residual.append(Residual)\n",
    "            list_RatiotoSigma.append(RatiotoSigma)\n",
    "            list_Elev1.append(Elev1)\n",
    "            list_Elev2.append(Elev2)\n",
    "            list_OBS_No.append(OBS_No)\n",
    "            list_Block.append(Block)\n",
    "        except:\n",
    "    #         print('Not a data block', line[117:125]) \n",
    "            pass\n",
    "\n",
    "    resids_dict= {'StatSatConfig' : list_config_type,\n",
    "                  'Sat_main'      : list_SAT_main   ,\n",
    "                  'SAT_1'         : list_SAT_1      ,\n",
    "                  'SAT_2'         : list_SAT_2      ,\n",
    "                  'Note'          : list_note       ,\n",
    "                  'YYMMDD'        : list_YYMMDD      ,\n",
    "                  'HHMM'          : list_HHMM        ,\n",
    "                  'SEC_UTC'       : list_SEC_UTC      ,\n",
    "                  'Observation'   : list_Observation  ,\n",
    "                  'Residual'      : list_Residual     ,\n",
    "                  'RatiotoSigma'  : list_RatiotoSigma ,\n",
    "                  'Elev1'         : list_Elev1       ,\n",
    "                  'Elev2'         : list_Elev2       ,\n",
    "                  'OBS_No'        : list_OBS_No      ,\n",
    "                  'Block'         : list_Block       ,\n",
    "                 } \n",
    "\n",
    "    resids_df = pd.DataFrame.from_dict(resids_dict)\n",
    "    linecache.clearcache()\n",
    "    #\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    #\n",
    "    # Fix the date column\n",
    "    # Year = 19\n",
    "    dates = make_datetime_column_resids(resids_df, Year)\n",
    "    resids_df['Date'] = dates\n",
    "\n",
    "    # The ratio-to-sigma columns has some weird strings in it\n",
    "    #        ValueError: could not convert string to float: ' -16.0620*'\n",
    "    #        remove them\n",
    "    fix_string = []\n",
    "    for i,val in enumerate(resids_df['RatiotoSigma']):\n",
    "        try:\n",
    "            float(val)\n",
    "            fix_string.append(val)\n",
    "        except:\n",
    "            # print(i, val)\n",
    "            fix_string.append(val[:-1])\n",
    "\n",
    "    resids_df['RatiotoSigma'] = fix_string\n",
    "#   \n",
    "# Some of the elevations are empty.  Replace the empty strings with nans\n",
    "#\n",
    "    elev_fix = []\n",
    "    for i,val in enumerate(A_FILE['Elev1']):\n",
    "        try:\n",
    "            float(val)\n",
    "            elev_fix.append(float(val))\n",
    "        except:\n",
    "            elev_fix.append(np.nan)\n",
    "    resids_df['Elev1'] = elev_fix\n",
    "    elev_fix = []\n",
    "    for i,val in enumerate(A_FILE['Elev2']):\n",
    "        try:\n",
    "            float(val)\n",
    "            elev_fix.append(float(val))\n",
    "        except:\n",
    "            elev_fix.append(np.nan)\n",
    "    resids_df['Elev2'] = elev_fix\n",
    "        \n",
    "    resids_df['Observation']  = resids_df['Observation'].astype(float)\n",
    "    resids_df['Residual']     = resids_df['Residual'].astype(float)\n",
    "    resids_df['RatiotoSigma'] = resids_df['RatiotoSigma'].astype(float)\n",
    "\n",
    "\n",
    "    return(resids_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "import os.path\n",
    "import linecache\n",
    "# VERBOSE_timer = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_FILE = read_observed_resids_gps(iieout_file, Year=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StatSatConfig</th>\n",
       "      <th>Sat_main</th>\n",
       "      <th>SAT_1</th>\n",
       "      <th>SAT_2</th>\n",
       "      <th>Note</th>\n",
       "      <th>YYMMDD</th>\n",
       "      <th>HHMM</th>\n",
       "      <th>SEC_UTC</th>\n",
       "      <th>Observation</th>\n",
       "      <th>Residual</th>\n",
       "      <th>...</th>\n",
       "      <th>Block</th>\n",
       "      <th>timeHHMM</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hours</th>\n",
       "      <th>minutes</th>\n",
       "      <th>secs</th>\n",
       "      <th>microsecs</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DSS1WRNG</td>\n",
       "      <td>9806701</td>\n",
       "      <td>5044284</td>\n",
       "      <td>5553175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190420</td>\n",
       "      <td>2118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>209.464035</td>\n",
       "      <td>-0.075906</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2118</td>\n",
       "      <td>2019</td>\n",
       "      <td>04</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>000000</td>\n",
       "      <td>2019-04-20 21:18:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSS1WRNG</td>\n",
       "      <td>9806701</td>\n",
       "      <td>5044284</td>\n",
       "      <td>5553175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190420</td>\n",
       "      <td>2118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>206.595126</td>\n",
       "      <td>-0.072653</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2118</td>\n",
       "      <td>2019</td>\n",
       "      <td>04</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>000000</td>\n",
       "      <td>2019-04-20 21:18:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DSS1WRNG</td>\n",
       "      <td>9806701</td>\n",
       "      <td>5044284</td>\n",
       "      <td>5553175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190420</td>\n",
       "      <td>2118</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>203.725479</td>\n",
       "      <td>-0.068320</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2118</td>\n",
       "      <td>2019</td>\n",
       "      <td>04</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>000000</td>\n",
       "      <td>2019-04-20 21:18:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSS1WRNG</td>\n",
       "      <td>9806701</td>\n",
       "      <td>5044284</td>\n",
       "      <td>5553175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190420</td>\n",
       "      <td>2118</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.855102</td>\n",
       "      <td>-0.065772</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2118</td>\n",
       "      <td>2019</td>\n",
       "      <td>04</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>000000</td>\n",
       "      <td>2019-04-20 21:18:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DSS1WRNG</td>\n",
       "      <td>9806701</td>\n",
       "      <td>5044284</td>\n",
       "      <td>5553175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190420</td>\n",
       "      <td>2118</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>197.984004</td>\n",
       "      <td>-0.060666</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2118</td>\n",
       "      <td>2019</td>\n",
       "      <td>04</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>000000</td>\n",
       "      <td>2019-04-20 21:18:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301329</th>\n",
       "      <td>DSS1WRNG</td>\n",
       "      <td>9806701</td>\n",
       "      <td>5345214</td>\n",
       "      <td>5652315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190422</td>\n",
       "      <td>239</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1596.112520</td>\n",
       "      <td>0.068724</td>\n",
       "      <td>...</td>\n",
       "      <td>18542</td>\n",
       "      <td>0239</td>\n",
       "      <td>2019</td>\n",
       "      <td>04</td>\n",
       "      <td>22</td>\n",
       "      <td>02</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>000000</td>\n",
       "      <td>2019-04-22 02:39:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301330</th>\n",
       "      <td>DSS1WRNG</td>\n",
       "      <td>9806701</td>\n",
       "      <td>5345214</td>\n",
       "      <td>5652315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190422</td>\n",
       "      <td>239</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1590.391982</td>\n",
       "      <td>0.072347</td>\n",
       "      <td>...</td>\n",
       "      <td>18542</td>\n",
       "      <td>0239</td>\n",
       "      <td>2019</td>\n",
       "      <td>04</td>\n",
       "      <td>22</td>\n",
       "      <td>02</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>000000</td>\n",
       "      <td>2019-04-22 02:39:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301331</th>\n",
       "      <td>DSS1WRNG</td>\n",
       "      <td>9806701</td>\n",
       "      <td>5345214</td>\n",
       "      <td>5652315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190422</td>\n",
       "      <td>239</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1584.675257</td>\n",
       "      <td>0.071817</td>\n",
       "      <td>...</td>\n",
       "      <td>18542</td>\n",
       "      <td>0239</td>\n",
       "      <td>2019</td>\n",
       "      <td>04</td>\n",
       "      <td>22</td>\n",
       "      <td>02</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>000000</td>\n",
       "      <td>2019-04-22 02:39:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301332</th>\n",
       "      <td>DSS1WRNG</td>\n",
       "      <td>9806701</td>\n",
       "      <td>5345214</td>\n",
       "      <td>5652315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190422</td>\n",
       "      <td>239</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>1578.962361</td>\n",
       "      <td>0.067737</td>\n",
       "      <td>...</td>\n",
       "      <td>18542</td>\n",
       "      <td>0239</td>\n",
       "      <td>2019</td>\n",
       "      <td>04</td>\n",
       "      <td>22</td>\n",
       "      <td>02</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>000000</td>\n",
       "      <td>2019-04-22 02:39:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301333</th>\n",
       "      <td>DSS1WRNG</td>\n",
       "      <td>9806701</td>\n",
       "      <td>5345214</td>\n",
       "      <td>5652315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190422</td>\n",
       "      <td>239</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1573.253312</td>\n",
       "      <td>0.063634</td>\n",
       "      <td>...</td>\n",
       "      <td>18542</td>\n",
       "      <td>0239</td>\n",
       "      <td>2019</td>\n",
       "      <td>04</td>\n",
       "      <td>22</td>\n",
       "      <td>02</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>000000</td>\n",
       "      <td>2019-04-22 02:39:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301334 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       StatSatConfig  Sat_main     SAT_1      SAT_2 Note  YYMMDD  HHMM  \\\n",
       "0          DSS1WRNG   9806701   5044284    5553175   NaN  190420  2118   \n",
       "1          DSS1WRNG   9806701   5044284    5553175   NaN  190420  2118   \n",
       "2          DSS1WRNG   9806701   5044284    5553175   NaN  190420  2118   \n",
       "3          DSS1WRNG   9806701   5044284    5553175   NaN  190420  2118   \n",
       "4          DSS1WRNG   9806701   5044284    5553175   NaN  190420  2118   \n",
       "...              ...       ...       ...        ...  ...     ...   ...   \n",
       "301329    DSS1WRNG    9806701   5345214    5652315   NaN  190422   239   \n",
       "301330    DSS1WRNG    9806701   5345214    5652315   NaN  190422   239   \n",
       "301331    DSS1WRNG    9806701   5345214    5652315   NaN  190422   239   \n",
       "301332    DSS1WRNG    9806701   5345214    5652315   NaN  190422   239   \n",
       "301333    DSS1WRNG    9806701   5345214    5652315   NaN  190422   239   \n",
       "\n",
       "           SEC_UTC  Observation  Residual  ...     Block  timeHHMM  year  \\\n",
       "0        0.000000    209.464035 -0.075906  ...        1       2118  2019   \n",
       "1        1.000000    206.595126 -0.072653  ...        1       2118  2019   \n",
       "2        2.000000    203.725479 -0.068320  ...        1       2118  2019   \n",
       "3        3.000000    200.855102 -0.065772  ...        1       2118  2019   \n",
       "4        4.000000    197.984004 -0.060666  ...        1       2118  2019   \n",
       "...            ...          ...       ...  ...       ...       ...   ...   \n",
       "301329  40.000000   1596.112520  0.068724  ...    18542       0239  2019   \n",
       "301330  41.000000   1590.391982  0.072347  ...    18542       0239  2019   \n",
       "301331  42.000000   1584.675257  0.071817  ...    18542       0239  2019   \n",
       "301332  43.000000   1578.962361  0.067737  ...    18542       0239  2019   \n",
       "301333  44.000000   1573.253312  0.063634  ...    18542       0239  2019   \n",
       "\n",
       "       month day hours minutes secs microsecs                Date  \n",
       "0         04  20    21      18    0   000000  2019-04-20 21:18:00  \n",
       "1         04  20    21      18    1   000000  2019-04-20 21:18:01  \n",
       "2         04  20    21      18    2   000000  2019-04-20 21:18:02  \n",
       "3         04  20    21      18    3   000000  2019-04-20 21:18:03  \n",
       "4         04  20    21      18    4   000000  2019-04-20 21:18:04  \n",
       "...      ...  ..   ...     ...  ...       ...                 ...  \n",
       "301329    04  22    02      39   40   000000  2019-04-22 02:39:40  \n",
       "301330    04  22    02      39   41   000000  2019-04-22 02:39:41  \n",
       "301331    04  22    02      39   42   000000  2019-04-22 02:39:42  \n",
       "301332    04  22    02      39   43   000000  2019-04-22 02:39:43  \n",
       "301333    04  22    02      39   44   000000  2019-04-22 02:39:44  \n",
       "\n",
       "[301334 rows x 24 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = make_datetime_column_resids(resids_df)\n",
    "\n",
    "\n",
    "# D['Date'] = dates\n",
    "\n",
    "\n",
    "# fix_string = []\n",
    "# for i,val in enumerate(D['Ratio to sigma']):\n",
    "#     try:\n",
    "#         float(val)\n",
    "#         fix_string.append(val)\n",
    "#     except:\n",
    "#         # print(i, val)\n",
    "#         fix_string.append(val[:-1])\n",
    "\n",
    "# D['Ratio_to_sigma_fixed'] = fix_string\n",
    "#     return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "'''\n",
    "Now find all the instances of the OBSERVATION RESIDUALS \n",
    "header at the last iteration.  \n",
    "\n",
    "We will want to store these into a dictionary and save out:\n",
    "    - configuration type\n",
    "    - contributing satellites\n",
    "    \n",
    "    It will probably be best to input data base on BLOCK number\n",
    "    \n",
    "    \n",
    "'''\n",
    "# text_obs_resid = 'OBSERVATION RESIDUALS FOR ARC  1 FOR INNER ITERATION  '+ (iteration)\n",
    "# end_of_section = 'RESIDUAL SUMMARY BY STATION AND TYPE FOR ARC  1 INNER ITERATION  '+ (iteration)\n",
    "# lines_list_1 = [] #np.empty(np.size(num_observations))\n",
    "# lines_list_2 = [] #np.empty(np.size(num_observations))\n",
    "\n",
    "# # The below grabs the line numbers of the section headers\n",
    "# with open(iieout_file, 'r') as f:\n",
    "#     for line_no, line in enumerate(f):\n",
    "#         if text_obs_resid in line:\n",
    "# #                 print(line_no)\n",
    "#             lines_list_1.append(line_no)\n",
    "# #         line_no_1 =lines_list \n",
    "#         elif end_of_section in line:\n",
    "#             lines_list_2.append(line_no)\n",
    "\n",
    "\n",
    "# # lines = search_iiesout_all_line_numbers(iieout_file, text)\n",
    "# line_no_1 = lines_list_1[0]\n",
    "# line_no_2 = lines_list_2[-1]\n",
    "# #-------------------------------------------------------------------------------\n",
    "# #-------------------------------------------------------------------------------\n",
    "# '''\n",
    "# Use the first and last line numbers from above to select\n",
    "# the sections of data that contains the observation residuals.\n",
    "# The outputted csv data are stored as A\n",
    "# '''\n",
    "# RESID_OBSERV = pd.read_csv(iieout_file, \n",
    "#                            skiprows = line_no_1 + 6 , \n",
    "#                            nrows =  int((line_no_2 - line_no_1) ),\n",
    "#                            sep = '\\s+',\n",
    "#                            names = ['YYMMDD'        ,\n",
    "#                                     'HHMM'          ,\n",
    "#                                     'Sec-UTC-R'     ,\n",
    "#                                     'Observation'   ,\n",
    "#                                     'Residual'      ,\n",
    "#                                     'Ratio to sigma',\n",
    "#                                     'Elev1'         ,\n",
    "#                                     'Elev2'         ,\n",
    "#                                     'OBS No.'       ,\n",
    "#                                     'Block']        ,\n",
    "#                                     )\n",
    "\n",
    "\n",
    "\n",
    "# if VERBOSE_timer == True:\n",
    "#     end = time.time()\n",
    "#     elapsed = end - start\n",
    "#     print(\"Elapsed time after line search setup:\",elapsed)\n",
    "# else:\n",
    "#     pass\n",
    "# #-------------------------------------------------------------------------------\n",
    "# #-------------------------------------------------------------------------------\n",
    "# ''' \n",
    "#   We now need to fix the data that contains a lot of misplaced\n",
    "#   characters, random strings, and headers\n",
    "# '''\n",
    "# A = pd.DataFrame(RESID_OBSERV)  # input\n",
    "# index_list = []\n",
    "# for index, row in A.iterrows():\n",
    "#     try:\n",
    "#         float(row['OBS No.'])\n",
    "#         float(row['HHMM'])\n",
    "#     except:\n",
    "#         index_list.append(index)\n",
    "#         continue\n",
    "\n",
    "# B=A.drop(index_list)\n",
    "# if VERBOSE_timer == True:\n",
    "#     end = time.time()\n",
    "#     elapsed = end - start\n",
    "#     print(\"Elapsed time after loop through then drop indecies:\",elapsed)\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# #-------------------------------------------------------------------------------\n",
    "# #-------------------------------------------------------------------------------\n",
    "# ''' \n",
    "#   We locate the index of the last observation number and remove \n",
    "#   all datapoints that are after it in the DataFrame\n",
    "# '''\n",
    "# C = B.reset_index()\n",
    "# index_drops = np.arange(C[C['OBS No.']==str(int(num_observations))].index[0]+1,  C.index.stop)\n",
    "# index_drops\n",
    "\n",
    "# D = C.drop(index_drops)\n",
    "# if VERBOSE_timer == True:\n",
    "#     end = time.time()\n",
    "#     elapsed = end - start\n",
    "#     print(\"Elapsed time after dropping all bad indicies after last obs no.:\",elapsed)\n",
    "\n",
    "# # dates = make_datetime_column_resids(D)\n",
    "# # D['Date'] = dates\n",
    "\n",
    "# # fix_string = []\n",
    "# # for i,val in enumerate(D['Ratio to sigma']):\n",
    "# #     try:\n",
    "# #         float(val)\n",
    "# #         fix_string.append(val)\n",
    "# #     except:\n",
    "# #         # print(i, val)\n",
    "# #         fix_string.append(val[:-1])\n",
    "\n",
    "# # D['Ratio_to_sigma_fixed'] = fix_string\n",
    "# #     return D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM74G9L+KyabHIgPwslRiE4",
   "collapsed_sections": [],
   "name": "Read_starlette_data.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
